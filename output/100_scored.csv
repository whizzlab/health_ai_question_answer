,pmid,title,abstract,disease_answer,disease_score,sample_answer,sample_score,question_answer,question_score,modality_answer,modality_score,country_answer,country_score,hospital_answer,hospital_score,database_answer,database_score,organisation_answer,organisation_score
0,35308674,Comparison of Chest Computed Tomography Between the Two Waves of Coronavirus Disease 2019 in Belgium Using Artificial Intelligence.,"Background In this study, we aimed to compare two outbreaks of coronavirus disease 2019 (COVID-19) in Belgium in tomographic and biological-clinical aspects with artificial intelligence (AI). Methodology We performed an observational retrospective study. Adult patients who were symptomatic in the first seven days with COVID-19 infection, diagnosed by chest computed tomography (CT) and/or reverse transcription-polymerase chain reaction, were included in this study. The first wave of the pandemic lasted from March 25, 2020, to May 25, 2020, and the second wave lasted from October 7, 2020, to December 7, 2020. For each wave, two subgroups were defined depending on whether respiratory failure occurred during the course of the disease. The quantitative estimation of COVID-19 lung lesions was performed by AI, radiologists, and radiology residents. The chest CT severity score was calculated by AI. Results In the 202 patients included in this study, we found statistically significant differences for obesity, hypertension, and asthma. The differences were predominant in the second wave. Moreover, a mixed distribution (central and peripherical) of pulmonary lesions was noted in the second wave, but no differences were noted regarding mortality, respiratory failure, complications, and other radiological and biological elements. Chest CT severity score was among the risk factors of mortality and respiratory failure. There was a mild agreement between AI and visual evaluation of pulmonary lesion extension (K = 0.4). Conclusions Between March and December 2020, in our cohort, for the majority of the parameters analyzed, we did not record significant changes between the two waves. AI can reduce the experience and performance gap of radiologists and better establish a hospitalization criterion.",'coronavirus disease 2019',0.668181777,'202',0.821366847,'to compare two outbreaks of coronavirus disease 2019 (COVID-19) in Belgium in tomographic and biological-clinical aspects',0.28023392,'chest computed tomography',0.524326056,'Belgium',0.875027597,'Belgium',0.010742113,'COVID-19',0.232817098,'COVID-19',0.232817098
1,35309014,A Study of Social and Behavioral Determinants of Health in Lung Cancer Patients Using Transformers-based Natural Language Processing Models.,"Social and behavioral determinants of health (SBDoH) have important roles in shaping people's health. In clinical research studies, especially comparative effectiveness studies, failure to adjust for SBDoH factors will potentially cause confounding issues and misclassification errors in either statistical analyses and machine learning-based models. However, there are limited studies to examine SBDoH factors in clinical outcomes due to the lack of structured SBDoH information in current electronic health record (EHR) systems, while much of the SBDoH information is documented in clinical narratives. Natural language processing (NLP) is thus the key technology to extract such information from unstructured clinical text. However, there is not a mature clinical NLP system focusing on SBDoH. In this study, we examined two state-of-the-art transformer-based NLP models, including BERT and RoBERTa, to extract SBDoH concepts from clinical narratives, applied the best performing model to extract SBDoH concepts on a lung cancer screening patient cohort, and examined the difference of SBDoH information between NLP extracted results and structured EHRs (SBDoH information captured in standard vocabularies such as the International Classification of Diseases codes). The experimental results show that the BERT-based NLP model achieved the best strict/lenient F1-score of 0.8791 and 0.8999, respectively. The comparison between NLP extracted SBDoH information and structured EHRs in the lung cancer patient cohort of 864 patients with 161,933 various types of clinical notes showed that much more detailed information about smoking, education, and employment were only captured in clinical narratives and that it is necessary to use both clinical narratives and structured EHRs to construct a more complete picture of patients' SBDoH factors.",'lung cancer',0.632609516,'864',0.465912864,'applied the best performing model to extract SBDoH concepts on a lung cancer screening patient cohort',0.224621266,'clinical narratives',0.380929828,'BERT and RoBERTa',0.001857242,"'clinical narratives. Natural language processing (NLP) is thus the key technology to extract such information from unstructured clinical text. However, there is not a mature clinical NLP system focusing on SBDoH. In this study, we examined two state-of-the-art transformer-based NLP models, including BERT and RoBERTa'",0.002024623,'lung cancer patient cohort',0.270736933,'lung cancer patient cohort',0.270736933
2,35308968,A Federated Mining Approach on Predicting Diabetes-Related Complications: Demonstration Using Real-World Clinical Data.,"Chronic diabetes can lead to microvascular complications, including diabetic eye disease, diabetic kidney disease, and diabetic neuropathy. However, the long-term complications often remain undetected at the early stages of diagnosis. Developing a machine learning model to identify the patients at high risk of developing diabetes-related complications can help design better treatment interventions. Building robust machine learning models require large datasets which further requires sharing data among different healthcare systems, hence, involving privacy and confidentiality concerns. The main <b>objective</b> of this study is to design a decentralized privacy-protected federated learning architecture that can deliver comparable performance to centralized learning. We demonstrate the potential of adopting federated learning to address the challenges such as class-imbalance in using real-world clinical data. In all our experiments, federated learning showed comparable performance to the gold-standard of centralized learning, and applying class balancing techniques improved performance across all cohorts.",'Chronic diabetes',0.388034329,'large datasets',0.011680413,'to design a decentralized privacy-protected federated learning architecture that can deliver comparable performance to centralized learning',0.445467412,'real-world clinical data',0.137084737,'all our experiments',0.000273526,'sharing data among different healthcare systems',0.001076368,'real-world clinical data',0.012900324,'real-world clinical data',0.012900324
3,35308960,Identifying Opioid Use Disorder from Longitudinal Healthcare Data using a Multi-stream Transformer.,"Opioid Use Disorder (OUD) is a public health crisis costing the US billions of dollars annually in healthcare, lost workplace productivity, and crime. Analyzing longitudinal healthcare data is critical in addressing many real-world problems in healthcare. Leveraging the real-world longitudinal healthcare data, we propose a novel multi-stream transformer model called MUPOD for OUD identification. MUPOD is designed to simultaneously analyze multiple types of healthcare data streams, such as medications and diagnoses, by attending to segments within and across these data streams. Our model tested on the data from 392,492 patients with long-term back pain problems showed significantly better performance than the traditional models and recently developed deep learning models.",'Opioid Use Disorder',0.571486503,"'392,492'",0.822405368,"'Analyzing longitudinal healthcare data is critical in addressing many real-world problems in healthcare. Leveraging the real-world longitudinal healthcare data, we propose a novel multi-stream transformer model called MUPOD for OUD identification'",0.102811877,'longitudinal healthcare data',0.360551566,'US',0.030675611,"'392,492'",0.005899241,"'392,492 patients with long-term back pain problems'",0.119990323,"'392,492 patients with long-term back pain problems'",0.119990323
4,35306966,Both Cross-Patient and Patient-Specific Seizure Detection Based on Self-Organizing Fuzzy Logic.,"Automatic epilepsy detection is of great significance for the diagnosis and treatment of patients. Most detection methods are based on patient-specific models and have achieved good results. However, in practice, new patients do not have their own previous EEG data and therefore cannot be initially diagnosed. If the EEG data of other patients can be used to achieve cross-patient detection, and cross-patient and patient-specific experiments can be combined at the same time, this method will be more widely used. In this work, an EEG classification model based on a self-organizing fuzzy logic (SOF) classifier is proposed for both cross-patient and patient-specific seizure detection. After preprocessing, the features of the original EEG signal are extracted and sent to the SOF classifier. This classification model is free from predefined parameters or a prior assumption regarding the EEG data generation model and only stores the key meta-parameters in memory. Therefore, it is very suitable for large-scale EEG signals in cross-patient detection. Selecting different granularity and classification distance in two different experiments after post-processing will achieve the best results. Experiments were conducted using a long-term continuous scalp EEG database and the [Formula: see text]-mean of cross-patient and patient-specific detection reached 83.35% and 92.04%, respectively. A comparison with other methods shows that there is greater performance and generalizability with this method.",'epilepsy',0.453978151,'large-scale EEG signals in cross-patient detection. Selecting different granularity and classification distance in two different experiments after post-processing will achieve the best results. Experiments were conducted using a long-term continuous scalp EEG database',0.020932735,"'Automatic epilepsy detection is of great significance for the diagnosis and treatment of patients. Most detection methods are based on patient-specific models and have achieved good results. However, in practice, new patients do not have their own previous EEG data and therefore cannot be initially diagnosed. If the EEG data of other patients can be used to achieve cross-patient detection, and cross-patient and patient-specific experiments can be combined at the same time, this method will be more widely used. In this work, an EEG classification model based on a self-organizing fuzzy logic (SOF) classifier is proposed for both cross-patient and patient-specific seizure detection'",0.151243523,"'EEG data and therefore cannot be initially diagnosed. If the EEG data of other patients can be used to achieve cross-patient detection, and cross-patient and patient-specific experiments can be combined at the same time, this method will be more widely used. In this work, an EEG classification model based on a self-organizing fuzzy logic (SOF) classifier is proposed for both cross-patient and patient-specific seizure detection. After preprocessing, the features of the original EEG signal are extracted and sent to the SOF classifier. This classification model is free from predefined parameters or a prior assumption regarding the EEG data generation model and only stores the key meta-parameters in memory. Therefore, it is very suitable for large-scale EEG signals in cross-patient detection. Selecting different granularity and classification distance in two different experiments after post-processing will achieve the best results. Experiments were conducted using a long-term continuous scalp EEG'",0.15154583,'long-term continuous scalp EEG database',0.002265991,'long-term continuous scalp EEG database',0.00126295,'long-term continuous scalp EEG database',0.589610308,'long-term continuous scalp EEG database',0.589610308
5,35309504,Transformer-Based High-Frequency Oscillation Signal Detection on Magnetoencephalography From Epileptic Patients.,"High-frequency oscillations (HFOs), observed within 80-500 Hz of magnetoencephalography (MEG) data, are putative biomarkers to localize epileptogenic zones that are critical for the success of surgical epilepsy treatment. It is crucial to accurately detect HFOs for improving the surgical outcome of patients with epilepsy. However, in clinical practices, detecting HFOs in MEG signals mainly depends on visual inspection by clinicians, which is very time-consuming, labor-intensive, subjective, and error-prone. To accurately and automatically detect HFOs, machine learning approaches have been developed and have demonstrated the promising results of automated HFO detection. More recently, the transformer-based model has attracted wide attention and achieved state-of-the-art performance on many machine learning tasks. In this paper, we are investigating the suitability of transformer-based models on the detection of HFOs. Specifically, we propose a transformer-based HFO detection framework for biomedical MEG one-dimensional signal data. For signal classification, we develop a transformer-based HFO (TransHFO) classification model. Then, we investigate the relationship between depth of deep learning models and classification performance. The experimental results show that the proposed framework outperforms the state-of-the-art HFO classifiers, increasing classification accuracy by 7%. Furthermore, we find that shallow TransHFO ( <math xmlns=""http://www.w3.org/1998/Math/MathML""><mo><</mo></math> 10 layers) outperforms deep TransHFO models (≥10 layers) on most data augmented factors.",'epilepsy',0.464471206,'MEG one-dimensional signal data',0.013328706,'detection of HFOs',0.167158443,'magnetoencephalography (MEG)',0.481073499,'biomedical MEG',0.001181816,'biomedical MEG one-dimensional signal data',0.003762421,'magnetoencephalography (MEG)',0.19039242,'magnetoencephalography (MEG)',0.19039242
6,35305619,Analysis of potential genetic biomarkers using machine learning methods and immune infiltration regulatory mechanisms underlying atrial fibrillation.,"We aimed to screen out biomarkers for atrial fibrillation (AF) based on machine learning methods and evaluate the degree of immune infiltration in AF patients in detail.Two datasets (GSE41177 and GSE79768) related to AF were downloaded from Gene expression omnibus (GEO) database and merged for further analysis. Differentially expressed genes (DEGs) were screened out using ""limma"" package in R software. Candidate biomarkers for AF were identified using machine learning methods of the LASSO regression algorithm and SVM-RFE algorithm. Receiver operating characteristic (ROC) curve was employed to assess the diagnostic effectiveness of biomarkers, which was further validated in another independent validation dataset of GSE14975. Moreover, we used CIBERSORT to study the proportion of infiltrating immune cells in each sample, and the Spearman method was used to explore the correlation between biomarkers and immune cells.129 DEGs were identified, and CYBB, CXCR2, and S100A4 were identified as key biomarkers of AF using LASSO regression and SVM-RFE algorithm. Both in the training dataset and the validation dataset, CYBB, CXCR2, and S100A4 showed favorable diagnostic effectiveness. Immune infiltration analysis indicated that, compared with sinus rhythm (SR), the atrial samples of patients with AF contained a higher T cells gamma delta, neutrophils and mast cells resting, whereas T cells follicular helper were relatively lower. Correlation analysis demonstrated that CYBB, CXCR2, and S100A4 were significantly correlated with the infiltrating immune cells.In conclusion, this study suggested that CYBB, CXCR2, and S100A4 are key biomarkers of AF correlated with infiltrating immune cells, and infiltrating immune cells play pivotal roles in AF.",'atrial fibrillation',0.597912028,'Two',0.242892258,'We aimed to screen out biomarkers for atrial fibrillation (AF) based on machine learning methods and evaluate the degree of immune infiltration in AF patients in detail',0.325322524,'GSE41177 and GSE79768',0.138758264,'GSE14975',0.003430004,'Gene expression omnibus (GEO) database',0.015785655,'Gene expression omnibus (GEO) database',0.563001677,'Gene expression omnibus (GEO) database',0.563001677
7,35308879,Dynamic Tracking of State Anxiety <i>via</i> Multi-Modal Data and Machine Learning.,"Anxiety induction is widely used in the investigations of the mechanism and treatment of state anxiety. State anxiety is accompanied by immediate psychological and physiological responses. However, the existing state anxiety measurement, such as the commonly used state anxiety subscale of the State-Trait Anxiety Inventory, mainly relies on questionnaires with low temporal resolution. This study aims to develop a tracking model of state anxiety with high temporal resolution. To capture the dynamic changes of state anxiety levels, we induced the participants' state anxiety through exposure to aversive pictures or the risk of electric shocks and simultaneously recorded multi-modal data, including dimensional emotion ratings, electrocardiogram, and galvanic skin response. Using the paired self-reported state anxiety levels and multi-modal measures, we trained and validated machine learning models to predict state anxiety based on psychological and physiological features extracted from the multi-modal data. The prediction model achieved a high correlation between the predicted and self-reported state anxiety levels. This quantitative model provides fine-grained and sensitive measures of state anxiety levels for future affective brain-computer interaction and anxiety modulation studies.",'state anxiety',0.196176894,'multi-modal data',0.032235915,'develop a tracking model of state anxiety with high temporal resolution',0.398598634,"'multi-modal data, including dimensional emotion ratings, electrocardiogram, and galvanic skin response'",0.474273294,'induced the participants' state anxiety through exposure to aversive pictures or the risk of electric shocks',0.000540993,'multi-modal data',0.00241956,'state anxiety subscale of the State-Trait Anxiety Inventory',0.448302656,'state anxiety subscale of the State-Trait Anxiety Inventory',0.448302656
8,35309831,Intelligent Algorithm-Based Ultrasound Image for Evaluating the Effect of Comprehensive Nursing Scheme on Patients with Diabetic Kidney Disease.,"This study was aimed at exploring the effect of ultrasound image evaluation of comprehensive nursing scheme based on artificial intelligence algorithms on patients with diabetic kidney disease (DKD). 44 patients diagnosed with DKD were randomly divided into two groups: group A (no nursing intervention) and group B (comprehensive nursing). In the same period, 32 healthy volunteers were selected as the control group. Ultrasonographic images based on the <i>K</i> non-local-means (KNL-Means) filtering algorithm were used to perform imaging examinations in healthy people and DKD patients before and after care. The results suggested that compared with those of the SAE reconstruction algorithm and KAVD reconstruction algorithm, the PSNR value of artificial bee colony algorithm reconstruction of image was higher and the MSE value was lower. The resistant index (RI) of DKD patients in group B after nursing was 0.63 ± 0.06, apparently distinct from the RI of the healthy people (controls) in the same group (0.58 ± 0.06) and the RI of DKD patients in group A (0.68 ± 0.07) (<i>P</i> < 0.05). The incidence rate of complications in DKD patients in group B was apparently inferior to that in group A. After comprehensive nursing intervention (CNI), the scores of all dimensions of quality of life (QoL) in DKD patients in group B were obviously superior versus those in DKD patients in group A. It suggests that implementation of nursing intervention for DKD patients can effectively help patients improve and control the level of renal function, while ultrasound images based on intelligent algorithm can dynamically detect the changes in the level of renal function in patients, which has the value of clinical promotion.",'diabetic kidney disease',0.720039606,'44',0.433767915,'exploring the effect of ultrasound image evaluation of comprehensive nursing scheme based on artificial intelligence algorithms on patients with diabetic kidney disease (DKD)',0.426087782,'ultrasound',0.384988815,'44 patients diagnosed with DKD were randomly divided into two groups: group A (no nursing intervention) and group B (comprehensive nursing)',0.000797252,'44 patients diagnosed with DKD were randomly divided into two groups: group A (no nursing intervention) and group B (comprehensive nursing)',0.002438395,'44 patients diagnosed with DKD were randomly divided into two groups: group A (no nursing intervention) and group B (comprehensive nursing)',0.024291379,'44 patients diagnosed with DKD were randomly divided into two groups: group A (no nursing intervention) and group B (comprehensive nursing)',0.024291379
9,35309227,Prediction of Atrial Fibrillation in Hospitalized Elderly Patients With Coronary Heart Disease and Type 2 Diabetes Mellitus Using Machine Learning: A Multicenter Retrospective Study.,"The objective of this study was to use machine learning algorithms to construct predictive models for atrial fibrillation (AF) in elderly patients with coronary heart disease (CHD) and type 2 diabetes mellitus (T2DM).The diagnosis and treatment data of elderly patients with CHD and T2DM, who were treated in four tertiary hospitals in Chongqing, China from 2015 to 2021, were collected. Five machine learning algorithms: logistic regression, logistic regression+least absolute shrinkage and selection operator, classified regression tree (CART), random forest (RF) and extreme gradient lifting (XGBoost) were used to construct the prediction models. The area under the receiver operating characteristic curve (AUC), sensitivity, specificity, and accuracy were used as the comparison measures between different models.A total of 3,858 elderly patients with CHD and T2DM were included. In the internal validation cohort, XGBoost had the highest AUC (0.743) and sensitivity (0.833), and RF had the highest specificity (0.753) and accuracy (0.735). In the external verification, RF had the highest AUC (0.726) and sensitivity (0.686), and CART had the highest specificity (0.925) and accuracy (0.841). Total bilirubin, triglycerides and uric acid were the three most important predictors of AF.The risk prediction models of AF in elderly patients with CHD and T2DM based on machine learning algorithms had high diagnostic value. The prediction models constructed by RF and XGBoost were more effective. The results of this study can provide reference for the clinical prevention and treatment of AF.",'atrial fibrillation (AF) in elderly patients with coronary heart disease',0.295742273,"'3,858'",0.778016597,'to use machine learning algorithms to construct predictive models for atrial fibrillation (AF) in elderly patients with coronary heart disease (CHD) and type 2 diabetes mellitus (T2DM)',0.483030304,'diagnosis and treatment data',0.611412406,'China',0.699350238,'Chongqing',0.56634517,"'diagnosis and treatment data of elderly patients with CHD and T2DM, who were treated in four tertiary hospitals in Chongqing, China'",0.168827765,"'diagnosis and treatment data of elderly patients with CHD and T2DM, who were treated in four tertiary hospitals in Chongqing, China'",0.168827765
10,35309885,Machine Learning for Detecting Parkinson's Disease by Resting-State Functional Magnetic Resonance Imaging: A Multicenter Radiomics Analysis.,"Parkinson's disease (PD) is one of the most common progressive degenerative diseases, and its diagnosis is challenging on clinical grounds. Clinically, effective and quantifiable biomarkers to detect PD are urgently needed. In our study, we analyzed data from two centers, the primary set was used to train the model, and the independent external validation set was used to validate our model. We applied amplitude of low-frequency fluctuation (ALFF)-based radiomics method to extract radiomics features (including first- and high-order features). Subsequently, <i>t</i>-test and least absolute shrinkage and selection operator (LASSO) were harnessed for feature selection and data dimensionality reduction, and grid search method and nested 10-fold cross-validation were applied to determine the optimal hyper-parameter λ of LASSO and evaluate the performance of the model, in which a support vector machine was used to construct the classification model to classify patients with PD and healthy controls (HCs). We found that our model achieved good performance [accuracy = 81.45% and area under the curve (AUC) = 0.850] in the primary set and good generalization in the external validation set (accuracy = 67.44% and AUC = 0.667). Most of the discriminative features were high-order radiomics features, and the identified brain regions were mainly located in the sensorimotor network and lateral parietal cortex. Our study indicated that our proposed method can effectively classify patients with PD and HCs, ALFF-based radiomics features that might be potential biomarkers of PD, and provided further support for the pathological mechanism of PD, that is, PD may be related to abnormal brain activity in the sensorimotor network and lateral parietal cortex.",'Parkinson's disease',0.64686349,'two centers',0.713909745,'we analyzed data from two centers',0.35490711,'radiomics',0.345898166,'two centers',0.1475363,'two centers',0.205814868,'two centers',0.699458063,'two centers',0.699458063
11,35308524,Predicting Optical Coherence Tomography-Derived High Myopia Grades From Fundus Photographs Using Deep Learning.,"To develop an artificial intelligence (AI) system that can predict optical coherence tomography (OCT)-derived high myopia grades based on fundus photographs.In this retrospective study, 1,853 qualified fundus photographs obtained from the Zhongshan Ophthalmic Center (ZOC) were selected to develop an AI system. Three retinal specialists assessed corresponding OCT images to label the fundus photographs. We developed a novel deep learning model to detect and predict myopic maculopathy according to the atrophy (A), traction (T), and neovascularisation (N) classification and grading system. Furthermore, we compared the performance of our model with that of ophthalmologists.When evaluated on the test set, the deep learning model showed an area under the receiver operating characteristic curve (AUC) of 0.969 for category A, 0.895 for category T, and 0.936 for category N. The average accuracy of each category was 92.38% (A), 85.34% (T), and 94.21% (N). Moreover, the performance of our AI system was superior to that of attending ophthalmologists and comparable to that of retinal specialists.Our AI system achieved performance comparable to that of retinal specialists in predicting vision-threatening conditions in high myopia via simple fundus photographs instead of fundus and OCT images. The application of this system can save the cost of patients' follow-up, and is more suitable for applications in less developed areas that only have fundus photography.",'high myopia',0.801621556,"'1,853'",0.268361278,'predicting vision-threatening conditions in high myopia via simple fundus photographs instead of fundus and OCT images',0.175708324,'fundus photographs',0.304538682,'high myopia',0.000409785,'Zhongshan Ophthalmic Center',0.102281649,'Zhongshan Ophthalmic Center',0.277373165,'Zhongshan Ophthalmic Center',0.277373165
12,35309216,Prediction of Online Psychological Help-Seeking Behavior During the COVID-19 Pandemic: An Interpretable Machine Learning Method.,"Online mental health service (OMHS) has been named as the best psychological assistance measure during the COVID-19 pandemic. An interpretable, accurate, and early prediction for the demand of OMHS is crucial to local governments and organizations which need to allocate and make the decision in mental health resources. The present study aimed to investigate the influence of the COVID-19 pandemic on the online psychological help-seeking (OPHS) behavior in the OMHS, then propose a machine learning model to predict and interpret the OPHS number in advance. The data was crawled from two Chinese OMHS platforms. Linguistic inquiry and word count (LIWC), neural embedding-based topic modeling, and time series analysis were utilized to build time series feature sets with lagging one, three, seven, and 14 days. Correlation analysis was used to examine the impact of COVID-19 on OPHS behaviors across different OMHS platforms. Machine learning algorithms and Shapley additive explanation (SHAP) were used to build the prediction. The result showed that the massive growth of OPHS behavior during the COVID-19 pandemic was a common phenomenon. The predictive model based on random forest (RF) and feature sets containing temporal features of the OPHS number, mental health topics, LIWC, and COVID-19 cases achieved the best performance. Temporal features of the OPHS number showed the biggest positive and negative predictive power. The topic features had incremental effects on performance of the prediction across different lag days and were more suitable for OPHS prediction compared to the LIWC features. The interpretable model showed that the increase in the OPHS behaviors was impacted by the cumulative confirmed cases and cumulative deaths, while it was not sensitive in the new confirmed cases or new deaths. The present study was the first to predict the demand for OMHS using machine learning during the COVID-19 pandemic. This study suggests an interpretable machine learning method that can facilitate quick, early, and interpretable prediction of the OPHS behavior and to support the operational decision-making; it also demonstrated the power of utilizing the OMHS platforms as an always-on data source to obtain a high-resolution timeline and real-time prediction of the psychological response of the online public.",'COVID-19 pandemic',0.335568279,'two Chinese OMHS platforms',0.199391283,'to investigate the influence of the COVID-19 pandemic on the online psychological help-seeking (OPHS) behavior in the OMHS',0.208385222,'crawled from two Chinese OMHS platforms',0.320484117,'Chinese',0.375706062,'two Chinese OMHS platforms',0.086677812,'two Chinese OMHS platforms',0.579917461,'two Chinese OMHS platforms',0.579917461
13,35309889,MRI Radiomics Features From Infarction and Cerebrospinal Fluid for Prediction of Cerebral Edema After Acute Ischemic Stroke.,"Neuroimaging biomarkers that predict the edema after acute stroke may help clinicians provide targeted therapies and minimize the risk of secondary injury. In this study, we applied pretherapy MRI radiomics features from infarction and cerebrospinal fluid (CSF) to predict edema after acute ischemic stroke. MRI data were obtained from a prospective, endovascular thrombectomy (EVT) cohort that included 389 patients with acute stroke from two centers (dataset 1, <i>n</i> = 292; dataset 2, <i>n</i> = 97), respectively. Patients were divided into edema group (brain swelling and midline shift) and non-edema group according to CT within 36 h after therapy. We extracted the imaging features of infarct area on diffusion weighted imaging (DWI) (abbreviated as DWI), CSF on fluid-attenuated inversion recovery (FLAIR) (CSF<sub>FLAIR</sub>) and CSF on DWI (CSF<sub>DWI</sub>), and selected the optimum features associated with edema for developing models in two forms of feature sets (DWI + CSF<sub>FLAIR</sub> and DWI + CSF<sub>DWI</sub>) respectively. We developed seven ML models based on dataset 1 and identified the most stable model. External validations (dataset 2) of the developed stable model were performed. Prediction model performance was assessed using the area under the receiver operating characteristic curve (AUC). The Bayes model based on DWI + CSF<sub>FLAIR</sub> and the RF model based on DWI + CSF<sub>DWI</sub> had the best performances (DWI + CSF<sub>FLAIR</sub>: AUC, 0.86; accuracy, 0.85; recall, 0.88; DWI + CSF<sub>DWI</sub>: AUC, 0.86; accuracy, 0.84; recall, 0.84) and the most stability (RSD% in DWI + CSF<sub>FLAIR</sub> AUC: 0.07, RSD% in DWI + CSF<sub>DWI</sub> AUC: 0.09), respectively. External validation showed that the AUC of the Bayes model based on DWI + CSF<sub>FLAIR</sub> was 0.84 with accuracy of 0.77 and area under precision-recall curve (auPRC) of 0.75, and the AUC of the RF model based on DWI + CSF<sub>DWI</sub> was 0.83 with accuracy of 0.81 and the auPRC of 0.76. The MRI radiomics features from infarction and CSF may offer an effective imaging biomarker for predicting edema.",'acute ischemic stroke',0.566984832,'389',0.405916706,'we applied pretherapy MRI radiomics features from infarction and cerebrospinal fluid (CSF) to predict edema after acute ischemic stroke',0.399560221,'MRI',0.429815292,'two centers',0.004064005,'two centers',0.025221471,'endovascular thrombectomy (EVT)',0.306761935,'endovascular thrombectomy (EVT)',0.306761935
14,35308538,A Few-Shot Learning-Based Retinal Vessel Segmentation Method for Assisting in the Central Serous Chorioretinopathy Laser Surgery.,"The location of retinal vessels is an important prerequisite for Central Serous Chorioretinopathy (CSC) Laser Surgery, which does not only assist the ophthalmologist in marking the location of the leakage point (LP) on the fundus color image but also avoids the damage of the laser spot to the vessel tissue, as well as the low efficiency of the surgery caused by the absorption of laser energy by retinal vessels. In acquiring an excellent intra- and cross-domain adaptability, the existing deep learning (DL)-based vessel segmentation scheme must be driven by big data, which makes the densely annotated work tedious and costly.This paper aims to explore a new vessel segmentation method with a few samples and annotations to alleviate the above problems. Firstly, a key solution is presented to transform the vessel segmentation scene into the few-shot learning task, which lays a foundation for the vessel segmentation task with a few samples and annotations. Then, we improve the existing few-shot learning framework as our baseline model to adapt to the vessel segmentation scenario. Next, the baseline model is upgraded from the following three aspects: (1) A multi-scale class prototype extraction technique is designed to obtain more sufficient vessel features for better utilizing the information from the support images; (2) The multi-scale vessel features of the query images, inferred by the support image class prototype information, are gradually fused to provide more effective guidance for the vessel extraction tasks; and (3) A multi-scale attention module is proposed to promote the consideration of the global information in the upgraded model to assist vessel localization. Concurrently, the integrated framework is further conceived to appropriately alleviate the low performance of a single model in the cross-domain vessel segmentation scene, enabling to boost the domain adaptabilities of both the baseline and the upgraded models.Extensive experiments showed that the upgraded operation could further improve the performance of vessel segmentation significantly. Compared with the listed methods, both the baseline and the upgraded models achieved competitive results on the three public retinal image datasets (i.e., CHASE_DB, DRIVE, and STARE). In the practical application of private CSC datasets, the integrated scheme partially enhanced the domain adaptabilities of the two proposed models.",'Central Serous Chorioretinopathy',0.604336679,'a few',0.117940485,'This paper aims to explore a new vessel segmentation method with a few samples and annotations',0.1384077,'big data',0.220676295,'private CSC datasets',0.001423492,'private CSC datasets',0.002027596,"'CHASE_DB, DRIVE, and STARE'",0.095254272,"'CHASE_DB, DRIVE, and STARE'",0.095254272
15,35310049,Three-dimensional diabetic macular edema thickness maps based on fluid segmentation and fovea detection using deep learning.,"To explore a more accurate quantifying diagnosis method of diabetic macular edema (DME) by displaying detailed 3D morphometry beyond the gold-standard quantification indicator-central retinal thickness (CRT) and apply it in follow-up of DME patients.Optical coherence tomography (OCT) scans of 229 eyes from 160 patients were collected. We manually annotated cystoid macular edema (CME), subretinal fluid (SRF) and fovea as ground truths. Deep convolution neural networks (DCNNs) were constructed including U-Net, sASPP, HRNetV2-W48, and HRNetV2-W48+Object-Contextual Representation (OCR) for fluid (CME+SRF) segmentation and fovea detection respectively, based on which the thickness maps of CME, SRF and retina were generated and divided by Early Treatment Diabetic Retinopathy Study (ETDRS) grid.In fluid segmentation, with the best DCNN constructed and loss function, the dice similarity coefficients (DSC) of segmentation reached 0.78 (CME), 0.82 (SRF), and 0.95 (retina). In fovea detection, the average deviation between the predicted fovea and the ground truth reached 145.7±117.8 µm. The generated macular edema thickness maps are able to discover center-involved DME by intuitive morphometry and fluid volume, which is ignored by the traditional definition of CRT>250 µm. Thickness maps could also help to discover fluid above or below the fovea center ignored or underestimated by a single OCT B-scan.Compared to the traditional unidimensional indicator-CRT, 3D macular edema thickness maps are able to display more intuitive morphometry and detailed statistics of DME, supporting more accurate diagnoses and follow-up of DME patients.",'diabetic macular edema',0.537370265,'160',0.585719138,'To explore a more accurate quantifying diagnosis method of diabetic macular edema (DME) by displaying detailed 3D morphometry beyond the gold-standard quantification indicator-central retinal thickness (CRT) and apply it in follow-up of DME patients',0.224132843,'Optical coherence tomography (OCT)',0.48332803,'Optical coherence tomography (OCT) scans of 229 eyes from 160 patients',0.000438697,'Optical coherence tomography (OCT) scans of 229 eyes from 160 patients',0.001300248,'Early Treatment Diabetic Retinopathy Study',0.046685332,'Early Treatment Diabetic Retinopathy Study',0.046685332
16,35309190,Evaluation of the Predictors for Unfavorable Clinical Outcomes of Degenerative Lumbar Spondylolisthesis After Lumbar Interbody Fusion Using Machine Learning.,"An increasing number of geriatric patients are suffering from degenerative lumbar spondylolisthesis (DLS) and need a lumbar interbody fusion (LIF) operation to alleviate the symptoms. Our study was performed aiming to determine the predictors that contributed to unfavorable clinical efficacy among patients with DLS after LIF according to the support vector machine (SVM) algorithm.A total of 157 patients with single-segment DLS were recruited and performed LIF in our hospital from January 1, 2015 to October 1, 2020. Postoperative functional evaluation, including ODI and VAS were, performed, and endpoint events were defined as significant relief of symptom in the short term (2 weeks postoperatively) and long term (1 year postoperatively). General patient information and radiological data were selected and analyzed for statistical relationships with the endpoint events. The SVM method was used to establish the predictive model.Among the 157 consecutive patients, a postoperative unfavorable clinical outcome was reported in 26 patients (16.6%) for a short-term cohort and nine patients (5.7%) for a long-term cohort. Based on univariate and multivariate regression analysis, increased disc height (DH), enlarged facet angle (FA), and raised lateral listhesis (LLS) grade were confirmed as the risk factors that hindered patients' short-term functional recovery. Furthermore, long-term functional recovery was significantly associated with DH alone. In combination with the SVM method, a prediction model with consistent and superior predictive performance was achieved with average and maximum areas under the receiver operating characteristic curve (AUC) of 0.88 and 0.96 in the short-term cohort, and 0.78 and 0.82 in the long-term cohort. The classification results of the discriminant analysis were demonstrated by the confusion matrix.The proposed SVM model indicated that DH, FA, and LLS were statistically associated with a clinical outcome of DLS. These results may provide optimized clinical strategy for treatment of DLS.",'degenerative lumbar spondylolisthesis',0.679110467,'157',0.351032406,'to determine the predictors that contributed to unfavorable clinical efficacy',0.314505175,'radiological data',0.057193052,"'2015 to October 1, 2020'",0.001316611,'our hospital',0.311041906,'General patient information and radiological data',0.063237451,'General patient information and radiological data',0.063237451
17,35308365,Screening of Long Non-coding RNAs Biomarkers for the Diagnosis of Tuberculosis and Preliminary Construction of a Clinical Diagnosis Model.,"Pathogenic testing for tuberculosis (TB) is not yet sufficient for early and differential clinical diagnosis; thus, we investigated the potential of screening long non-coding RNAs (lncRNAs) from human hosts and using machine learning (ML) algorithms combined with electronic health record (EHR) metrics to construct a diagnostic model.A total of 2,759 subjects were included in this study, including 12 in the primary screening cohort [7 TB patients and 5 healthy controls (HCs)] and 2,747 in the selection cohort (798 TB patients, 299 patients with non-TB lung disease, and 1,650 HCs). An Affymetrix HTA2.0 array and qRT-PCR were applied to screen new specific lncRNA markers for TB in individual nucleated cells from host peripheral blood. A ML algorithm was established to combine the patients' EHR information and lncRNA data <i>via</i> logistic regression models and nomogram visualization to differentiate PTB from suspected patients of the selection cohort.Two differentially expressed lncRNAs (TCONS_00001838 and n406498) were identified (<i>p</i> < 0.001) in the selection cohort. The optimal model was the ""LncRNA + EHR"" model, which included the above two lncRNAs and eight EHR parameters (age, hemoglobin, lymphocyte count, gamma interferon release test, weight loss, night sweats, polymorphic changes, and calcified foci on imaging). The best model was visualized by a nomogram and validated, and the accuracy of the ""LncRNA + EHR"" model was 0.79 (0.75-0.82), with a sensitivity of 0.81 (0.78-0.86), a specificity of 0.73 (0.64-0.79), and an area under the ROC curve (AUC) of 0.86. Furthermore, the nomogram showed good compliance in predicting the risk of TB and a higher net benefit than the ""EHR"" model for threshold probabilities of 0.2-1.LncRNAs TCONS_00001838 and n406498 have the potential to become new molecular markers for PTB, and the nomogram of ""LncRNA + EHR"" model is expected to be effective for the early clinical diagnosis of TB.",'tuberculosis (TB)',0.569567025,"'2,759'",0.744044811,'Pathogenic testing for tuberculosis (TB) is not yet sufficient for early and differential clinical diagnosis',0.205105864,'electronic health record',0.484962597,"'2,759 subjects were included in this study, including 12 in the primary screening cohort [7 TB patients and 5 healthy controls (HCs)] and 2,747 in the selection cohort (798 TB patients, 299 patients with non-TB lung disease, and 1,650 HCs). An Affymetrix HTA2.0 array and qRT-PCR were applied to screen new specific lncRNA markers for TB in individual nucleated cells from host peripheral blood. A ML algorithm was established to combine the patients' EHR information and lncRNA data <i>via</i> logistic regression models and nomogram visualization to differentiate PTB'",0.000862107,'electronic health record',0.001246909,'electronic health record',0.3074193,'electronic health record',0.3074193
18,35308952,Characterizing Brain Signals for Epileptic Pre-ictal Signal Classification.,"Epilepsy is a kind of neurological disorder characterized by recurrent epileptic seizures. While it is crucial to characterize pre-ictal brain electrical activities, the problem to this day still remains computationally challenging. Using brain signal acquisition and advances in deep learning technology, we aim to classify pre-ictal signals and characterize the brain waveforms of patients with epilepsy during the pre-ictal period. We develop a novel machine learning model called Pre-ictal Signal Classification (PiSC) for pre-ictal signal classification and for identifying brain waveform patterns critical for seizure onset early detection. In PiSC, a unique preprocessing procedure is developed to convert the stereo-electroencephalography (sEEG) signals to data blocks ready for pre-ictal signal classification. Also, a novel deep learning framework is developed to integrate deep neural networks and meta-learning to effectively mitigate patient-to-patient variances as well as fine-tuning a trained classification model for new patients. The unique network architecture ensures model stability and generalization in sEEG data modeling. The experimental results on a real-world patient dataset show that PiSC improved the accuracy and F1 score by 10% compared with the existing models. Two types of sEEG patterns were discovered to be associated with seizure development in nocturnal epileptic patients.",'Epilepsy',0.746836215,'real-world',0.055026524,'identifying brain waveform patterns critical for seizure onset early detection',0.203411866,'stereo-electroencephalography',0.650402859,'real-world',0.010417976,'real-world patient dataset',0.001623125,'real-world patient dataset',0.394589171,'real-world patient dataset',0.394589171
19,35308550,Prediction of Endometrial Carcinoma Using the Combination of Electronic Health Records and an Ensemble Machine Learning Method.,"Endometrial carcinoma (EC) is a common cause of cancer death in women, and having an early accurate prediction model to identify this disease is crucial. The aim of this study was to develop a new machine learning (ML) model-based diagnostic prediction model for EC. We collected data from consecutive patients between November 2012 and January 2021 at tertiary hospitals in central China. Inclusion criteria included women undergoing endometrial biopsy, dilation and curettage, or hysterectomy. A total of 9 features, including patient demographics, vital signs, and laboratory and ultrasound results, were selected in the final analysis. This new model was combined with three top optimal ML methods, namely, logistic regression, gradient-boosted decision tree, and random forest. A total of 1,922 patients were eligible for final analysis and modeling. The ensemble model, called TJHPEC, was validated in an internal validation cohort and two external validation cohorts. The results showed that the AUC values were 0.9346, 0.8341, and 0.8649 for the prediction of total EC and 0.9347, 0.8073, and 0.871 for prediction of stage I EC. Nine clinical features were confirmed to be highly related to the prediction of EC in TJHPEC. In conclusion, our new model may be accurate for identifying EC, especially in the early stage, in the general population of central China.",'Endometrial carcinoma',0.651852563,"'1,922'",0.536611438,'to develop a new machine learning (ML) model-based diagnostic prediction model for EC',0.513923615,"'patient demographics, vital signs, and laboratory and ultrasound results'",0.322288126,'China',0.577063575,'tertiary hospitals in central China',0.381501526,'tertiary hospitals in central China',0.266541451,'tertiary hospitals in central China',0.266541451
20,35310177,Performance Analysis of Deep Learning Models for Binary Classification of Cancer Gene Expression Data.,"The classification of patients as cancer and normal patients by applying the computational methods on their gene expression profiles is an extremely important task. Recently, deep learning models, mainly multilayer perceptron and convolutional neural networks, have gained popularity for being applied on this type of datasets. This paper aims to analyze the performance of deep learning models on different types of cancer gene expression datasets as no such consolidated work is available. For this purpose, three deep learning models along with two feature selection method and four cancer gene expression datasets have been considered. It has resulted in a total of 24 different combinations to be analyzed. Out of four datasets, two are imbalanced and two are balanced in terms of number of normal and cancer samples. Experimental results show that the deep learning models have performed well in terms of true positive rate, precision, F1-score, and accuracy.",'cancer',0.260144338,'four',0.268676318,'analyze the performance of deep learning models on different types of cancer gene expression datasets',0.232972234,'cancer gene expression datasets',0.427741349,'cancer gene expression datasets',0.000614379,"'cancer gene expression datasets as no such consolidated work is available. For this purpose, three deep learning models along with two feature selection method and four cancer gene expression datasets'",0.002089432,'cancer gene expression datasets',0.063825732,'cancer gene expression datasets',0.063825732
21,35310201,MRI Brain Tumor Image Classification Using a Combined Feature and Image-Based Classifier.,"Brain tumor classification plays a niche role in medical prognosis and effective treatment process. We have proposed a combined feature and image-based classifier (CFIC) for brain tumor image classification in this study. Carious deep neural network and deep convolutional neural networks (DCNN)-based architectures are proposed for image classification, namely, actual image feature-based classifier (AIFC), segmented image feature-based classifier (SIFC), actual and segmented image feature-based classifier (ASIFC), actual image-based classifier (AIC), segmented image-based classifier (<i>SIC</i>), actual and segmented image-based classifier (ASIC), and finally, CFIC. The Kaggle Brain Tumor Detection 2020 dataset has been used to train and test the proposed classifiers. Among the various classifiers proposed, the CFIC performs better than all other proposed methods. The proposed CFIC method gives significantly better results in terms of sensitivity, specificity, and accuracy with 98.86, 97.14, and 98.97%, respectively, compared with the existing classification methods.",'Brain tumor',0.615662068,'Kaggle Brain Tumor Detection 2020',0.034584015,'Brain tumor classification plays a niche role in medical prognosis and effective treatment process',0.412464783,'brain tumor image',0.273643695,'Kaggle Brain Tumor Detection 2020',0.009235172,'Kaggle Brain Tumor Detection 2020',0.022312356,'Kaggle Brain Tumor Detection 2020',0.58867383,'Kaggle Brain Tumor Detection 2020',0.58867383
22,35310011,CHS-Net: A Deep Learning Approach for Hierarchical Segmentation of COVID-19 via CT Images.,"The pandemic of novel severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) also known as COVID-19 has been spreading worldwide, causing rampant loss of lives. Medical imaging such as computed tomography (CT), X-ray, etc., plays a significant role in diagnosing the patients by presenting the visual representation of the functioning of the organs. However, for any radiologist analyzing such scans is a tedious and time-consuming task. The emerging deep learning technologies have displayed its strength in analyzing such scans to aid in the faster diagnosis of the diseases and viruses such as COVID-19. In the present article, an automated deep learning based model, COVID-19 hierarchical segmentation network (CHS-Net) is proposed that functions as a semantic hierarchical segmenter to identify the COVID-19 infected regions from lungs contour via CT medical imaging using two cascaded residual attention inception U-Net (RAIU-Net) models. RAIU-Net comprises of a residual inception U-Net model with spectral spatial and depth attention network (SSD) that is developed with the contraction and expansion phases of depthwise separable convolutions and hybrid pooling (max and spectral pooling) to efficiently encode and decode the semantic and varying resolution information. The CHS-Net is trained with the segmentation loss function that is the defined as the average of binary cross entropy loss and dice loss to penalize false negative and false positive predictions. The approach is compared with the recently proposed approaches and evaluated using the standard metrics like accuracy, precision, specificity, recall, dice coefficient and Jaccard similarity along with the visualized interpretation of the model prediction with GradCam++ and uncertainty maps. With extensive trials, it is observed that the proposed approach outperformed the recently proposed approaches and effectively segments the COVID-19 infected regions in the lungs.",'COVID-19',0.411657438,'two cascaded residual attention inception U-Net (RAIU-Net) models',0.005653041,'identify the COVID-19 infected regions from lungs contour via CT medical imaging',0.19273825,'CT medical imaging',0.761763155,'worldwide',0.006838002,'CT medical imaging',0.000518786,'CT medical imaging',0.040625557,'CT medical imaging',0.040625557
23,35309200,Early-Stage Alzheimer's Disease Prediction Using Machine Learning Models.,"Alzheimer's disease (AD) is the leading cause of dementia in older adults. There is currently a lot of interest in applying machine learning to find out metabolic diseases like Alzheimer's and Diabetes that affect a large population of people around the world. Their incidence rates are increasing at an alarming rate every year. In Alzheimer's disease, the brain is affected by neurodegenerative changes. As our aging population increases, more and more individuals, their families, and healthcare will experience diseases that affect memory and functioning. These effects will be profound on the social, financial, and economic fronts. In its early stages, Alzheimer's disease is hard to predict. A treatment given at an early stage of AD is more effective, and it causes fewer minor damage than a treatment done at a later stage. Several techniques such as Decision Tree, Random Forest, Support Vector Machine, Gradient Boosting, and Voting classifiers have been employed to identify the best parameters for Alzheimer's disease prediction. Predictions of Alzheimer's disease are based on Open Access Series of Imaging Studies (OASIS) data, and performance is measured with parameters like Precision, Recall, Accuracy, and F1-score for ML models. The proposed classification scheme can be used by clinicians to make diagnoses of these diseases. It is highly beneficial to lower annual mortality rates of Alzheimer's disease in early diagnosis with these ML algorithms. The proposed work shows better results with the best validation average accuracy of 83% on the test data of AD. This test accuracy score is significantly higher in comparison with existing works.",'Alzheimer's disease',0.450084686,'Open Access Series of Imaging Studies',0.009562194,"'Alzheimer's disease (AD) is the leading cause of dementia in older adults. There is currently a lot of interest in applying machine learning to find out metabolic diseases like Alzheimer's and Diabetes that affect a large population of people around the world. Their incidence rates are increasing at an alarming rate every year. In Alzheimer's disease, the brain is affected by neurodegenerative changes. As our aging population increases, more and more individuals, their families, and healthcare will experience diseases that affect memory and functioning'",0.058461171,'Open Access Series of Imaging Studies',0.521123603,'around the world',0.001818446,'Open Access Series of Imaging Studies (OASIS) data',0.000185331,'Open Access Series of Imaging Studies (OASIS)',0.503261641,'Open Access Series of Imaging Studies (OASIS)',0.503261641
24,35306830,Predicting New-Onset Psychiatric Disorders Throughout the COVID-19 Pandemic: A Machine Learning Approach.,"The investigators estimated new-onset psychiatric disorders (PsyDs) throughout the COVID-19 pandemic in Italian adults without preexisting PsyDs and developed a machine learning (ML) model predictive of at least one new-onset PsyD in subsequent independent samples.Data were from the first (May 18-June 20, 2020) and second (September 15-October 20, 2020) waves of an ongoing longitudinal study, based on a self-reported online survey. Provisional diagnoses of PsyDs (PPsyDs) were assessed via DSM-based screening tools to maximize assessment specificity. Gradient-boosted decision trees as an ML modeling technique and the SHapley Additive exPlanations technique were applied to identify each variable's contribution to the model.From the original sample of 3,532 participants, the final sample included 500 participants in the first wave and 236 in the second. Some 16.0% of first-wave participants and 18.6% of second-wave participants met criteria for at least one new-onset PPsyD. The final best ML predictive model, trained on the first wave, displayed a sensitivity of 70% and a specificity of 73% when tested on the second wave. The following variables made the largest contributions: low resilience, being an undergraduate student, and being stressed by pandemic-related conditions. Living alone and having ceased physical activity contributed to a lesser extent.Substantial rates of new-onset PPsyDs emerged among Italians throughout the pandemic, and the ML model exhibited moderate predictive performance. Results highlight modifiable vulnerability factors that are suitable for targeting by public campaigns or interventions to mitigate the pandemic's detrimental effects on mental health.",'COVID-19 pandemic',0.39894487,"'3,532 participants, the final sample included 500 participants in the first wave and 236 in the second'",0.248883575,"'Data were from the first (May 18-June 20, 2020) and second (September 15-October 20, 2020) waves of an ongoing longitudinal study, based on a self-reported online survey'",0.197027639,'self-reported online survey',0.640579611,'Italian',0.592859626,"'the first (May 18-June 20, 2020) and second (September 15-October 20, 2020) waves of an ongoing longitudinal study'",0.00297664,'a self-reported online survey',0.364160582,'a self-reported online survey',0.364160582
25,35305690,The differential diagnosis of IgG4-related disease based on machine learning.,"To eliminate the disparity and maldistribution of physicians and medical specialty services, the development of diagnostic support for rare diseases using artificial intelligence is being promoted. Immunoglobulin G4 (IgG4)-related disease (IgG4-RD) is a rare disorder often requiring special knowledge and experience to diagnose. In this study, we investigated the possibility of differential diagnosis of IgG4-RD based on basic patient characteristics and blood test findings using machine learning.Six hundred and two patients with IgG4-RD and 204 patients with non-IgG4-RD that needed to be differentiated who visited the participating institutions were included in the study. Ten percent of the subjects were randomly excluded as a validation sample. Among the remaining cases, 80% were used as training samples, and the remaining 20% were used as test samples. Finally, validation was performed on the validation sample. The analysis was performed using a decision tree and a random forest model. Furthermore, a comparison was made between conditions with and without the serum IgG4 concentration. Accuracy was evaluated using the area under the receiver-operating characteristic (AUROC) curve.In diagnosing IgG4-RD, the AUROC curve values of the decision tree and the random forest method were 0.906 and 0.974, respectively, when serum IgG4 levels were included in the analysis. Excluding serum IgG4 levels, the AUROC curve value of the analysis by the random forest method was 0.925.Based on machine learning in a multicenter collaboration, with or without serum IgG4 data, basic patient characteristics and blood test findings alone were sufficient to differentiate IgG4-RD from non-IgG4-RD.",'Immunoglobulin G4 (IgG4)-related disease',0.415532216,'Six hundred and two',0.798674911,'differential diagnosis of IgG4-RD based on basic patient characteristics and blood test findings',0.215170756,'basic patient characteristics and blood test findings',0.449588209,'Six hundred and two patients with IgG4-RD and 204 patients with non-IgG4-RD that needed to be differentiated who visited the participating institutions',0.001599159,'Six hundred and two patients with IgG4-RD and 204 patients with non-IgG4-RD that needed to be differentiated who visited the participating institutions',0.007740015,'Six hundred and two patients with IgG4-RD and 204 patients with non-IgG4-RD that needed to be differentiated who visited the participating institutions',0.046994509,'Six hundred and two patients with IgG4-RD and 204 patients with non-IgG4-RD that needed to be differentiated who visited the participating institutions',0.046994509
26,35306044,Detecting and predicting visually induced motion sickness with physiological measures in combination with machine learning techniques.,"Visually induced motion sickness (VIMS) is a common sensation when using visual displays such as smartphones or Virtual Reality. In the present study, we investigated whether Machine Learning (ML) techniques in combination with physiological measures (ECG, EDA, EGG, respiration, body and skin temperature, and body movements) could be used to detect and predict the severity of VIMS in real-time, minute-by-minute. A total of 43 healthy younger adults (25 female) were exposed to a 15-minute VIMS-inducing video. VIMS severity was subjectively measured during the video using the Fast Motion Sickness Scale (FMS) as well as before and after the video using the Simulator Sickness Questionnaire (SSQ). Thirty-one participants (72%) experienced VIMS in the present study. Results showed that changes in facial skin temperature and body movement had the strongest relationship with VIMS. On a minute-by-minute basis, ML models revealed a medium correlation between the physiological measures and the FMS scores. An acceptable classification score distinguishing between sick and non-sick participants was found. Our findings suggest that physiological measures may be useful for measuring VIMS, but that they are not a reliable standalone method to detect or predict VIMS severity in real time.",'Visually induced motion sickness',0.56920439,'43',0.211434364,"'Visually induced motion sickness (VIMS) is a common sensation when using visual displays such as smartphones or Virtual Reality. In the present study, we investigated whether Machine Learning (ML) techniques in combination with physiological measures (ECG, EDA, EGG, respiration, body and skin temperature, and body movements) could be used to detect and predict the severity of VIMS in real-time, minute-by-minute'",0.123727344,'physiological measures',0.572357714,"'In the present study, we investigated whether Machine Learning (ML) techniques in combination with physiological measures (ECG, EDA, EGG, respiration, body and skin temperature, and body movements) could be used to detect and predict the severity of VIMS in real-time, minute-by-minute.'",0.001155167,'43',0.002138667,'Simulator Sickness Questionnaire (SSQ)',0.163453795,'Simulator Sickness Questionnaire (SSQ)',0.163453795
27,35306382,Assessment of a novel deep learning-based marker-less motion capture system for gait study.,"Marker-less systems based on digital video cameras and deep learning for gait analysis could have a deep impact in clinical routine. A recently developed system has shown promising results in terms of joint center position but has not been yet evaluated in terms of gait outcomes.How does this novel marker-less system compare to a marker-based reference system in terms of clinically relevant gait parameters?The deep learning method behind the developed marker-less system was trained on a dedicated dataset consisting of forty-one asymptomatic and pathological subjects each performing ten walking trials. The system could estimate the three-dimensional position of seventeen joint centers or keypoints (e.g., neck, shoulders, hip, knee, and ankles). We evaluated the marker-less system against a marker-based system in terms of differences in joint position (Euclidean distance), detection of gait events (e.g., heel strike and toe-off), spatiotemporal parameters (e.g., step length, time), kinematic parameters (e.g., hip and knee extension-flexion), and inter-trial reliability for kinematic parameters.The marker-less system was able to estimate the three-dimensional position of joint centers with a mean difference of 13.1 mm (SD = 10.2 mm). 99% of the estimated gait events were estimated within 10 ms of the corresponding reference values. Estimated spatiotemporal parameters showed zero bias. The mean and standard deviation of the differences of the estimated kinematic parameters varied by parameter (for example, the mean and standard deviation for knee extension flexion angle were -3.0° and 2.7°). Inter-trial reliability of the measured parameters was similar to that of the marker-based references.The developed marker-less system can measure the spatiotemporal parameters within the range of the minimum detectable changes obtained using the marker-based reference system. Moreover, except for hip extension flexion, the system showed promising results in terms of several kinematic parameters.",'pathological',0.089313176,'forty-one',0.658772379,'forty-one asymptomatic and pathological subjects each performing ten walking trials',0.158189446,'digital video cameras',0.478800714,'forty-one asymptomatic and pathological subjects each performing ten walking trials',0.000465915,'forty-one asymptomatic and pathological subjects each performing ten walking trials',0.003579344,'forty-one asymptomatic and pathological subjects each performing ten walking trials',0.390540361,'forty-one asymptomatic and pathological subjects each performing ten walking trials',0.390540361
28,35307554,"Dense, deep learning-based intracranial aneurysm detection on TOF MRI using two-stage regularized U-Net.","The prevalence of unruptured intracranial aneurysms in the general population is high and aneurysms are usually asymptomatic. Their diagnosis is often fortuitous on MRI and might be difficult and time consuming for the radiologist. The purpose of this study was to develop a deep learning neural network tool for automated segmentation of intracranial arteries and automated detection of intracranial aneurysms from 3D time-of-flight magnetic resonance angiography (TOF-MRA).3D TOF-MRA with aneurysms were retrospectively extracted. All were confirmed with angiography. The data were divided into two sets: a training set of 24 examinations and a test set of 25 examinations. Manual annotations of intracranial blood vessels and aneurysms were performed by neuroradiologists. A double convolutional neuronal network based on the U-Net architecture with regularization was used to increase performance despite a small amount of training data. The performance was evaluated for the test set. Subgroup analyses according to size and location of aneurysms were performed.The average processing time was 15 minutes. Overall, the sensitivity and the positive predictive value of the proposed algorithm were 78% (21 of 27; 95% CI: 62-94) and 62% (21 of 34; 95%CI: 46-78) respectively, with 0.5 FP/case. Despite gradual improvement in sensitivity regarding aneurysm size, there was no significant difference of sensitivity detection between subgroups of size and location.This developed tool based on a double CNN with regularization trained with small dataset, enables accurate intracranial arteries segmentation as well as effective aneurysm detection on 3D TOF MRA.",'intracranial aneurysms',0.200207002,'25 examinations',0.258640401,'to develop a deep learning neural network tool for automated segmentation of intracranial arteries and automated detection of intracranial aneurysms from 3D time-of-flight magnetic resonance angiography (TOF-MRA)',0.385691583,'3D time-of-flight magnetic resonance angiography',0.488425404,'a training set of 24 examinations and a test set of 25 examinations',0.000777622,'a training set of 24 examinations and a test set of 25 examinations',0.00232168,'3D time-of-flight magnetic resonance angiography (TOF-MRA)',0.253183201,'3D time-of-flight magnetic resonance angiography (TOF-MRA)',0.253183201
29,35308093,Cross-Camera External Validation for Artificial Intelligence Software in Diagnosis of Diabetic Retinopathy.,"To investigate the applicability of deep learning image assessment software VeriSee DR to different color fundus cameras for the screening of diabetic retinopathy (DR).Color fundus images of diabetes patients taken with three different nonmydriatic fundus cameras, including 477 Topcon TRC-NW400, 459 Topcon TRC-NW8 series, and 471 Kowa nonmyd 8 series that were judged as ""gradable"" by one ophthalmologist were enrolled for validation. VeriSee DR was then used for the diagnosis of referable DR according to the International Clinical Diabetic Retinopathy Disease Severity Scale. Gradability, sensitivity, and specificity were calculated for each camera model.All images (100%) from the three camera models were gradable for VeriSee DR. The sensitivity for diagnosing referable DR in the TRC-NW400, TRC-NW8, and non-myd 8 series was 89.3%, 94.6%, and 95.7%, respectively, while the specificity was 94.2%, 90.4%, and 89.3%, respectively. Neither the sensitivity nor the specificity differed significantly between these camera models and the original camera model used for VeriSee DR development (<i>p</i> = 0.40, <i>p</i> = 0.065, respectively).VeriSee DR was applicable to a variety of color fundus cameras with 100% agreement with ophthalmologists in terms of gradability and good sensitivity and specificity for the diagnosis of referable DR.",'diabetic retinopathy (DR)',0.425928563,'three',0.127188034,'To investigate the applicability of deep learning image assessment software VeriSee DR to different color fundus cameras for the screening of diabetic retinopathy (DR)',0.151135845,'Color fundus images',0.13395758,'diabetes',0.000407005,'diabetes patients',0.000265064,'International Clinical Diabetic Retinopathy Disease Severity Scale',0.045593603,'International Clinical Diabetic Retinopathy Disease Severity Scale',0.045593603
30,35306784,Multivariable Diagnostic Prediction Model to Detect Hormone Secretion Profile From T2W MRI Radiomics with Artificial Neural Networks in Pituitary Adenomas.,"This study aims to develop neural networks to detect hormone secretion profiles in the pituitary adenomas based on T2 weighted magnetic resonance imaging (MRI) radiomics.This retrospective model-development study included a cohort of patients with pituitary adenomas (n=130) from January 2015 to January 2020 in one tertiary center. The mean age was 46.49±13.69 years, and 76/130 (58.46%) were women. Three observers segmented lesions on coronal T2 weighted MRI, and an interrater agreement was evaluated using the Dice coefficient. Predictors were determined as radiomics features (n=851). Feature selection was based on intraclass correlation coefficient, coefficient variance, variance inflation factor, and LASSO regression analysis. Outcomes were identified as 7 hormone secretion profiles [non-functioning pituitary adenoma, growth hormone-secreting adenomas, prolactinomas, adrenocorticotropic hormone-secreting adenomas, pluri-hormonal secreting adenomas (PHA), follicle-stimulating hormone and luteinizing hormone-secreting adenomas, and thyroid-stimulating hormone adenomas]. A multivariable diagnostic prediction model was developed with artificial neural networks (ANN) for 7 outcomes. ANN performance was presented as an area under the receiver operating characteristic curve (AUC) and accepted as successful if the AUC was >0.85 and p-value was <0.01.The performance of the ANN distinguishing prolactinomas from other adenomas was validated (AUC=0.95, p<0.001, sensitivity: 91%, and specificity: 98%). The model distinguishing PHA had the lowest AUC (AUC=0.74 and p<0.001). The AUC values for the other five ANN were >0.85 and p values were <0.001.This study was successful in training neural networks that could differentiate the hormone secretion profile of pituitary adenomas.",'pituitary adenomas',0.447648168,'130',0.525792018,'develop neural networks to detect hormone secretion profiles in the pituitary adenomas',0.385223135,'radiomics',0.524660125,'one tertiary center',0.01205426,'one tertiary center',0.304558486,'one tertiary center',0.301432014,'one tertiary center',0.301432014
31,35310449,COVIR: A virtual rendering of a novel NN architecture O-Net for COVID-19 Ct-scan automatic lung lesions segmentation.,"With the Coronavirus disease 2019 (COVID-19) spread, causing a world pandemic, and recently, the virus new variants continue to appear, making the situation more challenging and threatening, the visual assessment and quantification by expert radiologists have become costly and error-prone. Hence, there is a need to propose a model to predict the COVID-19 cases at the earliest possible to control the disease spread. In order to assist the medical professionals and reduce workload and the time the COVID-19 diagnosis cycle takes, this paper proposes a novel neural network architecture termed as O-Net to automatically segment chest Computerised Tomography Ct-scans infected by COVID-19 with optimised computing power and memory occupation. The O-Net consists of two convolutional autoencoders with an upsampling channel and a downsampling channel. Experimental tests show our proposal's effectiveness and potential, with a dice score of 0.86, pixel accuracy, precision, specificity of 0.99, 0.99, 0.98, respectively. Performance on the external dataset illustrates generalisation and scalability capabilities of the O-Net model to Ct-scan obtained from different scanners with different sizes. The second objective of this work is to introduce our virtual reality platform, COVIR, that visualises and manipulates 3D reconstructed lungs and segmented infected lesions caused by COVID-19. COVIR platform acts as a reading and visualisation support for medical practitioners to diagnose COVID-19 lung infection. The COVIR platform could be used for medical education professional practice and training. It was tested by Thirteen participants (medical staff, researchers, and collaborators), they conclude that the 3D VR visualisation of segmented Ct-Scan provides an aid diagnosis tool for better interpretation.",'Coronavirus disease 2019',0.365269586,'Thirteen',0.008746971,'automatically segment chest Computerised Tomography Ct-scans',0.071478385,'chest Computerised Tomography Ct-scans',0.546649128,'world',0.000390321,'external dataset',0.000143151,'external dataset',0.024783851,'external dataset',0.024783851
32,35308891,Abilities and Disabilities-Applying Machine Learning to Disentangle the Role of Intelligence in Diagnosing Autism Spectrum Disorders.,"Although autism spectrum disorder (ASD) is a relatively common, well-known but heterogeneous neuropsychiatric disorder, specific knowledge about characteristics of this heterogeneity is scarce. There is consensus that IQ contributes to this heterogeneity as well as complicates diagnostics and treatment planning. In this study, we assessed the accuracy of the Autism Diagnostic Observation Schedule (ADOS/2) in the whole and IQ-defined subsamples, and analyzed if the ADOS/2 accuracy may be increased by the application of machine learning (ML) algorithms that processed additional information including the IQ level.The study included 1,084 individuals: 440 individuals with ASD (with a mean IQ level of 3.3 ± 1.5) and 644 individuals without ASD (with a mean IQ level of 3.2 ± 1.2). We applied and analyzed Random Forest (RF) and Decision Tree (DT) to the ADOS/2 data, compared their accuracy to ADOS/2 cutoff algorithms, and examined most relevant items to distinguish between ASD and Non-ASD. In sum, we included 49 individual features, independently of the applied ADOS module.In DT analyses, we observed that for the decision ASD/Non-ASD, solely one to four items are sufficient to differentiate between groups with high accuracy. In addition, in sub-cohorts of individuals with (a) below (IQ level ≥4)/ID and (b) above average intelligence (IQ level ≤ 2), the ADOS/2 cutoff showed reduced accuracy. This reduced accuracy results in (a) a three times higher risk of false-positive diagnoses or (b) a 1.7 higher risk for false-negative diagnoses; both errors could be significantly decreased by the application of the alternative ML algorithms.Using ML algorithms showed that a small set of ADOS/2 items could help clinicians to more accurately detect ASD in clinical practice across all IQ levels and to increase diagnostic accuracy especially in individuals with below and above average IQ level.",'autism spectrum disorder (ASD)',0.435204148,"'1,084'",0.718648911,'assessed the accuracy of the Autism Diagnostic Observation Schedule (ADOS/2) in the whole and IQ-defined subsamples',0.219244082,'ADOS/2',0.264333941,"'The study included 1,084 individuals'",0.002729315,"'1,084 individuals: 440 individuals with ASD (with a mean IQ level of 3.3 ± 1.5) and 644 individuals without ASD (with a mean IQ level of 3.2 ± 1.2). We applied and analyzed Random Forest (RF) and Decision Tree (DT) to the ADOS/2 data'",0.00047489,'Autism Diagnostic Observation Schedule (ADOS/2)',0.150075048,'Autism Diagnostic Observation Schedule (ADOS/2)',0.150075048
33,35308965,Practical Perfusion Quantification in Multispectral Endoscopic Video: Using the Minutes after ICG Administration to Assess Tissue Pathology.,"The wide availability of near infrared light sources in interventional medical imaging stacks enables non-invasive quantification of perfusion by using fluorescent dyes, typically Indocyanine Green (ICG). Due to their often leaky and chaotic vasculatures, intravenously administered ICG perfuses through cancerous tissues differently. We investigate here how a few characteristic values derived from the time series of fluorescence can be used in simple machine learning algorithms to distinguish benign lesions from cancers. These features capture the initial uptake of ICG in the colon, its peak fluorescence, and its early wash-out. By using simple, explainable algorithms we demonstrate, in clinical cases, that sensitivity (specificity) rates of over 95% (95%) for cancer classification can be achieved.",'cancers',0.288395435,'a few characteristic values derived from the time series of fluorescence can be used in simple machine learning algorithms to distinguish benign lesions from cancers',0.016001847,'distinguish benign lesions from cancers',0.3035978,'fluorescence',0.482352525,'benign lesions from cancers',0.000109375,'fluorescence',0.000439137,'interventional medical imaging stacks',0.060774164,'interventional medical imaging stacks',0.060774164
34,35308971,On Predicting Recurrence in Early Stage Non-small Cell Lung Cancer.,"Early detection and mitigation of disease recurrence in non-small cell lung cancer (NSCLC) patients is a nontrivial problem that is typically addressed either by rather generic follow-up screening guidelines, self-reporting, simple nomograms, or by models that predict relapse risk in individual patients using statistical analysis of retrospective data. We posit that machine learning models trained on patient data can provide an alternative approach that allows for more efficient development of many complementary models at once, superior accuracy, less dependency on the data collection protocols and increased support for explainability of the predictions. In this preliminary study, we describe an experimental suite of various machine learning models applied on a patient cohort of 2442 early stage NSCLC patients. We discuss the promising results achieved, as well as the lessons we learned while developing this baseline for further, more advanced studies in this area.",'non-small cell lung cancer',0.490829855,'2442',0.876550168,'Early detection and mitigation of disease recurrence',0.388501063,'retrospective data. We posit that machine learning models trained on patient data',0.217682004,'2442 early stage NSCLC patients',0.000414225,'2442 early stage NSCLC patients',0.000751485,'2442 early stage NSCLC patients',0.173801757,'2442 early stage NSCLC patients',0.173801757
35,35306294,Cardiac age detected by machine learning applied to the surface ECG of healthy subjects: Creation of a benchmark.,"The aim of the present study was to develop a neural network to characterize the effect of aging on the ECG in healthy volunteers. Moreover, the impact of the various ECG features on aging was evaluated.A total of 6228 healthy subjects without structural heart disease were included in this study. A neural network regression model was created to predict age of the subjects based on their ECG; 577 parameters derived from a 12‑lead ECG of each subject were used to develop and validate the neural network; A tenfold cross-validation was performed, using 118 subjects for validation each fold. Using SHapley Additive exPlanations values the impact of the individual features on the prediction of age was determined. Of 6228 subjects tested, 1808 (29%) were females and mean age was 34 years, range 18-75 years. Physiologic age was estimated as a continuous variable with an average error of 6.9 ± 5.6 years (R<sup>2</sup> = 0.72 ± 0.04). The correlation was slightly stronger for men (R<sup>2</sup> = 0.74) than for women (R<sup>2</sup> = 0.66). The most important features on the prediction of physiologic age were T wave morphology indices in leads V4 and V5, and P wave amplitude in leads AVR and II.The application of machine learning to the ECG using a neural network regression model, allows accurate estimation of physiologic cardiac age. This technique could be used to pick up subtle age-related cardiac changes, but also estimate the reversing of these age-associated effects by administered treatments.",'structural heart disease',0.442931324,'6228',0.654967904,'to develop a neural network to characterize the effect of aging on the ECG in healthy volunteers',0.594780862,'ECG',0.550979227,"'The aim of the present study was to develop a neural network to characterize the effect of aging on the ECG in healthy volunteers. Moreover, the impact of the various ECG features on aging'",0.001370583,'577 parameters derived from a 12‑lead ECG',0.003070573,'12‑lead ECG of each subject',0.178183563,'12‑lead ECG of each subject',0.178183563
36,35310199,Optimal Deep Learning Enabled Prostate Cancer Detection Using Microarray Gene Expression.,"Prostate cancer is the main cause of death over the globe. Earlier detection and classification of cancer is highly important to improve patient health. Previous studies utilized statistical and machine learning (ML) techniques for prostate cancer detection. However, several challenges that exist in the investigation process are the existence of high dimensionality data and less number of training samples. Metaheuristic algorithms can be used to resolve the curse of dimensionality and improve the detection rate of artificial intelligence (AI) techniques. With this motivation, this article develops an artificial intelligence based feature selection with deep learning model for prostate cancer detection (AIFSDL-PCD) using microarray gene expression data. The AIFSDL-PCD technique involves preprocessing to enhance the input data quality. In addition, a chaotic invasive weed optimization (CIWO) based feature selection (FS) technique for choosing an optimal subset of features shows the novelty of the work. Moreover, the deep neural network (DNN) model can be applied as a classification model to detect the existence of prostate cancer in the microarray gene expression data. Furthermore, the hyperparameters of the DNN model can be effectively adjusted by the use of RMSprop optimizer. The design of CIWO based FS technique helps for reducing the computational complexity and improve the classification accuracy. The experimental results highlighted the betterment of the AIFSDL-PCD approach on the other techniques with respect to distinct measures.",'Prostate cancer',0.660163492,'less number of training samples',0.126823265,'artificial intelligence based feature selection with deep learning model for prostate cancer detection (AIFSDL-PCD) using microarray gene expression data',0.204576798,'microarray gene expression data',0.654313087,'Prostate cancer is the main cause of death over the globe',0.003111803,'microarray gene expression data',0.003416563,'microarray gene expression data',0.245286115,'microarray gene expression data',0.245286115
37,35309201,COVID-19 Identification System Using Transfer Learning Technique With Mobile-NetV2 and Chest X-Ray Images.,"Diagnosis is a crucial precautionary step in research studies of the coronavirus disease, which shows indications similar to those of various pneumonia types. The COVID-19 pandemic has caused a significant outbreak in more than 150 nations and has significantly affected the wellness and lives of many individuals globally. Particularly, discovering the patients infected with COVID-19 early and providing them with treatment is an important way of fighting the pandemic. Radiography and radiology could be the fastest techniques for recognizing infected individuals. Artificial intelligence strategies have the potential to overcome this difficulty. Particularly, transfer learning MobileNetV2 is a convolutional neural network architecture that can perform well on mobile devices. In this study, we used MobileNetV2 with transfer learning and augmentation data techniques as a classifier to recognize the coronavirus disease. Two datasets were used: the first consisted of 309 chest X-ray images (102 with COVID-19 and 207 were normal), and the second consisted of 516 chest X-ray images (102 with COVID-19 and 414 were normal). We assessed the model based on its sensitivity rate, specificity rate, confusion matrix, and F1-measure. Additionally, we present a receiver operating characteristic curve. The numerical simulation reveals that the model accuracy is 95.8% and 100% at dropouts of 0.3 and 0.4, respectively. The model was implemented using Keras and Python programming.",'coronavirus disease',0.628254354,"'Two datasets were used: the first consisted of 309 chest X-ray images (102 with COVID-19 and 207 were normal), and the second consisted of 516'",0.117229819,'Diagnosis is a crucial precautionary step',0.254267402,'chest X-ray images',0.242777094,'globally',0.002035799,'309 chest X-ray images',0.001269519,'MobileNetV2',0.074081598,'MobileNetV2',0.074081598
38,35310183,Analyzing the Patient Behavior for Improving the Medical Treatment Using Smart Healthcare and IoT-Based Deep Belief Network.,"Patient behavioral analysis is a critical component in treating patients with a variety of issues, with head trauma, neurological disease, and mental illness. The analysis of the patient's behavior aids in establishing the disease's core cause. Patient behavioral analysis has a number of contests that are much more problematic in traditional healthcare. With the advancement of smart healthcare, patient behavior may be simply analyzed. A new generation of information technologies, particularly the Internet of Things (IoT), is being utilized to transform the traditional healthcare system in a variety of ways. The Internet of Things (IoT) in healthcare is a crucial role in offering improved medical facilities to people as well as assisting doctors and hospitals. The proposed system comprises of a variety of medical equipment, such as mobile-based apps and sensors, which is useful in collecting and monitoring the medical information and health data of patient and interact to the doctor via network connected devices. This research may provide key information on the impact of smart healthcare and the Internet of Things in patient beavior and treatment. Patient data are exchanged via the Internet, where it is viewed and analyzed using machine learning algorithms. The deep belief neural network evaluates the patient's particulars from health data in order to determine the patient's exact health state. The developed system proved the average error rate of about 0.04 and ensured accuracy about 99% in analyzing the patient behavior.","'neurological disease, and mental illness'",0.361110881,"'Patient behavioral analysis is a critical component in treating patients with a variety of issues, with head trauma, neurological disease, and mental illness. The analysis of the patient's behavior aids in establishing the disease's core cause. Patient behavioral analysis has a number of contests that are much more problematic in traditional healthcare. With the advancement of smart healthcare'",0.001353998,'key information on the impact of smart healthcare and the Internet of Things in patient beavior and treatment',0.257875733,'health data',0.027805049,'Patient behavioral analysis has a number of contests that are much more problematic in traditional healthcare',0.000196325,'health data',0.001296442,'Internet of Things (IoT)',0.089314427,'Internet of Things (IoT)',0.089314427
39,35308984,Predicting Motor Responsiveness to Deep Brain Stimulation with Machine Learning.,"Deep brain stimulation is a complex movement disorder intervention that requires highly invasive brain surgery. Clinicians struggle to predict how patients will respond to this treatment. To address this problem, we are working toward developing a clinical tool to help neurologists predict deep brain stimulation response. We analyzed a cohort of 105 Parkinson's patients who underwent deep brain stimulation at Vanderbilt University Medical Center. We developed binary and multicategory models for predicting likelihood of motor symptom reduction after undergoing deep brain stimulation. We compared the performances of our best models to predictions made by neurologist experts in movement disorders. The strongest binary classification model achieved a 10-fold cross validation AUC of 0.90, outperforming the best neurologist predictions (0.56). These results are promising for future clinical applications, though more work is necessary to validate these findings in a larger cohort and taking into consideration broader quality of life outcome measures.",'Parkinson's',0.769201249,'105',0.669005811,'We analyzed a cohort of 105 Parkinson's patients who underwent deep brain stimulation at Vanderbilt University Medical Center',0.168268442,'deep brain stimulation',0.285654783,'Vanderbilt University Medical Center',0.001079339,'Vanderbilt University Medical Center',0.521191061,'Vanderbilt University Medical Center',0.601382285,'Vanderbilt University Medical Center',0.601382285
40,35310531,Application of predictive models in boosting power of Alzheimer's disease clinical trials: A post hoc analysis of phase 3 solanezumab trials.,"The ideal participants for Alzheimer's disease (AD) clinical trials would show cognitive decline in the absence of treatment (i.e., placebo arm) and would also respond to the therapeutic intervention.To investigate if predictive models can be an effective tool for identifying and excluding people unlikely to show cognitive decline as an enrichment strategy in AD trials.We used data from the placebo arms of two phase 3, double-blind trials, EXPEDITION and EXPEDITION2. Patients had 18 months of follow-up. Based on the longitudinal data from the placebo arm, we classified participants into two groups: one showed cognitive decline (any negative slope) and the other showed no cognitive decline (slope is zero or positive) on the Alzheimer's Disease Assessment Scale-Cognitive subscale (ADAS-cog). We used baseline data for EXPEDITION to train regression-based classifiers and machine learning classifiers to estimate probability of cognitive decline. Models were applied to EXPEDITION2 data to assess predicted performance in an independent sample. Features used in predictive models included baseline demographics, apolipoprotein E ε4 genotype, neuropsychological scores, functional scores, and volumetric magnetic resonance imaging.In EXPEDITION, 46.3% of placebo-treated patients showed no cognitive decline and the proportion was similar in EXPEDITION2 (45.6%). Models had high sensitivity and modest specificity in both the training (EXPEDITION) and replication samples (EXPEDITION2) for detecting the stable group. Positive predictive value of models was higher than the base prevalence of cognitive decline, and negative predictive value of models were higher than the base rate of participants who had stable cognition.Excluding persons with AD unlikely to decline from the active and placebo arms of clinical trials using predictive models may boost the power of AD trials through selective inclusion of participants expected to decline.",'Alzheimer's disease',0.776915669,"'two phase 3, double-blind trials, EXPEDITION and EXPEDITION2. Patients had 18 months of follow-up'",0.188513651,'To investigate if predictive models can be an effective tool for identifying and excluding people unlikely to show cognitive decline as an enrichment strategy in AD trials',0.303003579,'Patients had 18 months of follow-up',0.166561715,'EXPEDITION and EXPEDITION2',0.008565682,'EXPEDITION2',0.011629367,'EXPEDITION and EXPEDITION2',0.408952236,'EXPEDITION and EXPEDITION2',0.408952236
41,35306870,3D Photography to Quantify the Severity of Metopic Craniosynostosis.,"This study aims to determine the utility of 3D photography for evaluating the severity of metopic craniosynostosis (MCS) using a validated, supervised machine learning (ML) algorithm.This single-center retrospective cohort study included patients who were evaluated at our tertiary care center for MCS from 2016 to 2020 and underwent both head CT and 3D photography within a 2-month period.The analysis method builds on our previously established ML algorithm for evaluating MCS severity using skull shape from CT scans. In this study, we regress the model to analyze 3D photographs and correlate the severity scores from both imaging modalities.14 patients met inclusion criteria, 64.3% male (n = 9). The mean age in years at 3D photography and CT imaging was 0.97 and 0.94, respectively. Ten patient images were obtained preoperatively, and 4 patients did not require surgery. The severity prediction of the ML algorithm correlates closely when comparing the 3D photographs to CT bone data (Spearman correlation coefficient [SCC] r = 0.75; Pearson correlation coefficient [PCC] r = 0.82).The results of this study show that 3D photography is a valid alternative to CT for evaluation of head shape in MCS. Its use will provide an objective, quantifiable means of assessing outcomes in a rigorous manner while decreasing radiation exposure in this patient population.",'metopic craniosynostosis',0.706541151,'14',0.638965309,'determine the utility of 3D photography for evaluating the severity of metopic craniosynostosis',0.30848588,'head CT and 3D photography',0.262164965,'single-center retrospective cohort study included patients who were evaluated at our tertiary care center for MCS from 2016 to 2020',0.001942638,'tertiary care center',0.284344241,'CT scans',0.188391548,'CT scans',0.188391548
42,35308953,A Fusion NLP Model for the Inference of Standardized Thyroid Nodule Malignancy Scores from Radiology Report Text.,"Radiology reports are a rich resource for advancing deep learning applications for medical images, facilitating the generation of large-scale annotated image databases. Although the ambiguity and subtlety of natural language poses a significant challenge to information extraction from radiology reports. Thyroid Imaging Reporting and Data Systems (TI-RADS) has been proposed as a system to standardize ultrasound imaging reports for thyroid cancer screening and diagnosis, through the implementation of structured templates and a standardized thyroid nodule malignancy risk scoring system; however there remains significant variation in radiologist practice when it comes to diagnostic thyroid ultrasound interpretation and reporting. In this work, we propose a computerized approach using a contextual embedding and fusion strategy for the large-scale inference of TI-RADS final assessment categories from narrative ultrasound (US) reports. The proposed model has achieved high accuracy on an internal data set, and high performance scores on an external validation dataset.",'thyroid cancer',0.537309006,'internal data set',0.007061021,'we propose a computerized approach using a contextual embedding and fusion strategy for the large-scale inference of TI-RADS final assessment categories from narrative ultrasound (US) reports',0.07748301,'narrative ultrasound (US)',0.360200748,"'Thyroid Imaging Reporting and Data Systems (TI-RADS) has been proposed as a system to standardize ultrasound imaging reports for thyroid cancer screening and diagnosis, through the implementation of structured templates and a standardized thyroid nodule malignancy risk scoring system; however there remains significant variation in radiologist practice when it comes to diagnostic thyroid ultrasound interpretation and reporting. In this work, we propose a computerized approach using a contextual embedding and fusion strategy for the large-scale inference of TI-RADS final assessment categories from narrative ultrasound (US) reports'",0.000227771,'Radiology reports',0.000764263,'Thyroid Imaging Reporting and Data Systems',0.187685691,'Thyroid Imaging Reporting and Data Systems',0.187685691
43,35308939,Using Radiomics as Prior Knowledge for Thorax Disease Classification and Localization in Chest X-rays.,"Chest X-ray becomes one of the most common medical diagnoses due to its noninvasiveness. The number of chest X-ray images has skyrocketed, but reading chest X-rays still have been manually performed by radiologists, which creates huge burnouts and delays. Traditionally, radiomics, as a subfield of radiology that can extract a large number of quantitative features from medical images, demonstrates its potential to facilitate medical imaging diagnosis before the deep learning era. In this paper, we develop an end-to-end framework, ChexRadiNet, that can utilize the radiomics features to improve the abnormality classification performance. Specifically, ChexRadiNet first applies a light-weight but efficient triplet-attention mechanism to classify the chest X-rays and highlight the abnormal regions. Then it uses the generated class activation map to extract radiomic features, which further guides our model to learn more robust image features. After a number of iterations and with the help of radiomic features, our framework can converge to more accurate image regions. We evaluate the ChexRadiNet framework using three public datasets: NIH ChestX-ray, CheXpert, and MIMIC-CXR. We find that ChexRadiNet outperforms the state-of-the-art on both disease detection (0.843 in AUC) and localization (0.679 in T(IoU) = 0.1). We make the code publicly available at https://github. com/bionlplab/lung_disease_detection_amia2021, with the hope that this method can facilitate the development of automatic systems with a higher-level understanding of the radiological world.",'Chest X-ray',0.127851795,'three',0.062475603,'abnormality classification performance',0.096039027,"'Chest X-ray becomes one of the most common medical diagnoses due to its noninvasiveness. The number of chest X-ray images has skyrocketed, but reading chest X-rays still have been manually performed by radiologists, which creates huge burnouts and delays. Traditionally, radiomics'",0.244018346,'NIH',0.000782447,"'NIH ChestX-ray, CheXpert, and MIMIC-CXR'",0.018813496,"'NIH ChestX-ray, CheXpert, and MIMIC-CXR'",0.517129734,"'NIH ChestX-ray, CheXpert, and MIMIC-CXR'",0.517129734
44,35309968,mTeeth: Identifying Brushing Teeth Surfaces Using Wrist-Worn Inertial Sensors.,"Ensuring that all the teeth surfaces are adequately covered during daily brushing can reduce the risk of several oral diseases. In this paper, we propose the <i>mTeeth</i> model to detect teeth surfaces being brushed with a manual toothbrush in the natural free-living environment using wrist-worn inertial sensors. To unambiguously label sensor data corresponding to different surfaces and capture all transitions that last only milliseconds, we present a lightweight method to detect the micro-event of <i>brushing strokes</i> that cleanly demarcates transitions among brushing surfaces. Using features extracted from brushing strokes, we propose a Bayesian Ensemble method that leverages the natural hierarchy among teeth surfaces and patterns of transition among them. For training and testing, we enrich a publicly-available wrist-worn inertial sensor dataset collected from the natural environment with time-synchronized precise labels of brushing surface timings and moments of transition. We annotate 10,230 instances of brushing on different surfaces from 114 episodes and evaluate the impact of wide between-person and within-person between-episode variability on machine learning model's performance for brushing surface detection.",'oral diseases',0.103532813,"'10,230 instances of brushing on different surfaces from 114 episodes'",0.265362658,"'Ensuring that all the teeth surfaces are adequately covered during daily brushing can reduce the risk of several oral diseases. In this paper, we propose the <i>mTeeth</i> model to detect teeth surfaces being brushed with a manual toothbrush in the natural free-living environment'",0.113381784,'wrist-worn inertial sensors',0.638245076,'natural free-living environment',0.000307393,"'wrist-worn inertial sensors. To unambiguously label sensor data corresponding to different surfaces and capture all transitions that last only milliseconds, we present a lightweight method to detect the micro-event of <i>brushing strokes</i> that cleanly demarcates transitions among brushing surfaces. Using features extracted from brushing strokes, we propose a Bayesian Ensemble method that leverages the natural hierarchy among teeth surfaces and patterns of transition among them. For training and testing, we enrich a publicly-available wrist-worn inertial sensor dataset collected from the natural environment'",0.002754713,'wrist-worn inertial sensor dataset collected from the natural environment',0.320310786,'wrist-worn inertial sensor dataset collected from the natural environment',0.320310786
45,35308977,Prediction of Resuscitation for Pediatric Sepsis from Data Available at Triage.,"Pediatric sepsis imposes a significant burden of morbidity and mortality among children. While the speedy application of existing supportive care measures can substantially improve outcomes, further improvements in delivering that care require tools that go beyond recognizing sepsis and towards predicting its development. Machine learning techniques have great potential as predictive tools, but their application to pediatric sepsis has been stymied by several factors, particularly the relative rarity of its occurrence. We propose an alternate approach which focuses on predicting the provision of resuscitative care, rather than sepsis diagnoses or criteria themselves. Using three years of Emergency Department data from a large academic medical center, we developed a boosted tree model that predicts resuscitation within 6 hours of triage, and significantly outperforms existing rule-based sepsis alerts.",'Pediatric sepsis',0.604788154,'three years',0.363803312,'predicting the provision of resuscitative care',0.26822453,'Emergency Department',0.612141505,'academic medical center',0.000683805,'academic medical center',0.204815015,'academic medical center',0.384743214,'academic medical center',0.384743214
46,35308938,Weak Supervision for Affordable Modeling of Electrocardiogram Data.,"Analysing electrocardiograms (ECGs) is an inexpensive and non-invasive, yet powerful way to diagnose heart disease. ECG studies using Machine Learning to automatically detect abnormal heartbeats so far depend on large, manually annotated datasets. While collecting vast amounts of unlabeled data can be straightforward, the point-by-point annotation of abnormal heartbeats is tedious and expensive. We explore the use of multiple weak supervision sources to learn diagnostic models of abnormal heartbeats via human designed heuristics, without using ground truth labels on individual data points. Our work is among the first to define weak supervision sources directly on time series data. Results show that with as few as six intuitive time series heuristics, we are able to infer high quality probabilistic label estimates for over 100,000 heartbeats with little human effort, and use the estimated labels to train competitive classifiers evaluated on held out test data.",'heart disease',0.680730313,"'over 100,000'",0.129556559,"'Analysing electrocardiograms (ECGs) is an inexpensive and non-invasive, yet powerful way to diagnose heart disease'",0.152247105,'electrocardiograms',0.371348843,"'ECG studies using Machine Learning to automatically detect abnormal heartbeats so far depend on large, manually annotated datasets'",0.000304632,'time series data',0.002190231,'manually annotated datasets',0.083973803,'manually annotated datasets',0.083973803
47,35310099,Alzheimer's Disease Classification Through Imaging Genetic Data With IGnet.,"The application of deep learning techniques to the detection and automated classification of Alzheimer's disease (AD) has recently gained considerable attention. The rapid progress in neuroimaging and sequencing techniques has enabled the generation of large-scale imaging genetic data for AD research. In this study, we developed a deep learning approach, IGnet, for automated AD classification using both magnetic resonance imaging (MRI) data and genetic sequencing data. The proposed approach integrates computer vision (CV) and natural language processing (NLP) techniques, with a deep three-dimensional convolutional network (3D CNN) being used to handle the three-dimensional MRI input and a Transformer encoder being used to manage the genetic sequence input. The proposed approach has been applied to the Alzheimer's Disease Neuroimaging Initiative (ADNI) data set. Using baseline MRI scans and selected single-nucleotide polymorphisms on chromosome 19, it achieved a classification accuracy of 83.78% and an area under the receiver operating characteristic curve (AUC-ROC) of 0.924 with the test set. The results demonstrate the great potential of using multi-disciplinary AI approaches to integrate imaging genetic data for the automated classification of AD.",'Alzheimer's disease',0.721230805,'genetic sequencing data',0.015424726,'automated AD classification',0.146371998,'magnetic resonance imaging',0.635354087,'ADNI)',0.011747609,"'genetic sequencing data. The proposed approach integrates computer vision (CV) and natural language processing (NLP) techniques, with a deep three-dimensional convolutional network (3D CNN) being used to handle the three-dimensional MRI input and a Transformer encoder being used to manage the genetic sequence input. The proposed approach has been applied to the Alzheimer's Disease Neuroimaging Initiative (ADNI)'",0.001768924,'Alzheimer's Disease Neuroimaging Initiative',0.518271044,'Alzheimer's Disease Neuroimaging Initiative',0.518271044
48,35308963,Multi-task deep learning-based survival analysis on the prognosis of late AMD using the longitudinal data in AREDS.,"Age-related macular degeneration (AMD) is the leading cause of vision loss. Some patients experience vision loss over a delayed timeframe, others at a rapid pace. Physicians analyze time-of-visit fundus photographs to predict patient risk of developing late-AMD, the most severe form of AMD. Our study hypothesizes that 1) incorporating historical data improves predictive strength of developing late-AMD and 2) state-of-the-art deep-learning techniques extract more predictive image features than clinicians do. We incorporate longitudinal data from the Age-Related Eye Disease Studies and deep-learning extracted image features in survival settings to predict development of late- AMD. To extract image features, we used multi-task learning frameworks to train convolutional neural networks. Our findings show 1) incorporating longitudinal data improves prediction of late-AMD for clinical standard features, but only the current visit is informative when using complex features and 2) ""deep-features"" are more informative than clinician derived features. We make codes publicly available at https://github.com/bionlplab/AMD_prognosis_amia2021.",'Age-related macular degeneration',0.55413574,'longitudinal data from the Age-Related Eye Disease Studies',0.071979739,'incorporating historical data improves predictive strength of developing late-AMD',0.265562832,'longitudinal data from the Age-Related Eye Disease Studies',0.199106708,'Age-Related Eye Disease Studies',0.00086749,'Age-Related Eye Disease Studies',0.008165098,'Age-Related Eye Disease Studies',0.715925962,'Age-Related Eye Disease Studies',0.715925962
49,35308909,Bias Assessment and Correction in Machine Learning Algorithms: A Use-Case in a Natural Language Processing Algorithm to Identify Hospitalized Patients with Unhealthy Alcohol Use.,"Unhealthy alcohol use represents a major economic burden and cause of morbidity and mortality in the United States. Implementation of interventions for unhealthy alcohol use depends on the availability and accuracy of screening tools. Our group previously applied methods in natural language processing and machine learning to build a classifier for unhealthy alcohol use. In this study, we sought to evaluate and address bias through the use-case of our classifier. We demonstrated the presence of biased unhealthy alcohol use risk underestimation among Hispanic compared to Non-Hispanic White trauma inpatients, 18- to 44-year-old compared to 45 years and older medical/surgical inpatients, and Non-Hispanic Black compared to Non-Hispanic White medical/surgical inpatients. We further showed that intercept, slope, and concurrent intercept and slope recalibration resulted in minimal or no improvements in bias-indicating metrics within these subgroups. Our results exemplify the importance of integrating bias assessment early into the classifier development pipeline.",'Unhealthy alcohol use',0.54886061,'18- to 44-year-old compared to 45 years and older medical/surgical inpatients',0.18255268,'we sought to evaluate and address bias through the use-case of our classifier',0.231665611,'natural language processing and machine learning',0.31109862,'United States',0.210324228,'trauma inpatients',0.004368467,"'natural language processing and machine learning to build a classifier for unhealthy alcohol use. In this study, we sought to evaluate and address bias through the use-case of our classifier. We demonstrated the presence of biased unhealthy alcohol use risk underestimation among Hispanic compared to Non-Hispanic White trauma inpatients'",0.026634593,"'natural language processing and machine learning to build a classifier for unhealthy alcohol use. In this study, we sought to evaluate and address bias through the use-case of our classifier. We demonstrated the presence of biased unhealthy alcohol use risk underestimation among Hispanic compared to Non-Hispanic White trauma inpatients'",0.026634593
50,35309349,Combined Single Cell Transcriptome and Surface Epitope Profiling Identifies Potential Biomarkers of Psoriatic Arthritis and Facilitates Diagnosis <i>via</i> Machine Learning.,"Early diagnosis of psoriatic arthritis (PSA) is important for successful therapeutic intervention but currently remains challenging due, in part, to the scarcity of non-invasive biomarkers. In this study, we performed single cell profiling of transcriptome and cell surface protein expression to compare the peripheral blood immunocyte populations of individuals with PSA, individuals with cutaneous psoriasis (PSO) alone, and healthy individuals. We identified genes and proteins differentially expressed between PSA, PSO, and healthy subjects across 30 immune cell types and observed that some cell types, as well as specific phenotypic subsets of cells, differed in abundance between these cohorts. Cell type-specific gene and protein expression differences between PSA, PSO, and healthy groups, along with 200 previously published genetic risk factors for PSA, were further used to perform machine learning classification, with the best models achieving AUROC ≥ 0.87 when either classifying subjects among the three groups or specifically distinguishing PSA from PSO. Our findings thus expand the repertoire of gene, protein, and cellular biomarkers relevant to PSA and demonstrate the utility of machine learning-based diagnostics for this disease.",'psoriatic arthritis',0.686624706,'30',0.355288886,"'Early diagnosis of psoriatic arthritis (PSA) is important for successful therapeutic intervention but currently remains challenging due, in part, to the scarcity of non-invasive biomarkers. In this study, we performed single cell profiling of transcriptome and cell surface protein expression to compare the peripheral blood immunocyte populations of individuals with PSA, individuals with cutaneous psoriasis (PSO) alone, and healthy individuals'",0.199641116,'single cell profiling of transcriptome and cell surface protein expression',0.665623486,"'single cell profiling of transcriptome and cell surface protein expression to compare the peripheral blood immunocyte populations of individuals with PSA, individuals with cutaneous psoriasis (PSO) alone, and healthy individuals'",0.000855415,"'peripheral blood immunocyte populations of individuals with PSA, individuals with cutaneous psoriasis (PSO) alone, and healthy individuals'",0.000902094,'genetic risk factors',0.078252397,'genetic risk factors',0.078252397
51,35308973,Unsupervised characterization of Major Depressive Disorder medication treatment pathways.,"Learning health systems have the ability to systematically evaluate treatments and treatment pathways. Characterization of treatment pathways can enhance a health system's ability to perform systematic evaluation to improve care quality. In this study we use a Long-Short Term Memory (LSTM) autoencoder model to systematically characterize treatment pathways in a prevalent phenotype-Major Depressive Disorder (MDD). LSTM autoencoder models generate representations of medication treatment pathways that account for temporality and complex interactions. Patients with similar pathways are grouped with K-means clustering. Clusters are characterized by analysis of medication utilization sequences and trends, as well as clinical features, such as demographics, outcomes and comorbidities. Cluster characterization identifies endotypes of MDD including acute MDD, moderate-chronic MDD and severe-chronic, but managed MDD.",'Major Depressive Disorder',0.753425896,'Major Depressive Disorder (MDD)',0.006570593,'systematically characterize treatment pathways in a prevalent phenotype-Major Depressive Disorder (MDD)',0.227053128,'Long-Short Term Memory (LSTM) autoencoder model',0.500291824,'Major Depressive Disorder (MDD)',0.000570859,"'Patients with similar pathways are grouped with K-means clustering. Clusters are characterized by analysis of medication utilization sequences and trends, as well as clinical features, such as demographics, outcomes and comorbidities'",0.000493622,'Major Depressive Disorder (MDD)',0.306492165,'Major Depressive Disorder (MDD)',0.306492165
52,35308958,DL4Burn: Burn Surgical Candidacy Prediction using Multimodal Deep Learning.,"Burn wounds are most commonly evaluated through visual inspection to determine surgical candidacy, taking into account burn depth and individualized patient factors. This process, though cost effective, is subjective and varies by provider experience. Deep learning models can assist in burn wound surgical candidacy with predictions based on the wound and patient characteristics. To this end, we present a multimodal deep learning approach and a complementary mobile application - DL4Burn - for predicting burn surgical candidacy, to emulate the multi-factored approach used by clinicians. Specifically, we propose a ResNet50-based multimodal model and validate it using retrospectively obtained patient burn images, demographic, and injury data.",'Burn wounds',0.439655319,'retrospectively',0.015590617,'predicting burn surgical candidacy',0.165847454,"'patient burn images, demographic, and injury data'",0.33391346,"'burn wound surgical candidacy with predictions based on the wound and patient characteristics. To this end, we present a multimodal deep learning approach and a complementary mobile application - DL4Burn - for predicting burn surgical candidacy, to emulate the multi-factored approach used by clinicians. Specifically, we propose a ResNet50-based multimodal model and validate it using retrospectively obtained patient burn images, demographic, and injury data'",0.00025192,"'retrospectively obtained patient burn images, demographic, and injury data'",0.000861854,'DL4Burn',0.016004735,'DL4Burn',0.016004735
53,35309012,A Machine Learning Pipeline for Accurate COVID-19 Health Outcome Prediction using Longitudinal Electronic Health Records.,"Current COVID-19 predictive models primarily focus on predicting the risk of mortality, and rely on COVID-19 specific medical data such as chest imaging after COVID-19 diagnosis. In this project, we developed an innovative supervised machine learning pipeline using longitudinal Electronic Health Records (EHR) to accurately predict COVID-19 related health outcomes including mortality, ventilation, days in hospital or ICU. In particular, we developed unique and effective data processing algorithms, including data cleaning, initial feature screening, vector representation. Then we trained models using state-of-the-art machine learning strategies combined with different parameter settings. Based on routinely collected EHR, our machine learning pipeline not only consistently outperformed those developed by other research groups using the same set of data, but also achieved similar accuracy as those trained on medical data that were only available after COVID-19 diagnosis. In addition, top risk factors for COVID-19 were identified, and are consistent with epidemiologic findings.",'COVID-19',0.136549219,'routinely collected EHR',0.024179216,"'mortality, ventilation, days in hospital or ICU'",0.240491368,'longitudinal Electronic Health Records',0.450284898,'routinely collected EHR',0.000288112,'routinely collected EHR',0.006970969,'Electronic Health Records',0.340224937,'Electronic Health Records',0.340224937
54,35308915,Comparing Deep Learning and Conventional Machine Learning Models for Predicting Mental Illness from History of Present Illness Notations.,"Mental illness, a serious problem across the globe, requires multi-pronged solutions including effective computational models to predict illness. Mental illness diagnosis is complicated by the pronounced sharing of symptoms and mutual pre-dispositions. Set in this context we offer a systematic comparison of seven deep learning and two conventional machine learning models for predicting mental illness from the history of present illness free-text descriptions in patient records. The models tested include a new architecture CB-MH which ranks best for F1 (0.62) while another attention model is best for F2 (0.71). We also explore model decisions using Integrated Gradients interpretability method which we use to identify key influential features. Overall, the majority of true positives have key features appearing in meaningful contexts. False negatives are most challenging with most key features appearing in unclear contexts. False positives are mostly true positives in actuality as supported by a small-scale clinician-based user judgement study.",'Mental illness',0.702109993,'seven',0.23904293,'predicting mental illness from the history of present illness free-text descriptions in patient records',0.271534413,'free-text descriptions in patient records',0.495199487,'globe',0.002911725,'patient records',0.003907382,'patient records',0.528467238,'patient records',0.528467238
55,35308970,Understanding Heart Failure Patients EHR Clinical Features via SHAP Interpretation of Tree-Based Machine Learning Model Predictions.,"Heart failure (HF) is a major cause of mortality. Accurately monitoring HF progress and adjusting therapies are critical for improving patient outcomes. An experienced cardiologist can make accurate HF stage diagnoses based on combination of symptoms, signs, and lab results from the electronic health records (EHR) of a patient, without directly measuring heart function. We examined whether machine learning models, more specifically the XGBoost model, can accurately predict patient stage based on EHR, and we further applied the SHapley Additive exPlanations (SHAP) framework to identify informative features and their interpretations. Our results indicate that based on structured data from EHR, our models could predict patients' ejection fraction (EF) scores with moderate accuracy. SHAP analyses identified informative features and revealed potential clinical subtypes of HF. Our findings provide insights on how to design computing systems to accurately monitor disease progression of HF patients through continuously mining patients' EHR data.",'Heart failure (HF)',0.616506845,'ejection fraction (EF) scores',0.005774942,"'Accurately monitoring HF progress and adjusting therapies are critical for improving patient outcomes. An experienced cardiologist can make accurate HF stage diagnoses based on combination of symptoms, signs, and lab results from the electronic health records (EHR) of a patient, without directly measuring heart function. We examined whether machine learning models, more specifically the XGBoost model, can accurately predict patient stage based on EHR, and we further applied the SHapley Additive exPlanations (SHAP) framework to identify informative features and their interpretations. Our results indicate that based on structured data from EHR, our models could predict patients' ejection fraction (EF) scores with moderate accuracy'",0.104656532,'electronic health records',0.676862419,"'SHapley Additive exPlanations (SHAP) framework to identify informative features and their interpretations. Our results indicate that based on structured data from EHR, our models could predict patients' ejection fraction (EF) scores with moderate accuracy. SHAP analyses'",0.000301839,'electronic health records',0.009098883,'electronic health records',0.520671189,'electronic health records',0.520671189
56,35308946,Development and Evaluation of an Automated Approach to Detect Weight Abnormalities in Pediatric Weight Charts.,"Inaccurate body weight measures can cause critical safety events in clinical settings as well as hindering utilization of clinical data for retrospective research. This study focused on developing a machine learning-based automated weight abnormality detector (AWAD) to analyze growth dynamics in pediatric weight charts and detect abnormal weight values. In two reference-standard based evaluation of real-world clinical data, the machine learning models showed good capacity for detecting weight abnormalities and they significantly outperformed the methods proposed in literature (p-value<0.05). A deep learning model with bi-directional long short-term memory networks achieved the best predictive performance, with AUCs ≥0.989 across the two datasets. The positive predictive value and sensitivity achieved by the system suggested more than 98% screening effort reduction potential in weight abnormality detection. Consequently, we hypothesize that the AWAD, when fully deployed, holds great potential to facilitate clinical research and healthcare delivery that rely on accurate and reliable weight measures.",'growth dynamics in pediatric weight charts',0.204971418,'two',0.374684021,'to analyze growth dynamics in pediatric weight charts and detect abnormal weight values',0.444176212,'real-world clinical data',0.262317672,'two reference-standard based evaluation of real-world clinical data',0.002169385,'two reference-standard based evaluation of real-world clinical data',0.001259245,'real-world clinical data',0.075065136,'real-world clinical data',0.075065136
57,35308914,Machine Learning Predictability of Clinical Next Generation Sequencing for Hematologic Malignancies to Guide High-Value Precision Medicine.,"Advancing diagnostic testing capabilities such as clinical next generation sequencing methods offer the potential to diagnose, risk stratify, and guide specialized treatment, but must be balanced against the escalating costs of healthcare to identify patient cases most likely to benefit from them. Heme-STAMP (Stanford Actionable Mutation Panel for Hematopoietic and Lymphoid Malignancies) is one such next generation sequencing test. Our objective is to assess how well Heme-STAMP pathological variants can be predicted given electronic health records data available at the time of test ordering. The model demonstrated AUROC 0.74 (95% CI: [0.72, 0.76]) with 99% negative predictive value at 6% specificity. A benchmark for comparison is the prevalence of positive results in the dataset at 58.7%. Identifying patients with very low or very high predicted probabilities of finding actionable mutations (positive result) could guide more precise high-value selection of patient cases to test.",'Hematopoietic and Lymphoid Malignancies',0.318984553,'58.7%',0.012609222,'to assess how well Heme-STAMP pathological variants can be predicted given electronic health records data available at the time of test ordering',0.422621518,'electronic health records',0.613382161,'Stanford Actionable Mutation Panel for Hematopoietic and Lymphoid Malignancies',0.003121835,'Stanford',0.025242179,'electronic health records',0.191394351,'electronic health records',0.191394351
58,35307289,Machine learning-based prediction of upgrading on magnetic resonance imaging targeted biopsy in patients eligible for active surveillance.,"To examine the ability of machine learning methods to predict upgrading of Gleason score on confirmatory magnetic resonance imaging-guided targeted biopsy (MRI-TB) of the prostate in candidates for active surveillance.Our database included 592 patients who received prostate multiparametric magnetic resonance imaging in the evaluation for active surveillance. Upgrading to significant prostate cancer on MRI-TB was defined as upgrading to G 3+4 (definition 1 - DF1) and 4+3 (DF2). Machine learning classifiers were applied on both classification problems DF1 and DF2.Univariate analysis showed that older age and the number of positive cores on pre-MRI-TB were positively correlated with upgrading by DF1 (P-value ≤ 0.05). Upgrading by DF2 was positively correlated with age and the number of positive cores and negatively correlated with body mass index. For upgrading prediction, the AdaBoost model was highly predictive of upgrading by DF1 (AUC 0.952), while for prediction of upgrading by DF2, the Random Forest model had a lower but excellent prediction performance (AUC 0.947).We show that machine learning has the potential to be integrated in future diagnostic assessments for patients eligible for AS. Training our models on larger multi-institutional databases is needed to confirm our results and improve the accuracy of these models' prediction.",'AS',0.100060657,'592',0.566795707,'To examine the ability of machine learning methods to predict upgrading of Gleason score on confirmatory magnetic resonance imaging-guided targeted biopsy (MRI-TB) of the prostate in candidates for active surveillance',0.135545902,'prostate multiparametric magnetic resonance imaging',0.321083248,'multi-institutional databases',0.000542726,'Our database included 592 patients who received prostate multiparametric magnetic resonance imaging in the evaluation for active surveillance',0.001967476,'592 patients who received prostate multiparametric magnetic resonance imaging in the evaluation for active surveillance',0.229024954,'592 patients who received prostate multiparametric magnetic resonance imaging in the evaluation for active surveillance',0.229024954
59,35309006,Learning Predictive and Interpretable Timeseries Summaries from ICU Data.,"Machine learning models that utilize patient data across time (rather than just the most recent measurements) have increased performance for many risk stratification tasks in the intensive care unit. However, many of these models and their learned representations are complex and therefore difficult for clinicians to interpret, creating challenges for validation. Our work proposes a new procedure to learn summaries of clinical timeseries that are both predictive and easily understood by humans. Specifically, our summaries consist of simple and intuitive functions of clinical data (e.g. ""falling mean arterial pressure""). Our learned summaries outperform traditional interpretable model classes and achieve performance comparable to state-of-the-art deep learning models on an in-hospital mortality classification task.",'intensive care unit',0.225701407,'falling mean arterial pressure',0.005053879,'in-hospital mortality classification task',0.131390583,'clinical timeseries',0.284664348,'mortality',0.000467323,'intensive care unit',0.005270453,"'falling mean arterial pressure""'",0.097141638,"'falling mean arterial pressure""'",0.097141638
60,35316192,Data-driven Real-time Magnetic Tracking Applied to Myokinetic Interfaces.,"A new concept of human-machine interface to control hand prostheses based on magnetic tracking, the myokinetic control interface, has been recently proposed. Control signals are the retrieved displacements of multiple magnets implanted in the limb residual muscles following contraction. In previous works, magnets localization has been achieved following an optimization procedure to find an approximate solution to an analytical model. To simplify and speed up the localization problem, here we employ a data-driven strategy to create mathematical models, which can translate measured magnetic information to desired commands for active prosthetic devices. We employed machine learning models, namely linear and radial basis functions artificial neural networks, due to their inherently parallel architecture. They were developed offline and then implemented on field-programmable gate arrays using customized floating-point operators. We optimized computational precision, execution time, hardware, and energy consumption, as they are essential features in the context of wearable devices. When used to track a single magnet in an anatomical mockup of the human forearm, the proposed data-driven strategy achieved a tracking accuracy of 720m 95% of the time and latency of 12.07s. In addition, the proposed system architecture is expected to require a low energy consumption compared to previous solutions. The outcomes of this work encourage further research on improving the devised methods to deal with multiple magnets simultaneously.",'contraction',0.01786775,'single magnet in an anatomical mockup of the human forearm',0.002605936,'When used to track a single magnet in an anatomical mockup of the human forearm',0.057430176,'measured magnetic information',0.422845855,'When used to track a single magnet in an anatomical mockup of the human forearm',0.000416924,"'machine learning models, namely linear and radial basis functions artificial neural networks, due to their inherently parallel architecture. They were developed offline and then implemented on field-programmable gate arrays using customized floating-point operators. We optimized computational precision, execution time, hardware, and energy consumption, as they are essential features in the context of wearable devices. When used to track a single magnet in an anatomical mockup of the human forearm'",0.000506747,'anatomical mockup of the human forearm',0.05489485,'anatomical mockup of the human forearm',0.05489485
61,35314576,[Discrimination of Chin Electromyography in REM Sleep Behavior Disorder Using Deep Learning].,"The confirmation of abnormal behavior during video monitoring in polysomnography (PSG) and the frequency of rapid eye movement (REM) sleep without atonia (RWA) during REM sleep based on physiological indicators are essential diagnostic criteria for the diagnosis of REM sleep behavior disorder (RBD). However, no clear criteria have been established for the determination of the tonic and phasic activities of RWA. In this study, we investigated an RWA decision program that simulates visual inspection by clinical laboratory technicians.We used the measurement data of 25 men and women (average age±standard deviation: 72.7±1.7 years) who visited the Sleep Treatment Center for PSG inspection due to suspected RBD. The chin electromyography (EMG) during REM sleep was divided into 30 s intervals, and RWA decisions were made on the basis of visual inspection by a clinical laboratory technician. We compared and investigated two machine-learning methods namely support vector machine (SVM) and convolutional neural network (CNN) for RWA decisions.When comparing SVM and CNN, the highest discrimination accuracy for RWA decisions was obtained when using the average rectified value (ARV) processed chin EMG images using CNN as a feature. We also estimated the prevalence of RBD on the basis of the Mahalanobis distance measure using the frequency of occurrence of both tonic and phasic activities calculated from a total of 25 subjects in the patient and healthy groups. Consequently, estimation of RBD prevalence using CNN resulted in misclassification of none of the subjects in the patient group and two subjects in the healthy group.In this study, we investigated the automatic analysis of PSG results focusing on RBD, which is a parasomnia. As a result, there were no misclassifications of patients in the 25 subjects in the patient or healthy groups based on the estimates of RBD prevalence using CNN. The prevalence estimation based on our proposed automated algorithm is considered effective for the primary screening for RBD.",'REM sleep behavior disorder',0.705159843,'25',0.611917093,'we investigated an RWA decision program that simulates visual inspection by clinical laboratory technicians',0.206435852,'PSG',0.557019264,'We used the measurement data of 25 men and women (average age±standard deviation: 72.7±1.7 years) who visited the Sleep Treatment Center for PSG inspection due to suspected RBD',0.001276436,'Sleep Treatment Center',0.11307146,'Sleep Treatment Center',0.467851341,'Sleep Treatment Center',0.467851341
62,35320098,Deep Learning-based Classification of Reduced Lung Ultrasound Data from COVID-19 Patients.,"The application of Lung Ultrasound (LUS) imaging for the diagnosis of lung diseases has recently captured significant interest within the research community. With the ongoing COVID-19 pandemic, many efforts have been made to evaluate LUS data. A four-level scoring system has been introduced to semi-quantitatively assess the state of the lung, classifying the patients. Various Deep Learning (DL) algorithms supported with clinical validations have been proposed to automate the stratification process. However, no work has been done to evaluate the impact on the automated decision by varying pixel resolution and bit depth, leading to the reduction in size of overall data. This paper evaluates the performance of DL algorithm over LUS data with varying pixel and grey-level resolution. The algorithm is evaluated over a dataset of 448 LUS videos captured from 34 examinations of 20 patients. All videos are resampled by a factor of 2, 3, and 4 of original resolution, and quantized to 128, 64 and 32 levels, followed by score prediction. The results indicate that the automated scoring shows negligible variation in accuracy when it comes to the quantization of intensity levels only. Combined effect of intensity quantization with spatial down-sampling resulted in a prognostic agreement ranging from 73.5% to 82.3%.These results also suggest that such level of prognostic agreement can be achieved over evaluation of data reduced to 32 times of its original size. Thus, laying foundation to efficient processing of data in resource constrained environments.",'lung diseases',0.380580574,'20 patients',0.165238999,'classifying the patients',0.152152088,"'Lung Ultrasound (LUS) imaging for the diagnosis of lung diseases has recently captured significant interest within the research community. With the ongoing COVID-19 pandemic, many efforts have been made to evaluate LUS data. A four-level scoring system has been introduced to semi-quantitatively assess the state of the lung, classifying the patients. Various Deep Learning (DL) algorithms supported with clinical validations have been proposed to automate the stratification process. However, no work has been done to evaluate the impact on the automated decision by varying pixel resolution and bit depth, leading to the reduction in size of overall data. This paper evaluates the performance of DL algorithm over LUS data with varying pixel and grey-level resolution. The algorithm is evaluated over a dataset of 448 LUS videos'",0.395194292,'COVID-19',0.031497527,'COVID-19',0.018632963,'COVID-19 pandemic',0.7088615,'COVID-19 pandemic',0.7088615
63,35318420,Unsupervised machine learning for identifying important visual features through bag-of-words using histopathology data from chronic kidney disease.,"Pathologists use visual classification to assess patient kidney biopsy samples when diagnosing the underlying cause of kidney disease. However, the assessment is qualitative, or semi-quantitative at best, and reproducibility is challenging. To discover previously unknown features which predict patient outcomes and overcome substantial interobserver variability, we developed an unsupervised bag-of-words model. Our study applied to the C-PROBE cohort of patients with chronic kidney disease (CKD). 107,471 histopathology images were obtained from 161 biopsy cores and identified important morphological features in biopsy tissue that are highly predictive of the presence of CKD both at the time of biopsy and in one year. To evaluate the performance of our model, we estimated the AUC and its 95% confidence interval. We show that this method is reliable and reproducible and can achieve 0.93 AUC at predicting glomerular filtration rate at the time of biopsy as well as predicting a loss of function at one year. Additionally, with this method, we ranked the identified morphological features according to their importance as diagnostic markers for chronic kidney disease. In this study, we have demonstrated the feasibility of using an unsupervised machine learning method without human input in order to predict the level of kidney function in CKD. The results from our study indicate that the visual dictionary, or visual image pattern, obtained from unsupervised machine learning can predict outcomes using machine-derived values that correspond to both known and unknown clinically relevant features.",'chronic kidney disease',0.610666528,"'107,471'",0.664628088,"'To discover previously unknown features which predict patient outcomes and overcome substantial interobserver variability, we developed an unsupervised bag-of-words model. Our study applied to the C-PROBE cohort of patients with chronic kidney disease (CKD)'",0.136174597,'histopathology images',0.335682474,'C-PROBE cohort of patients with chronic kidney disease (CKD)',0.004259088,'C-PROBE',0.014926832,'C-PROBE',0.574385762,'C-PROBE',0.574385762
64,35319671,Covid-19 vaccination priorities defined on machine learning.,"Defining priority vaccination groups is a critical factor to reduce mortality rates.We sought to identify priority population groups for covid-19 vaccination, based on in-hospital risk of death, by using Extreme Gradient Boosting Machine Learning (ML) algorithm. We performed a retrospective cohort study comprising 49,197 patients (18 years or older), with RT-PCR-confirmed for covid-19, who were hospitalized in any of the 336 Brazilian hospitals considered in this study, from March 19th, 2020, to March 22nd, 2021. Independent variables encompassed age, sex, and chronic health conditions grouped into 179 large categories. Primary outcome was hospital discharge or in-hospital death. Priority population groups for vaccination were formed based on the different levels of in-hospital risk of death due to covid-19, from the ML model developed by taking into consideration the independent variables. All analysis were carried out in Python programming language (version 3.7) and R programming language (version 4.05).Patients' mean age was of 60.5 ± 16.8 years (mean ± SD), mean in-hospital mortality rate was 17.9%, and the mean number of comorbidities per patient was 1.97 ± 1.85 (mean ± SD). The predictive model of in-hospital death presented area under the Receiver Operating Characteristic Curve (AUC - ROC) equal to 0.80. The investigated population was grouped into eleven (11) different risk categories, based on the variables chosen by the ML model developed in this study.The use of ML for defining population priorities groups for vaccination, based on risk of in-hospital death, can be easily applied by health system managers.",'covid-19',0.317621097,"'49,197'",0.729632676,'Primary outcome was hospital discharge or in-hospital death',0.286672816,'in-hospital risk of death',0.346469328,'Brazilian',0.634881675,'336',0.174721159,'covid-19',0.058110991,'covid-19',0.058110991
65,35317720,Data-independent acquisition mass spectrometry in severe rheumatic heart disease (RHD) identifies a proteomic signature showing ongoing inflammation and effectively classifying RHD cases.,"Rheumatic heart disease (RHD) remains a major source of morbidity and mortality in developing countries. A deeper insight into the pathogenetic mechanisms underlying RHD could provide opportunities for drug repurposing, guide recommendations for secondary penicillin prophylaxis, and/or inform development of near-patient diagnostics.We performed quantitative proteomics using Sequential Windowed Acquisition of All Theoretical Fragment Ion Mass Spectrometry (SWATH-MS) to screen protein expression in 215 African patients with severe RHD, and 230 controls. We applied a machine learning (ML) approach to feature selection among the 366 proteins quantifiable in at least 40% of samples, using the Boruta wrapper algorithm. The case-control differences and contribution to Area Under the Receiver Operating Curve (AUC) for each of the 56 proteins identified by the Boruta algorithm were calculated by Logistic Regression adjusted for age, sex and BMI. Biological pathways and functions enriched for proteins were identified using ClueGo pathway analyses.Adiponectin, complement component C7 and fibulin-1, a component of heart valve matrix, were significantly higher in cases when compared with controls. Ficolin-3, a protein with calcium-independent lectin activity that activates the complement pathway, was lower in cases than controls. The top six biomarkers from the Boruta analyses conferred an AUC of 0.90 indicating excellent discriminatory capacity between RHD cases and controls.These results support the presence of an ongoing inflammatory response in RHD, at a time when severe valve disease has developed, and distant from previous episodes of acute rheumatic fever. This biomarker signature could have potential utility in recognizing different degrees of ongoing inflammation in RHD patients, which may, in turn, be related to prognostic severity.",'Rheumatic heart disease',0.696609974,'215',0.547437459,"'A deeper insight into the pathogenetic mechanisms underlying RHD could provide opportunities for drug repurposing, guide recommendations for secondary penicillin prophylaxis, and/or inform development of near-patient diagnostics'",0.128652882,'Sequential Windowed Acquisition of All Theoretical Fragment Ion Mass Spectrometry',0.388352901,'African',0.358060166,"'215 African patients with severe RHD, and 230 controls'",0.001453473,'Sequential Windowed Acquisition of All Theoretical Fragment Ion Mass Spectrometry (SWATH-MS)',0.091581265,'Sequential Windowed Acquisition of All Theoretical Fragment Ion Mass Spectrometry (SWATH-MS)',0.091581265
66,35319542,Scalable Deep Learning Algorithm to Compute Percent Pulmonary Contusion among Patients with Rib Fractures.,"Pulmonary contusion exists along a spectrum of severity, yet is commonly binarily classified as present or absent. We aimed to develop a deep learning algorithm to automate percent pulmonary contusion computation and exemplify how transfer learning could facilitate large-scale validation. We hypothesized our deep learning algorithm could automate percent pulmonary contusion computation and that greater percent contusion would be associated with higher odds of adverse inpatient outcomes among patients with rib fractures.We evaluated admission-day chest computed tomography (CT) scans of adults aged ≥18 years admitted to our institution with multiple rib fractures and pulmonary contusions (2010-2020). We adapted a pre-trained convolutional neural network that segments 3-dimensional lung volumes and segmented contused lung parenchyma, pulmonary blood vessels, and computed percent pulmonary contusion. Exploratory analysis evaluated associations between percent pulmonary contusion (quartiles) and odds of mechanical ventilation, mortality, and prolonged hospital length-of-stay using multivariable logistic regression. Sensitivity analysis included pulmonary blood vessel volumes during percent contusion computation.A total of 332 patients met inclusion criteria (median 5 rib fractures), among whom 28% underwent mechanical ventilation and 6% died. The study population's median (IQR) percent pulmonary contusion was 4(2-8)%. Compared to the lowest quartile of percent pulmonary contusion, each increasing quartile was associated with higher adjusted odds of undergoing mechanical ventilation (OR[95%CI]: 1.5[1.1-2.1]) and prolonged hospitalization (OR[95%CI]: 1.6[1.1-2.2]), but not with mortality (OR[95%CI]: 1.1 [0.6-2.0]. Findings were similar on sensitivity analysis.We developed a scalable deep learning algorithm to automate percent pulmonary contusion calculating using chest CTs of adults admitted with rib fractures. Open code sharing and collaborative research is needed to validate our algorithm and exploratory analysis at large scale. Transfer learning can help harness the full potential of big data and high-performing algorithms to bring precision medicine to the bedside.IV.",'Pulmonary contusion',0.462843448,'332',0.571766749,'We evaluated admission-day chest computed tomography (CT) scans of adults aged ≥18 years admitted to our institution with multiple rib fractures and pulmonary contusions',0.162088543,'chest computed tomography (CT) scans',0.399354279,'2010-2020',0.001845112,'our institution',0.01558949,'admission-day chest computed tomography (CT) scans of adults aged ≥18 years admitted to our institution with multiple rib fractures and pulmonary contusions (2010-2020)',0.056031235,'admission-day chest computed tomography (CT) scans of adults aged ≥18 years admitted to our institution with multiple rib fractures and pulmonary contusions (2010-2020)',0.056031235
67,35320099,Interpretable machine learning for characterization of focal liver lesions by contrast-enhanced ultrasound.,"This work proposes an interpretable radiomics approach to differentiate between malignant and benign focal liver lesions (FLLs) on contrast-enhanced ultrasound (CEUS). Although CEUS has shown promise for differential FLLs diagnosis, current clinical assessment is performed only by qualitative analysis of the contrast enhancement patterns. Quantitative analysis is often hampered by the unavoidable presence of motion artefacts and by the complex, spatiotemporal nature of liver contrast enhancement, consisting of multiple, overlapping vascular phases. To fully exploit the wealth of information in CEUS, while coping with these challenges, here we propose to combine features extracted by temporal and spatiotemporal analysis in the arterial phase enhancement with spatial features extracted by texture analysis at different time points. Using the extracted features as input, several machine learning classifier are optimized to achieve semi-automatic FLLs characterization, for which there is no need for motion compensation and the only manual input required is the location of a suspicious lesion. Clinical validation on 87 FLLs from 72 patients at risk for HCC showed promising performance, achieving a balanced accuracy of 0.84 in the distinction between benign and malignant lesions. Analysis of feature relevance demonstrates that a combination of spatiotemporal and texture features is needed to achieve the best performance. Interpretation of the most relevant features suggests that aspects related to microvascular perfusion and the microvascular architecture, together with the spatial enhancement characteristics at wash-in and peak enhancement, are important to aid the accurate characterization of FLLs.",'focal liver lesions',0.223779343,'72',0.025152171,'differentiate between malignant and benign focal liver lesions (FLLs) on contrast-enhanced ultrasound (CEUS)',0.225698046,'contrast-enhanced ultrasound',0.409577757,"'This work proposes an interpretable radiomics approach to differentiate between malignant and benign focal liver lesions (FLLs) on contrast-enhanced ultrasound (CEUS). Although CEUS has shown promise for differential FLLs diagnosis, current clinical assessment is performed only by qualitative analysis of the contrast enhancement patterns. Quantitative analysis is often hampered by the unavoidable presence of motion artefacts and by the complex, spatiotemporal nature of liver contrast enhancement, consisting of multiple, overlapping vascular phases. To fully exploit the wealth of information in CEUS, while coping with these challenges, here we propose to combine features extracted by temporal and spatiotemporal analysis in the arterial phase enhancement with spatial features extracted by texture analysis at different time points. Using the extracted features as input, several machine learning classifier are optimized to achieve semi-automatic FLLs characterization, for which there is no need for motion compensation and the only manual input required is the location of a suspicious lesion. Clinical validation on 87 FLLs from 72 patients at risk for HCC'",0.000804188,'87 FLLs from 72 patients at risk for HCC',0.000251363,'radiomics approach to differentiate between malignant and benign focal liver lesions (FLLs) on contrast-enhanced ultrasound (CEUS)',0.025963575,'radiomics approach to differentiate between malignant and benign focal liver lesions (FLLs) on contrast-enhanced ultrasound (CEUS)',0.025963575
68,35320090,Physics-informed neural networks for brain hemodynamic predictions using medical imaging.,"Determining brain hemodynamics plays a critical role in the diagnosis and treatment of various cerebrovascular diseases. In this work, we put forth a physics-informed deep learning framework that augments sparse clinical measurements with one-dimensional (1D) reduced-order model (ROM) simulations to generate physically consistent brain hemodynamic parameters with high spatiotemporal resolution. Transcranial Doppler (TCD) ultrasound is one of the most common techniques in the current clinical workflow that enables noninvasive and instantaneous evaluation of blood flow velocity within the cerebral arteries. However, it is spatially limited to only a handful of locations across the cerebrovasculature due to the constrained accessibility through the skull's acoustic windows. Our deep learning framework uses in vivo real-time TCD velocity measurements at several locations in the brain combined with baseline vessel cross-sectional areas acquired from 3D angiography images and provides high-resolution maps of velocity, area, and pressure in the entire brain vasculature. We validate the predictions of our model against in vivo velocity measurements obtained via four-dimensional (4D) flow magnetic resonance imaging (MRI) scans. We then showcase the clinical significance of this technique in diagnosing cerebral vasospasm (CVS) by successfully predicting the changes in vasospastic local vessel diameters based on corresponding sparse velocity measurements. We show this capability by generating synthetic blood flow data after cerebral vasospasm at various levels of stenosis. Here, we demonstrate that the physics-based deep learning approach can estimate and quantify the subject-specific cerebral hemodynamic variables with high accuracy despite lacking knowledge of inlet and outlet boundary conditions, which is a significant limitation for the accuracy of the conventional purely physics-based computational models.",'cerebral vasospasm',0.44938533,'sparse clinical measurements',0.048237752,'Determining brain hemodynamics plays a critical role in the diagnosis and treatment of various cerebrovascular diseases',0.195791237,'Transcranial Doppler (TCD) ultrasound',0.328785345,"'in vivo real-time TCD velocity measurements at several locations in the brain combined with baseline vessel cross-sectional areas acquired from 3D angiography images and provides high-resolution maps of velocity, area, and pressure in the entire brain vasculature. We validate the predictions of our model against in vivo velocity measurements obtained via four-dimensional (4D) flow magnetic resonance imaging (MRI) scans'",0.000482511,'3D angiography images',0.001362087,'3D angiography images',0.0748768,'3D angiography images',0.0748768
69,35320092,Deep Relation Learning for Regression and Its Application to Brain Age Estimation.,"Most deep learning models for temporal regression directly output the estimation based on single input images, ignoring the relationships between different images. In this paper, we propose deep relation learning for regression, aiming to learn different relations between a pair of input images. Four non-linear relations are considered: ""cumulative relation"", ""relative relation"", ""maximal relation"" and ""minimal relation"". These four relations are learned simultaneously from one deep neural network which has two parts: feature extraction and relation regression. We use an efficient convolutional neural network to extract deep features from the pair of input images and apply a Transformer for relation learning. The proposed method is evaluated on a merged dataset with 6,049 subjects with ages of 0-97 years using 5-fold cross-validation for the task of brain age estimation. The experimental results have shown that the proposed method achieved a mean absolute error (MAE) of 2.38 years, which is lower than the MAEs of 8 other state-of-the-art algorithms with statistical significance (p<0.05) in paired T-test (two-side).",'brain age',0.114806734,"'6,049'",0.557830125,'brain age estimation',0.284976788,'single input images',0.186749727,"'a merged dataset with 6,049 subjects'",0.000772112,"'6,049 subjects'",0.003758923,"'6,049 subjects'",0.221049726,"'6,049 subjects'",0.221049726
70,35314672,Dissociation of tau pathology and neuronal hypometabolism within the ATN framework of Alzheimer's disease.,"Alzheimer's disease (AD) is defined by amyloid (A) and tau (T) pathologies, with T better correlated to neurodegeneration (N). However, T and N have complex regional relationships in part related to non-AD factors that influence N. With machine learning, we assessed heterogeneity in <sup>18</sup>F-flortaucipir vs. <sup>18</sup>F-fluorodeoxyglucose positron emission tomography as markers of T and neuronal hypometabolism (N<sub>M</sub>) in 289 symptomatic patients from the Alzheimer's Disease Neuroimaging Initiative. We identified six T/N<sub>M</sub> clusters with differing limbic and cortical patterns. The canonical group was defined as the T/N<sub>M</sub> pattern with lowest regression residuals. Groups resilient to T had less hypometabolism than expected relative to T and displayed better cognition than the canonical group. Groups susceptible to T had more hypometabolism than expected given T and exhibited worse cognitive decline, with imaging and clinical measures concordant with non-AD copathologies. Together, T/N<sub>M</sub> mismatch reveals distinct imaging signatures with pathobiological and prognostic implications for AD.",'Alzheimer's disease',0.701283187,'289',0.519164816,"'With machine learning, we assessed heterogeneity in <sup>18</sup>F-flortaucipir vs. <sup>18</sup>F-fluorodeoxyglucose positron emission tomography as markers of T and neuronal hypometabolism (N<sub>M</sub>) in 289 symptomatic patients from the Alzheimer's Disease Neuroimaging Initiative'",0.148640543,'fluorodeoxyglucose positron emission tomography',0.383657731,'Alzheimer's Disease Neuroimaging Initiative',0.028946922,'the Alzheimer's Disease Neuroimaging Initiative',0.017011422,'Alzheimer's Disease Neuroimaging Initiative',0.791122198,'Alzheimer's Disease Neuroimaging Initiative',0.791122198
71,35316188,Federated Deep Learning for the Diagnosis of Cerebellar Ataxia: Privacy Preservation and Auto-crafted Feature Extractor.,"Cerebellar ataxia (CA) is concerned with the incoordination of movement caused by cerebellar dysfunction. Movements of the eyes, speech, trunk, and limbs are affected. Conventional machine learning approaches utilizing centralised databases have been used to objectively diagnose and quantify the severity of CA. Although these approaches achieved high accuracy, large scale deployment will require large clinics and raises privacy concerns. In this study, we propose an image transformation-based approach to leverage the advantages of state-of-the-art deep learning with federated learning in diagnosing CA. We use motion capture sensors during the performance of a standard neurological balance test obtained from four geographically separated clinics. The recurrence plot, melspectrogram, and poincaré plot are three transformation techniques explored. Experimental results indicate that the recurrence plot yields the highest validation accuracy (86.69%) with MobileNetV2 model in diagnosing CA. The proposed scheme provides a practical solution with high diagnosis accuracy, removing the need for feature engineering and preserving data privacy for a large-scale deployment.",'Cerebellar ataxia (CA)',0.696219563,'four geographically separated clinics',0.36027205,'We use motion capture sensors during the performance of a standard neurological balance test obtained from four geographically separated clinics',0.244090058,'motion capture sensors',0.825673699,'four geographically separated clinics',0.000771481,'four geographically separated clinics',0.021870914,'centralised databases',0.130000979,'centralised databases',0.130000979
72,35317245,Using decision tree algorithms for estimating ICU admission of COVID-19 patients.,"Coronavirus disease 2019 (COVID-19) outbreak has overwhelmed many healthcare systems worldwide and put them at the edge of collapsing. As intensive care unit (ICU) capacities are limited, deciding on the proper allocation of required resources is crucial. This study aimed to develop and compare models for early predicting ICU admission in COVID-19 patients at the point of hospital admission.Using a single-center registry, we studied the records of 512 COVID-19 patients. First, the most important variables were identified using Chi-square test (at p < 0.01) and logistic regression (with odds ratio at P < 0.05). Second, we trained seven decision tree (DT) algorithms (decision stump (DS), Hoeffding tree (HT), LMT, J-48, random forest (RF), random tree (RT) and REP-Tree) using the selected variables. Finally, the models' performance was evaluated. Furthermore, we used an external dataset to validate the prediction models.Using the Chi-square test, 20 important variables were identified. Then, 12 variables were selected for model construction using logistic regression. Comparing the DT methods demonstrated that J-48 (F-score of 0.816 and AUC of 0.845) had the best performance. Also, the J-48 (F-score = 80.9% and AUC = 0.822) gained the best performance in generalizability using the external dataset.The study results demonstrated that DT algorithms can be used to predict ICU admission requirements in COVID-19 patients based on the first time of admission data. Implementing such models has the potential to inform clinicians and managers to adopt the best policy and get prepare during the COVID-19 time-sensitive and resource-constrained situation.",'Coronavirus disease 2019',0.562708527,'512',0.792520553,'develop and compare models for early predicting ICU admission in COVID-19 patients at the point of hospital admission',0.365025938,'single-center registry',0.629722595,'worldwide',0.047613328,'single-center registry',0.093174826,'a single-center registry',0.615610093,'a single-center registry',0.615610093
73,35313509,Analyzing the Treatment of Patients with Acute Exacerbation of COPD with the Aid of Intelligent Diagnosis Method.,"To observe the clinical efficacy of heat clearing phlegm mixture combined with vibration sputum excretion instrument in the treatment of patients with acute exacerbation of COPD with phlegm-heat obstructing lung, 90 patients with acute exacerbation of COPD are selected and divided into three groups, namely, control group, traditional medicine group, and combined group: the control group (conventional western medicine treatment), traditional medicine group (heat clearing and phlegm mixture), and combined group (heat clearing and phlegm mixture + vibratory sputum excretion instrument) with 30 cases each. All the patients in the three groups were given conventional western medicine treatment. On this basis, the traditional medicine group was given the oral administration of the heat-clearing and phlegm-clearing mixture, and the combined group was given the oral administration of the heat-clearing and phlegm-clearing mixture and the vibratory sputum discharge apparatus. Machine learning is used to classify the patients into three groups based on the characteristics of their biomarkers, physical attributes, and medical history. The TCM syndrome score, blood gas analysis, lung function, and inflammatory indexes of the three groups were compared. TCM syndrome scores of the three groups were all lower than before; both the combined group and the TCM group were better than the control group (<i>P</i> < 0.05). Although the improvement degree of the combined group was better than that of the TCM group, the difference was not statistically significant (<i>P</i> > 0.05). TCM syndrome effect is seen to be 96.55% in the combined group, 89.29% in the TCM group, and 63.33% in the control group. Blood gas analysis is also performed; PO2 and PCO2 of the three groups were significantly improved after treatment. The combination group was superior to the traditional medicine group and the control group (<i>P</i> < 0.05), and the traditional medicine group was superior to the control group (<i>P</i> < 0.05). It is concluded that the combination of heat clearing phlegm mixture and vibration sputum excretion instrument can improve TCM syndrome score, CAT score, blood gas analysis, lung function, and inflammatory indicators in patients with acute exacerbation of COPD with phlegm-heat obstructing lung.",'COPD',0.380025029,'90',0.117393531,'To observe the clinical efficacy of heat clearing phlegm mixture combined with vibration sputum excretion instrument in the treatment of patients with acute exacerbation of COPD with phlegm-heat obstructing lung',0.420641914,'Machine learning',0.664210379,"'90 patients with acute exacerbation of COPD are selected and divided into three groups, namely, control group, traditional medicine group, and combined group: the control group (conventional western medicine treatment), traditional medicine group (heat clearing and phlegm mixture), and combined group (heat clearing and phlegm mixture + vibratory sputum excretion instrument) with 30 cases each. All the patients in the three groups were given conventional western medicine treatment'",0.00052737,'90 patients with acute exacerbation of COPD are selected and divided into three groups',0.000978608,"'Machine learning is used to classify the patients into three groups based on the characteristics of their biomarkers, physical attributes, and medical history'",0.008399974,"'Machine learning is used to classify the patients into three groups based on the characteristics of their biomarkers, physical attributes, and medical history'",0.008399974
74,35311094,A Promising Preoperative Prediction Model for Microvascular Invasion in Hepatocellular Carcinoma Based on an Extreme Gradient Boosting Algorithm.,"The non-invasive preoperative diagnosis of microvascular invasion (MVI) in hepatocellular carcinoma (HCC) is vital for precise surgical decision-making and patient prognosis. Herein, we aimed to develop an MVI prediction model with valid performance and clinical interpretability.A total of 2160 patients with HCC without macroscopic invasion who underwent hepatectomy for the first time in West China Hospital from January 2015 to June 2019 were retrospectively included, and randomly divided into training and a validation cohort at a ratio of 8:2. Preoperative demographic features, imaging characteristics, and laboratory indexes of the patients were collected. Five machine learning algorithms were used: logistic regression, random forest, support vector machine, extreme gradient boosting (XGBoost), and multilayer perception. Performance was evaluated using the area under the receiver operating characteristic curve (AUC). We also determined the Shapley Additive exPlanation value to explain the influence of each feature on the MVI prediction model.The top six important preoperative factors associated with MVI were the maximum image diameter, protein induced by vitamin K absence or antagonist-II, α-fetoprotein level, satellite nodules, alanine aminotransferase (AST)/aspartate aminotransferase (ALT) ratio, and AST level, according to the XGBoost model. The XGBoost model for preoperative prediction of MVI exhibited a better AUC (0.8, 95% confidence interval: 0.74-0.83) than the other prediction models. Furthermore, to facilitate use of the model in clinical settings, we developed a user-friendly online calculator for MVI risk prediction based on the XGBoost model.The XGBoost model achieved outstanding performance for non-invasive preoperative prediction of MVI based on big data. Moreover, the MVI risk calculator would assist clinicians in conveniently determining the optimal therapeutic remedy and ameliorating the prognosis of patients with HCC.",'hepatocellular carcinoma',0.53942214,'2160',0.698233843,'we aimed to develop an MVI prediction model with valid performance and clinical interpretability',0.246946122,"'Preoperative demographic features, imaging characteristics, and laboratory indexes'",0.167595334,'West China Hospital',0.214553148,'West China Hospital',0.863717645,'West China Hospital',0.651992321,'West China Hospital',0.651992321
75,35311133,Accuracy Improvement Method Based on Characteristic Database Classification for IMRT Dose Prediction in Cervical Cancer: Scientifically Training Data Selection.,"Consistent training and testing datasets can lead to good performance for deep learning (DL) models. However, a large high-quality training dataset for unusual clinical scenarios is usually not easy to collect. The work aims to find optimal training data collection strategies for DL-based dose prediction models.A total of 325 clinically approved cervical IMRT plans were utilized. We designed comparison experiments to investigate the impact of (1) beam angles, (2) the number of beams, and (3) patient position for DL dose prediction models. In addition, a novel geometry-based beam mask generation method was proposed to provide beam setting information in the model training process. What is more, we proposed a new training strategy named ""full-database pre-trained strategy"".The model trained with a homogeneous dataset with the same beam settings achieved the best performance [mean prediction errors of planning target volume (PTV), bladder, and rectum: 0.29 ± 0.15%, 3.1 ± 2.55%, and 3.15 ± 1.69%] compared with that trained with large mixed beam setting plans (mean errors of PTV, bladder, and rectum: 0.8 ± 0.14%, 5.03 ± 2.2%, and 4.45 ± 1.4%). A homogeneous dataset is more accessible to train an accurate dose prediction model (mean errors of PTV, bladder and rectum: 2.2 ± 0.15%, 5 ± 2.1%, and 3.23 ± 1.53%) than a non-homogeneous one (mean errors of PTV, bladder and rectum: 2.55 ± 0.12%, 6.33 ± 2.46%, and 4.76 ± 2.91%) without other processing approaches. The added beam mask can constantly improve the model performance, especially for datasets with different beam settings (mean errors of PTV, bladder, and rectum improved from 0.8 ± 0.14%, 5.03 ± 2.2%, and 4.45 ± 1.4% to 0.29 ± 0.15%, 3.1 ± 2.55%, and 3.15 ± 1.69%).A consistent dataset is recommended to form a patient-specific IMRT dose prediction model. When a consistent dataset is not accessible to collect, a large dataset with different beam angles and a training model with beam information can also get a relatively good model. The full-database pre-trained strategies can rapidly form an accuracy model from a pre-trained model. The proposed beam mask can effectively improve the model performance. Our study may be helpful for further dose prediction studies in terms of training strategies or database establishment.",'cervical',0.454925299,'325',0.413503483,'to find optimal training data collection strategies for DL-based dose prediction models',0.478615761,'homogeneous dataset',0.316832364,'cervical IMRT plans were utilized. We designed comparison experiments',0.001289439,'homogeneous dataset',0.001779312,'homogeneous dataset',0.037154648,'homogeneous dataset',0.037154648
76,35310976,Development and Validation of a Machine Learning-Based Radiomics Model on Cardiac Computed Tomography of Epicardial Adipose Tissue in Predicting Characteristics and Recurrence of Atrial Fibrillation.,"This study aimed to evaluate the feasibility of differentiating the atrial fibrillation (AF) subtype and preliminary explore the prognostic value of AF recurrence after ablation using radiomics models based on epicardial adipose tissue around the left atrium (LA-EAT) of cardiac CT images.The cardiac CT images of 314 patients were collected wherein 251 and 63 cases were randomly enrolled in the training and validation cohorts, respectively. Mutual information and the random forest algorithm were used to screen for the radiomic features and construct the radiomics signature. Radiomics models reflecting the features of LA-EAT were built to differentiate the AF subtype, and the multivariable logistic regression model was adopted to integrate the radiomics signature and volume information. The same methodology and algorithm were applied to the radiomic features to explore the ability for predicting AF recurrence.The predictive model constructed by integrating the radiomic features and volume information using a radiomics nomogram showed the best ability in differentiating AF subtype in the training [AUC, 0.915; 95% confidence interval (CI), 0.880-0.951] and validation (AUC, 0.853; 95% CI, 0.755-0.951) cohorts. The radiomic features have shown convincible predictive ability of AF recurrence in both training (AUC, 0.808; 95% CI, 0.750-0.866) and validation (AUC, 0.793; 95% CI, 0.654-0.931) cohorts.The LA-EAT radiomic signatures are a promising tool in the differentiation of AF subtype and prediction of AF recurrence, which may have clinical implications in the early diagnosis of AF subtype and disease management.",'atrial fibrillation (AF)',0.534002572,'314',0.526866332,'to evaluate the feasibility of differentiating the atrial fibrillation (AF) subtype',0.282325439,'cardiac CT images',0.490714341,'The cardiac CT images of 314 patients were collected wherein 251 and 63 cases were randomly enrolled in the training and validation cohorts',0.002862939,'The cardiac CT images of 314 patients',0.008398631,'The cardiac CT images of 314 patients',0.07771704,'The cardiac CT images of 314 patients',0.07771704
77,35317128,Deep Learning Algorithm-Based MRI Image in the Diagnosis of Diabetic Macular Edema.,"This study investigates the value of magnetic resonance imaging (MRI) based on a deep learning algorithm in the diagnosis of diabetic macular edema (DME) patients. A total of 96 patients with DME were randomly divided into the experimental group (<i>N</i>  = 48) and the control group (<i>N</i>  = 48). A deep learning 3D convolutional neural network (3D-CNN) algorithm for MRI images of patients with DME was designed. The application value of this algorithm was comprehensively evaluated by MRI image segmentation Dice value, sensitivity, specificity, and other indicators and diagnostic accuracy. The results showed that the quality of MRI images processed by the 3D-CNN algorithm based on deep learning was significantly improved, and the Dice value, sensitivity, and specificity index data were significantly better than those of the traditional CNN algorithm (<i>P</i> < 0.05). In addition, the diagnostic accuracy of MRI images processed by this algorithm was 93.78 ± 5.32%, which was significantly better than the diagnostic accuracy of 64.25 ± 10.24% of traditional MRI images in the control group (<i>P</i> < 0.05). In summary, the 3D-CNN algorithm based on deep learning can significantly improve the accuracy and sensitivity of MRI image recognition and segmentation in patients with DME, can significantly improve the diagnostic accuracy of MRI in patients with DME, and has a good clinical application value.",'diabetic macular edema',0.655250132,'96',0.268504433,'This study investigates the value of magnetic resonance imaging (MRI) based on a deep learning algorithm in the diagnosis of diabetic macular edema (DME) patients',0.335570537,'magnetic resonance imaging',0.67449072,'diabetic macular edema (DME) patients. A total of 96 patients with DME',0.000456351,'96',0.001480059,'diabetic macular edema (DME)',0.032981298,'diabetic macular edema (DME)',0.032981298
78,35312969,Diagnosis of significant liver fibrosis in patients with chronic hepatitis B using a deep learning-based data integration network.,"Chronic hepatitis B virus (CHB) infection remains a major global health burden and the non-invasive and accurate diagnosis of significant liver fibrosis (≥ F2) in CHB patients is clinically very important. This study aimed to assess the potential of the joint use of ultrasound images of liver parenchyma, liver stiffness values, and patients' clinical parameters in a deep learning model to improve the diagnosis of ≥ F2 in CHB patients.Of 527 CHB patients who underwent US examination, liver elastography and biopsy, 284 eligible patients were included. We developed a deep learning-based data integration network (DI-Net) to fuse the information of ultrasound images of liver parenchyma, liver stiffness values and patients' clinical parameters for diagnosing ≥ F2 in CHB patients. The performance of DI-Net was cross-validated in a main cohort (n = 155) of the included patients and externally validated in an independent cohort (n = 129), with comparisons against single-source data-based models and other non-invasive methods in terms of the area under the receiver-operating-characteristic curve (AUC).DI-Net achieved an AUC of 0.943 (95% confidence interval [CI] 0.893-0.973) in the cross-validation, and an AUC of 0.901 (95% CI 0.834-0.945) in the external validation, which were significantly greater than those of the comparative methods (AUC ranges: 0.774-0.877 and 0.741-0.848 for cross- and external validations, respectively, p<sub>s</sub> < 0.01).The joint use of ultrasound images of liver parenchyma, liver stiffness values, and patients' clinical parameters in a deep learning model could significantly improve the diagnosis of ≥ F2 in CHB patients.",'Chronic hepatitis B virus (CHB) infection',0.481685296,'284',0.721369952,"'to assess the potential of the joint use of ultrasound images of liver parenchyma, liver stiffness values, and patients' clinical parameters in a deep learning model to improve the diagnosis of ≥ F2 in CHB patients'",0.455639362,'ultrasound images',0.538588881,'cross-validated in a main cohort (n = 155) of the included patients and externally validated in an independent cohort (n = 129)',0.003231124,'externally validated in an independent cohort (n = 129)',0.000985657,"'527 CHB patients who underwent US examination, liver elastography and biopsy, 284 eligible patients were included. We developed a deep learning-based data integration network (DI-Net) to fuse the information of ultrasound images of liver parenchyma, liver stiffness values and patients' clinical parameters for diagnosing ≥ F2 in CHB patients. The performance of DI-Net was cross-validated in a main cohort (n = 155)'",0.031354089,"'527 CHB patients who underwent US examination, liver elastography and biopsy, 284 eligible patients were included. We developed a deep learning-based data integration network (DI-Net) to fuse the information of ultrasound images of liver parenchyma, liver stiffness values and patients' clinical parameters for diagnosing ≥ F2 in CHB patients. The performance of DI-Net was cross-validated in a main cohort (n = 155)'",0.031354089
79,35311112,A Classifier for Improving Early Lung Cancer Diagnosis Incorporating Artificial Intelligence and Liquid Biopsy.,"Lung cancer is the leading cause of cancer-related deaths worldwide and in China. Screening for lung cancer by low dose computed tomography (LDCT) can reduce mortality but has resulted in a dramatic rise in the incidence of indeterminate pulmonary nodules, which presents a major diagnostic challenge for clinicians regarding their underlying pathology and can lead to overdiagnosis. To address the significant gap in evaluating pulmonary nodules, we conducted a prospective study to develop a prediction model for individuals at intermediate to high risk of developing lung cancer. Univariate and multivariate logistic analyses were applied to the training cohort (n = 560) to develop an early lung cancer prediction model. The results indicated that a model integrating clinical characteristics (age and smoking history), radiological characteristics of pulmonary nodules (nodule diameter, nodule count, upper lobe location, malignant sign at the nodule edge, subsolid status), artificial intelligence analysis of LDCT data, and liquid biopsy achieved the best diagnostic performance in the training cohort (sensitivity 89.53%, specificity 81.31%, area under the curve [AUC] = 0.880). In the independent validation cohort (n = 168), this model had an AUC of 0.895, which was greater than that of the Mayo Clinic Model (AUC = 0.772) and Veterans' Affairs Model (AUC = 0.740). These results were significantly better for predicting the presence of cancer than radiological features and artificial intelligence risk scores alone. Applying this classifier prospectively may lead to improved early lung cancer diagnosis and early treatment for patients with malignant nodules while sparing patients with benign entities from unnecessary and potentially harmful surgery.ChiCTR1900026233, URL: http://www.chictr.org.cn/showproj.aspx?proj=43370.",'lung cancer',0.577400237,'560',0.201082505,"'To address the significant gap in evaluating pulmonary nodules, we conducted a prospective study to develop a prediction model for individuals at intermediate to high risk of developing lung cancer'",0.328805387,'LDCT',0.822350323,'China',0.403432578,'Mayo Clinic',0.005758787,'ChiCTR1900026233',0.321284622,'ChiCTR1900026233',0.321284622
80,35311106,An Assisted Diagnosis Model for Cancer Patients Based on Federated Learning.,"Since the 20th century, cancer has been a growing threat to human health. Cancer is a malignant tumor with high clinical morbidity and mortality, and there is a high risk of recurrence after surgery. At the same time, the diagnosis of whether the cancer is <i>in situ</i> recurrence is crucial for further treatment of cancer patients. According to statistics, about 90% of cancer-related deaths are due to metastasis of primary tumor cells. Therefore, the study of the location of cancer recurrence and its influencing factors is of great significance for the clinical diagnosis and treatment of cancer. In this paper, we propose an assisted diagnosis model for cancer patients based on federated learning. In terms of data, the influencing factors of cancer recurrence and the special needs of data samples required by federated learning were comprehensively considered. Six first-level impact indicators were determined, and the historical case data of cancer patients were further collected. Based on the federated learning framework combined with convolutional neural network, various physical examination indicators of patients were taken as input. The recurrence time and recurrence location of patients were used as output to construct an auxiliary diagnostic model, and linear regression, support vector regression, Bayesling regression, gradient ascending tree and multilayer perceptrons neural network algorithm were used as comparison algorithms. CNN's federated prediction model based on improved under the condition of the joint modeling and simulation on the five types of cancer data accuracy reached more than 90%, the accuracy is better than single modeling machine learning tree model and linear model and neural network, the results show that auxiliary diagnosis model based on the study of cancer patients in assisted the doctor in the diagnosis of patients, As well as effectively provide nutritional programs for patients and have application value in prolonging the life of patients, it has certain guiding significance in the field of medical cancer rehabilitation.",'cancer',0.345715225,'Six',0.03196223,'the study of the location of cancer recurrence and its influencing factors is of great significance for the clinical diagnosis and treatment of cancer',0.223465309,'federated learning',0.145567715,'location of cancer recurrence',0.00054337,'historical case data of cancer patients were further collected',0.001343064,'historical case data of cancer patients',0.018587398,'historical case data of cancer patients',0.018587398
81,35310995,A Machine Learning-Based Prediction Model for Acute Kidney Injury in Patients With Congestive Heart Failure.,"Machine learning (ML) has been used to build high performance prediction model. Patients with congestive heart failure (CHF) are vulnerable to acute kidney injury (AKI) which makes treatment difficult. We aimed to establish an ML-based prediction model for the early identification of AKI in patients with CHF.Patients data were extracted from the Medical Information Mart for Intensive Care III (MIMIC-III) database, and patients with CHF were selected. Comparisons between several common ML classifiers were conducted to select the best prediction model. Recursive feature elimination (RFE) was used to select important prediction features. The model was improved using hyperparameters optimization (HPO). The final model was validated using an external validation set from the eICU Collaborative Research Database. The area under the receiver operating characteristic curve (AUROC), accuracy, calibration curve and decision curve analysis were used to evaluate prediction performance. Additionally, the final model was used to predict renal replacement therapy (RRT) requirement and to assess the short-term prognosis of patients with CHF. Finally, a software program was developed based on the selected features, which could intuitively report the probability of AKI.A total of 8,580 patients with CHF were included, among whom 2,364 were diagnosed with AKI. The LightGBM model showed the best prediction performance (AUROC = 0.803) among the 13 ML-based models. After RFE and HPO, the final model was established with 18 features including serum creatinine (SCr), blood urea nitrogen (BUN) and urine output (UO). The prediction performance of LightGBM was better than that of measuring SCr, UO or SCr combined with UO (AUROCs: 0.809, 0.703, 0.560 and 0.714, respectively). Additionally, the final model could accurately predict RRT requirement in patients with (AUROC = 0.954). Moreover, the participants were divided into high- and low-risk groups for AKI, and the 90-day mortality in the high-risk group was significantly higher than that in the low-risk group (log-rank <i>p</i> < 0.001). Finally, external validation using the eICU database comprising 9,749 patients with CHF revealed satisfactory prediction outcomes (AUROC = 0.816).A prediction model for AKI in patients with CHF was established based on LightGBM, and the prediction performance of this model was better than that of other models. This model may help in predicting RRT requirement and in identifying the population with poor prognosis among patients with CHF.",'congestive heart failure',0.378910527,"'8,580'",0.595603436,'early identification of AKI in patients with CHF',0.252879463,'Medical Information Mart for Intensive Care III (MIMIC-III) database',0.495853066,'Medical Information Mart for Intensive Care III (MIMIC-III) database',0.002565468,'Medical Information Mart for Intensive Care III',0.217192575,'Medical Information Mart for Intensive Care III',0.536296681,'Medical Information Mart for Intensive Care III',0.536296681
82,35319151,Prediction of Microvascular Invasion in Hepatocellular Carcinoma with Expert-inspiration and Skeleton Sharing Deep Learning.,"Radiological prediction of microvascular invasion (MVI) of hepatocellular carcinoma (HCC) is essential but few models were clinically implemented due to limited interpretability and generalizability.Basing on 2096 patients in three independent HCC cohorts, we established and validated an MVI predicting model. First, we used data from the primary cohort to train a 3D-ResNet network for MVI prediction, and then optimized the model with ""expert-inspired training"" for model construction. Second, we implemented the model to the other two cohorts using three implementation strategies, the original model implementation, data sharing model implementation and skeleton sharing model implementation, the latter two of which used part of the cohorts' data for fine-tuning. The areas under the receiver operating characteristic curve (AUCs) were calculated to compare performances of different models.For the MVI predicting model, the AUC of the expert-inspired model was 0.83 (95% CI: 0.77-0.88) compared to 0.54 (95%CI: 0.46-0.62) of model before expert-inspiring. Taking this model as an original model, AUC on the second cohort was 0.76 (95% CI: 0.67-0.84). The AUC was improved to 0.83 (95%CI: 0.77-0.90) with the data sharing model, and further improved to 0.85 (95% CI: 0.79-0.92) with the skeleton sharing model. The trend that skeleton sharing model had an advantage in performance was similar in the third cohort.We established an expert-inspired model with better predictive performance and interpretability than the traditional constructed model. Skeleton sharing process is superior to data sharing and direct model implementation in model implementation.",'hepatocellular carcinoma',0.555351689,'2096',0.786375552,'Radiological prediction of microvascular invasion (MVI) of hepatocellular carcinoma (HCC) is essential',0.143536463,'data from the primary cohort',0.121864442,'three independent HCC cohorts',0.003331936,'2096 patients in three independent HCC cohorts',0.003257892,'2096 patients in three independent HCC cohorts',0.211934481,'2096 patients in three independent HCC cohorts',0.211934481
83,35318153,Using preoperative and intraoperative factors to predict the risk of surgical site infections after lumbar spinal surgery: a machine learning-based study.,"This study aimed to develop a model based on machine learning to predict surgical site infections risk (SSI) in patients after lumbar spinal surgery (LSS).Patients who developed postoperative SSI after LSS in our hospital between December 2010 and December 2019 were retrospectively reviewed. preoperative and intraoperative variables including age, diabetes mellitus (DM), hypertension, BMI, previous spinal surgery history, surgical duration, number of fused segments, blood loss and surgical procedure were retrospectively analyzed. Six machine learning algorithms, including Logistic regression (LR), Multilayer Perceptron (MLP), Decision tree (DT), Random Forest (RF), Gradient Boosting Machine (GBM), and Extreme gradient boosting (XGB), were used to build prediction models. The performance of the models was evaluated using the area under the receiver operating characteristic curve (AUC), accuracy, precision, sensitivity and F1 score. A web predictor was developed based on the best-performing model.A total of 288 LSS patients from our hospital were included in the study. Of whom, 144 were complicated with SSI and 144 without. The XGB model offers the best predictive performance among these 6 models (AUC: 0.923, accuracy: 0.860, precision: 0.900, sensitivity: 0.834 and F1 score: 0.864). An XGB model-based web predictor was developed to predict SSI in patients after LSS.This study developed a machine learning model and a web predictor for predicting SSI in LSS patients, which may help clinicians screen high-risk patients, give personalized treatment and reduce the incidence of SSI after LSS.",'surgical site infections risk (SSI) in patients after lumbar spinal surgery',0.29359816,'288',0.621213332,'This study aimed to develop a model based on machine learning to predict surgical site infections risk',0.266884446,'machine learning to predict surgical site infections risk (SSI) in patients after lumbar spinal surgery (LSS).Patients who developed postoperative SSI after LSS in our hospital between December 2010 and December 2019 were retrospectively reviewed. preoperative and intraoperative variables',0.235113986,'2010 and December 2019',0.000434801,'our hospital',0.572974473,'our hospital',0.12334783,'our hospital',0.12334783
84,35317237,Multi-omics landscape and clinical significance of a <i>SMAD4</i>-driven immune signature: Implications for risk stratification and frontline therapies in pancreatic cancer.,"<i>SMAD4</i> mutation was recently implicated in promoting invasion and poor prognosis of pancreatic cancer (PACA) by regulating the tumor immune microenvironment. However, <i>SMAD4</i>-driven immune landscape and clinical significance remain elusive. In this study, we applied the consensus clustering and weighted correlation network analysis (WGCNA) to identify two heterogeneous immune subtypes and immune genes. Combined with <i>SMAD4</i>-driven genes determined by <i>SMAD4</i> mutation status, a <i>SMAD4</i>-driven immune signature (SDIS) was developed in ICGC-AU2 (microarray data) via machine learning algorithm, and then was validated by RNA-seq data (TCGA, ICGC-AU and ICGC-CA) and microarray data (GSE62452 and GSE85916). The high-risk group displayed a worse prognosis, and multivariate Cox regression indicated that SDIS was an independent prognostic factor. In six cohorts, SDIS also displayed excellent accuracy in predicting prognosis. Moreover, the high-risk group was characterized by higher frequencies of <i>TP53</i>/<i>CDKN2A</i> mutations and <i>SMAD4</i> deletion, superior immune checkpoint molecules expression and more sensitive to chemotherapy and immunotherapy. Meanwhile, the low-risk group was significantly enriched in metabolism-related pathways and suggested the potential to target tumor metabolism to develop specific drugs. Overall, SDIS could robustly predict prognosis in PACA, which might serve as an attractive platform to further tailor decision-making in chemotherapy and immunotherapy in clinical settings.",'pancreatic cancer',0.633930951,'six cohorts',0.026130164,'we applied the consensus clustering and weighted correlation network analysis (WGCNA) to identify two heterogeneous immune subtypes and immune genes',0.234389782,'microarray data',0.233383566,'ICGC-AU2',0.021123042,'ICGC-AU2',0.036299077,'ICGC-AU2',0.597576931,'ICGC-AU2',0.597576931
85,35315719,An Artificial Intelligence Model Based on ACR TI-RADS Characteristics for US Diagnosis of Thyroid Nodules.,"Background US-based diagnosis of thyroid nodules is subjective and influenced by radiologists' experience levels. Purpose To develop an artificial intelligence model based on American College of Radiology Thyroid Imaging Reporting and Data System characteristics for diagnosing thyroid nodules and identifying nodule characteristics (hereafter, M<sub>TI-RADS</sub>) and to compare the performance of M<sub>TI-RADS</sub>, radiologists, and a model trained on benign and malignant status based on surgical histopathologic analysis (hereafter, M<sub>Diag</sub>). Materials and Methods In this retrospective study, 1588 surgically proven nodules from 636 consecutive patients (mean age, 49 years ± 14 [SD]; 485 women) were included. M<sub>TI-RADS</sub> and M<sub>Diag</sub> were trained on US images of 1345 nodules (January 2018 to December 2019). The performance of M<sub>TI-RADS</sub> was compared with that of M<sub>Diag</sub> and radiologists with different experience levels on the test data set (243 nodules, January 2019 to December 2019) with the DeLong method and McNemar test. Results The area under the receiver operating characteristic curve (AUC) and sensitivity of M<sub>TI-RADS</sub> were 0.91 and 83% (55 of 66 nodules), respectively, which were not significantly different from those of experienced radiologists (0.93 [<i>P</i> = .45] and 92% [61 of 66 nodules; <i>P</i> = .07]) and exceeded those of junior radiologists (0.78 [<i>P</i> < .001] and 70% [46 of 66 nodules; <i>P</i> = .04]). The specificity of M<sub>TI-RADS</sub> (87% [154 of 177 nodules]) was higher than that of both experienced and junior radiologists (80% [141 of 177 nodules; <i>P</i> = .02] and 75% [133 of 177 nodules; <i>P</i> = .001], respectively). The AUC of M<sub>TI-RADS</sub> was higher than that of M<sub>Diag</sub> (0.91 vs 0.84, respectively; <i>P</i> = .001). In the test set of 243 nodules, the consistency rates between M<sub>TI-RADS</sub> and the experienced group were higher than those between M<sub>TI-RADS</sub> and the junior group for composition (79% [<i>n</i> = 193] vs 73% [<i>n</i> = 178], respectively; <i>P</i> = .02), echogenicity (75% [<i>n</i> = 183] vs 68% [<i>n</i> = 166]; <i>P</i> = .04), shape (93% [<i>n</i> = 227] vs 88% [<i>n</i> = 215]; <i>P</i> = .04), and smooth or ill-defined margin (72% [<i>n</i> = 174] vs 63% [<i>n</i> = 152]; <i>P</i> = .002). Conclusion The area under the receiver operating characteristic curve (AUC) of an artificial intelligence model based on the American College of Radiology Thyroid Imaging Reporting and Data System (TI-RADS) was higher than that of a model trained on benign and malignant status based on surgical histopathologic analysis. The AUC and sensitivity of the model based on TI-RADS exceeded those of junior radiologists; the specificity of the model was higher than that of both experienced and junior radiologists. © RSNA, 2022.",'thyroid nodules',0.450648189,'636',0.577262759,'To develop an artificial intelligence model based on American College of Radiology Thyroid Imaging Reporting and Data System characteristics for diagnosing thyroid nodules and identifying nodule characteristics',0.178956572,'US images',0.584061876,"'retrospective study, 1588 surgically proven nodules from 636 consecutive patients'",0.001972603,'1588 surgically proven nodules from 636 consecutive patients',0.002958021,'American College of Radiology Thyroid Imaging Reporting and Data System',0.357606202,'American College of Radiology Thyroid Imaging Reporting and Data System',0.357606202
86,35315146,Automatic Segmentation and Detection of Ectopic Eruption of the First Permanent Molars on Panoramic Radiographs Based on nnU-Net.,"The purpose of this research was to present an artificial intelligence (AI) model which can automatically segment and detect ectopic eruption of the permanent first molars (EMMs) in early mixed dentition on panoramic radiographs using no-new-Net (nnU-Net) model.438 EMMs obtained from 285 panoramic radiographs were included in this study. AI model based on nnU-Net was trained to segment and detect the EMMs. The performance of the model was evaluated by the intersection over union (IoU), precision, F1-score, accuracy and FROC. Furthermore, the detecting performance of nnU-Net was compared with three dentists with different years of experience using the McNemar chi-square test. The reliability of different dentists was evaluated by intraclass correlation coefficients (ICC).The nnU-Net yielded an IoU of 0.834, a precision of 0.845, an F1-score of 0.902 and an accuracy of 0.990. Moreover, the dentists yielded a mean IoU of 0.530, a mean precision of 0.539, a mean F1-score of 0.699 and a mean accuracy of 0.811. The ICC of different dentists was 0.776. The statistical analysis of the McNemar chi-square test showed that the nnU-Net results were statistically significant and superior to that of dentists (P <0.05).This study validated an AI model based on nnU-Net for automatically segmenting and detecting EMMs more consistently and accurately on panoramic radiography.",'ectopic eruption of the permanent first molars (EMMs) in early mixed dentition',0.219435789,'285',0.429224312,'to present an artificial intelligence (AI) model which can automatically segment and detect ectopic eruption of the permanent first molars (EMMs) in early mixed dentition',0.278652981,'panoramic radiographs',0.67107594,'438',0.002729721,'438 EMMs obtained from 285 panoramic radiographs',0.00497161,'panoramic radiographs using no-new-Net (nnU-Net) model.438 EMMs obtained from 285 panoramic radiographs',0.299871311,'panoramic radiographs using no-new-Net (nnU-Net) model.438 EMMs obtained from 285 panoramic radiographs',0.299871311
87,35311127,Deep Learning Model for Intracranial Hemangiopericytoma and Meningioma Classification.,"Intracranial hemangiopericytoma/solitary fibrous tumor (SFT/HPC) is a rare type of neoplasm containing malignancies of infiltration, peritumoral edema, bleeding, or bone destruction. However, SFT/HPC has similar radiological characteristics as meningioma, which had different clinical managements and outcomes. This study aims to discriminate SFT/HPC and meningioma <i>via</i> deep learning approaches based on routine preoperative MRI.We enrolled 236 patients with histopathological diagnosis of SFT/HPC (n = 144) and meningioma (n = 122) from 2010 to 2020 in Xiangya Hospital. Radiological features were extracted manually, and a radiological diagnostic model was applied for classification. And a deep learning pretrained model ResNet-50 was adapted to train T1-contrast images for predicting tumor class. Deep learning model attention mechanism was visualized by class activation maps.Our study reports that SFT/HPC was found to have more invasion to venous sinus (<i>p</i> = 0.001), more cystic components (<i>p</i> < 0.001), and more heterogeneous enhancement patterns (<i>p</i> < 0.001). Deep learning model achieved a high classification accuracy of 0.889 with receiver-operating characteristic curve area under the curve (AUC) of 0.91 in the validation set. Feature maps showed distinct clustering of SFT/HPC and meningioma in the training and test cohorts, respectively. And the attention of the deep learning model mainly focused on the tumor bulks that represented the solid texture features of both tumors for discrimination.",'Intracranial hemangiopericytoma/solitary fibrous tumor',0.362552747,'236',0.298732743,'to discriminate SFT/HPC and meningioma',0.37417388,'routine preoperative MRI',0.626612559,'Xiangya Hospital',0.013276291,'Xiangya Hospital',0.862264514,'Xiangya Hospital',0.711859733,'Xiangya Hospital',0.711859733
88,35311076,RDAU-Net: Based on a Residual Convolutional Neural Network With DFP and CBAM for Brain Tumor Segmentation.,"Due to the high heterogeneity of brain tumors, automatic segmentation of brain tumors remains a challenging task. In this paper, we propose RDAU-Net by adding dilated feature pyramid blocks with 3D CBAM blocks and inserting 3D CBAM blocks after skip-connection layers. Moreover, a CBAM with channel attention and spatial attention facilitates the combination of more expressive feature information, thereby leading to more efficient extraction of contextual information from images of various scales. The performance was evaluated on the Multimodal Brain Tumor Segmentation (BraTS) challenge data. Experimental results show that RDAU-Net achieves state-of-the-art performance. The Dice coefficient for WT on the BraTS 2019 dataset exceeded the baseline value by 9.2%.",'brain tumors',0.366471335,'Multimodal Brain Tumor Segmentation (BraTS) challenge data. Experimental results show that RDAU-Net achieves state-of-the-art performance. The Dice coefficient for WT on the BraTS 2019',0.015347902,'Multimodal Brain Tumor Segmentation',0.1393742,'Multimodal Brain Tumor Segmentation',0.227966376,'2019',0.008377525,'Multimodal Brain Tumor Segmentation (BraTS) challenge data. Experimental results show that RDAU-Net achieves state-of-the-art performance. The Dice coefficient for WT on the BraTS 2019',0.002083861,'Multimodal Brain Tumor Segmentation (BraTS)',0.172053128,'Multimodal Brain Tumor Segmentation (BraTS)',0.172053128
89,35317129,Artificial Intelligence Algorithm-Based Intraoperative Magnetic Resonance Navigation for Glioma Resection.,"The study aimed to analyze the application value of artificial intelligence algorithm-based intraoperative magnetic resonance imaging (iMRI) in neurosurgical glioma resection. 108 patients with glioma in a hospital were selected and divided into the experimental group (intraoperative magnetic resonance assisted glioma resection) and the control group (conventional surgical experience resection), with 54 patients in each group. After the resection, the tumor resection rate, NIHSS (National Institute of Health Stroke Scale) score, Karnofsky score, and postoperative intracranial infection were calculated in the two groups. The results revealed that the average tumor resection rate in the experimental group was significantly higher than that in the control group (<i>P</i> < 0.05). There was no significant difference in Karnofsky score before and after the operation in the experimental group (<i>P</i> > 0.05). There was no significant difference in NIHSS score between the experimental group and the control group after resection (<i>P</i> > 0.05). The number of patients with postoperative neurological deficits in the experimental group was smaller than that in the control group. In addition, there was no significant difference in infection rates between the two groups after glioma resection (<i>P</i> > 0.05). In summary, intraoperative magnetic resonance navigation on the basis of a segmentation dictionary learning algorithm has great clinical value in neurosurgical glioma resection. It can maximize the removal of tumors and ensure the integrity of neurological function while avoiding an increased risk of postoperative infection, which is of great significance for the treatment of glioma.",'glioma',0.397870779,'108',0.312556043,'to analyze the application value of artificial intelligence algorithm-based intraoperative magnetic resonance imaging (iMRI) in neurosurgical glioma resection',0.545006201,'intraoperative magnetic resonance imaging',0.66564545,'The study aimed to analyze the application value of artificial intelligence algorithm-based intraoperative magnetic resonance imaging (iMRI) in neurosurgical glioma resection. 108 patients with glioma in a hospital',0.001389008,'a hospital',0.07564172,'conventional surgical experience resection',0.092577174,'conventional surgical experience resection',0.092577174
90,35318170,Hierarchical Harris hawks optimization for epileptic seizure classification.,"The intelligent recognition of electroencephalogram (EEG) signals is a valuable tool for epileptic seizure classification. Given that visual inspection of EEG signals is time-consuming, and that mutant signals dramatically increase the workload of neurologists, automatic epilepsy diagnosis systems are extremely helpful. However, the existing epilepsy diagnosis methods suffer from some shortcomings. For example, they tend to fall into local optima quickly because of their failure to fully consider the discriminative features of EEG signals. To tackle this problem, in this article, an enhanced automatic epilepsy diagnosis method is proposed using time-frequency analysis and improved Harris hawks optimization (IHHO) with a hierarchical mechanism. Specifically, the signal is decomposed into five rhythms using continuous wavelet transform, with the local and global features extracted using the local binary pattern and the gray level co-occurrence matrix. Discriminative features are then selected and further mapped to the final recognition results using both IHHO and the k-nearest neighbor classifier. To evaluate its performance, the proposed method was compared with a variety of classical meta-heuristic algorithms on 23 benchmark functions. Moreover, the proposed approach achieved more than 99.67% accuracy on the Bonn dataset and 99.06% accuracy on the CHB-MIT dataset, out-performing a multitude of state-of-the-art methods. Taken together, these results demonstrate the utility of our approach in the automatic diagnosis of epilepsy. Supportive datasets and source codes for this research are publicly available at https://github.com/sstudying/lzzhen, and latest updates for the HHO algorithm are provided at https://aliasgharheidari.com/HHO.html.",'epilepsy',0.76003471,'23',0.035647282,'automatic diagnosis of epilepsy',0.378724426,'electroencephalogram (EEG) signals',0.50361152,'CHB-MIT',0.030912407,'CHB-MIT',0.002862097,'CHB-MIT',0.354481623,'CHB-MIT',0.354481623
91,35310781,Cognitive Impairment of Patient With Neurological Cerebrovascular Disease Using the Artificial Intelligence Technology Guided by MRI.,"This study was to explore the application of MRI based on artificial intelligence technology combined with neuropsychological assessment to the cognitive impairment of patients with neurological cerebrovascular diseases. A total of 176 patients were divided into a control group, a vascular cognitive impairment non-dementia (VCIND) group, a vascular dementia (VD) group, and an Alzheimer's disease (AD) group. All patients underwent MRI and neuropsychological evaluation and examination, and an improved fuzzy C-means (FCM) clustering algorithm was proposed for MRI processing. It was found that the segmentation accuracy (SA) and similarity (KI) data of the improved FCM algorithm used in this study were higher than those of the standard FCM algorithm, bias-corrected FCM (BCFCM) algorithm, and rough FCM (RFCM) algorithm (<i>p</i> < 0.05). In the activities of daily living (ADL), the values in the VCIND group (23.55 ± 6.12) and the VD group (28.56 ± 3.1) were higher than that in the control group (19.17 ± 3.67), so the hippocampal volume was negatively correlated with the ADL (<i>r</i> = -0.872, <i>p</i> < 0.01). In the VCIND group (52.4%), VD group (31%), and AD group (26.1%), the proportion of patients with the lacunar infarction distributed on both sides of the brain and the number of multiple cerebral infarction lesions (76.2, 71.4, and 71.7%, respectively) were significantly higher than those in the control group (23.9 and 50%). In short, the improved FCM algorithm showed a higher segmentation effect and SA for MRI of neurological cerebrovascular disease. In addition, the distribution, number, white matter lesions, and hippocampal volume of lacunar cerebral infarction were related to the cognitive impairment of patients with cerebrovascular diseases.",'cerebrovascular diseases',0.384142205,'176',0.50631015,'to explore the application of MRI based on artificial intelligence technology combined with neuropsychological assessment to the cognitive impairment of patients with neurological cerebrovascular diseases',0.390942037,'MRI',0.592175066,'This study was to explore the application of MRI based on artificial intelligence technology combined with neuropsychological assessment to the cognitive impairment of patients with neurological cerebrovascular diseases',0.00077582,"'It was found that the segmentation accuracy (SA) and similarity (KI) data of the improved FCM algorithm used in this study were higher than those of the standard FCM algorithm, bias-corrected FCM (BCFCM) algorithm, and rough FCM (RFCM) algorithm'",0.00154132,"'vascular cognitive impairment non-dementia (VCIND) group, a vascular dementia (VD) group, and an Alzheimer's disease (AD) group. All patients underwent MRI and neuropsychological evaluation and examination, and an improved fuzzy C-means (FCM) clustering algorithm was proposed for MRI processing. It was found that the segmentation accuracy (SA) and similarity (KI) data of the improved FCM algorithm used in this study were higher than those of the standard FCM algorithm, bias-corrected FCM (BCFCM) algorithm, and rough FCM (RFCM) algorithm'",0.042421443,"'vascular cognitive impairment non-dementia (VCIND) group, a vascular dementia (VD) group, and an Alzheimer's disease (AD) group. All patients underwent MRI and neuropsychological evaluation and examination, and an improved fuzzy C-means (FCM) clustering algorithm was proposed for MRI processing. It was found that the segmentation accuracy (SA) and similarity (KI) data of the improved FCM algorithm used in this study were higher than those of the standard FCM algorithm, bias-corrected FCM (BCFCM) algorithm, and rough FCM (RFCM) algorithm'",0.042421443
92,35310782,Improving Alzheimer's Disease Detection for Speech Based on Feature Purification Network.,"Alzheimer's disease (AD) is a neurodegenerative disease involving the decline of cognitive ability with illness progresses. At present, the diagnosis of AD mainly depends on the interviews between patients and doctors, which is slow, expensive, and subjective, so it is not a better solution to recognize AD using the currently available neuropsychological examinations and clinical diagnostic criteria. A recent study has indicated the potential of language analysis for AD diagnosis. In this study, we proposed a novel feature purification network that can improve the representation learning of transformer model further. Though transformer has made great progress in generating discriminative features because of its long-distance reasoning ability, there is still room for improvement. There exist many common features that are not indicative of any specific class, and we rule out the influence of common features from traditional features extracted by transformer encoder and can get more discriminative features for classification. We apply this method to improve transformer's performance on three public dementia datasets and get improved classification results markedly. Specifically, the method on Pitt datasets gets state-of-the-art (SOTA) result.",'Alzheimer's disease',0.619415522,'three',0.320445225,'indicated the potential of language analysis for AD diagnosis',0.220845029,'language analysis',0.292956799,'three public dementia datasets',0.00073725,'Pitt',0.002068952,'Pitt',0.260668375,'Pitt',0.260668375
93,35311083,Multiparametric MRI-Based Radiomics Model for Predicting H3 K27M Mutant Status in Diffuse Midline Glioma: A Comparative Study Across Different Sequences and Machine Learning Techniques.,"The performance of multiparametric MRI-based radiomics models for predicting H3 K27M mutant status in diffuse midline glioma (DMG) has not been thoroughly evaluated. The optimal combination of multiparametric MRI and machine learning techniques remains undetermined. We compared the performance of various radiomics models across different MRI sequences and different machine learning techniques.A total of 102 patients with pathologically confirmed DMG were retrospectively enrolled (27 with H3 K27M-mutant and 75 with H3 K27M wild-type). Radiomics features were extracted from eight sequences, and 18 feature sets were conducted by independent combination. There were three feature matrix normalization algorithms, two dimensionality-reduction methods, four feature selectors, and seven classifiers, consisting of 168 machine learning pipelines. Radiomics models were established across different feature sets and machine learning pipelines. The performance of models was evaluated using receiver operating characteristic curves with area under the curve (AUC) and compared with DeLong's test.The multiparametric MRI-based radiomics models could accurately predict the H3 K27M mutant status in DMG (highest AUC: 0.807-0.969, for different sequences or sequence combinations). However, the results varied significantly between different machine learning techniques. When suitable machine learning techniques were used, the conventional MRI-based radiomics models shared similar performance to advanced MRI-based models (highest AUC: 0.875-0.915 vs. 0.807-0.926; DeLong's test, <i>p</i> > 0.05). Most models had a better performance when generated with a combination of MRI sequences. The optimal model in the present study used a combination of all sequences (AUC = 0.969).The multiparametric MRI-based radiomics models could be useful for predicting H3 K27M mutant status in DMG, but the performance varied across different sequences and machine learning techniques.",'diffuse midline glioma (DMG)',0.514940634,'102',0.444127783,'We compared the performance of various radiomics models across different MRI sequences and different machine learning techniques',0.091934517,'MRI',0.296718389,'A total of 102 patients with pathologically confirmed DMG were retrospectively enrolled',0.001797631,'102 patients with pathologically confirmed DMG were retrospectively enrolled',0.002394534,'eight sequences',0.178655602,'eight sequences',0.178655602
94,35310885,Blood SSR1: A Possible Biomarker for Early Prediction of Parkinson's Disease.,"Parkinson's disease (PD) is the second most common neurodegenerative disease associated with age. Early diagnosis of PD is key to preventing the loss of dopamine neurons. Peripheral-blood biomarkers have shown their value in recent years because of their easy access and long-term monitoring advantages. However, few peripheral-blood biomarkers have proven useful. This study aims to explore potential peripheral-blood biomarkers for the early diagnosis of PD. Three substantia nigra (SN) transcriptome datasets from the Gene Expression Omnibus (GEO) database were divided into a training cohort and a test cohort. We constructed a protein-protein interaction (PPI) network and a weighted gene co-expression network analysis (WGCNA) network, found their overlapping differentially expressed genes and studied them as the key genes. Analysis of the peripheral-blood transcriptome datasets of PD patients from GEO showed that three key genes were upregulated in PD over healthy participants. Analysis of the relationship between their expression and survival and analysis of their brain expression suggested that these key genes could become biomarkers. Then, animal models were studied to validate the expression of the key genes, and only SSR1 (the signal sequence receptor subunit1) was significantly upregulated in both animal models in peripheral blood. Correlation analysis and logistic regression analysis were used to analyze the correlation between brain dopaminergic neurons and SSR1 expression, and it was found that SSR1 expression was negatively correlated with dopaminergic neuron survival. The upregulation of SSR1 expression in peripheral blood was also found to precede the abnormal behavior of animals. In addition, the application of artificial intelligence technology further showed the value of SSR1 in clinical PD prediction. The three classifiers all showed that SSR1 had high predictability for PD. The classifier with the best prediction accuracy was selected through AUC and MCC to construct a prediction model. In short, this research not only provides potential biomarkers for the early diagnosis of PD but also establishes a possible artificial intelligence model for predicting PD.",'Parkinson's disease',0.599228799,'Three',0.506345838,'to explore potential peripheral-blood biomarkers for the early diagnosis of PD',0.413033143,'peripheral-blood transcriptome',0.190599404,'Three substantia nigra (SN) transcriptome datasets from the Gene Expression Omnibus (GEO) database',0.006171206,'the Gene Expression Omnibus (GEO) database',0.036792038,'Gene Expression Omnibus (GEO) database',0.532074779,'Gene Expression Omnibus (GEO) database',0.532074779
95,35311111,Classification of Gliomas and Germinomas of the Basal Ganglia by Transfer Learning.,"Germ cell tumors (GCTs) are neoplasms derived from reproductive cells, mostly occurring in children and adolescents at 10 to 19 years of age. Intracranial GCTs are classified histologically into germinomas and non-germinomatous germ cell tumors. Germinomas of the basal ganglia are difficult to distinguish based on symptoms or routine MRI images from gliomas, even for experienced neurosurgeons or radiologists. Meanwhile, intracranial germinoma has a lower incidence rate than glioma in children and adults. Therefore, we established a model based on pre-trained ResNet18 with transfer learning to better identify germinomas of the basal ganglia.This retrospective study enrolled 73 patients diagnosed with germinoma or glioma of the basal ganglia. Brain lesions were manually segmented based on both T1C and T2 FLAIR sequences. The T1C sequence was used to build the tumor classification model. A 2D convolutional architecture and transfer learning were implemented. ResNet18 from ImageNet was retrained on the MRI images of our cohort. Class activation mapping was applied for the model visualization.The model was trained using five-fold cross-validation, achieving a mean AUC of 0.88. By analyzing the class activation map, we found that the model's attention was focused on the peri-tumoral edema region of gliomas and tumor bulk for germinomas, indicating that differences in these regions may help discriminate these tumors.This study showed that the T1C-based transfer learning model could accurately distinguish germinomas from gliomas of the basal ganglia preoperatively.",'Germ cell tumors',0.418851435,'73',0.379521921,'This retrospective study enrolled 73 patients diagnosed with germinoma or glioma of the basal ganglia',0.361198068,'T1C and T2 FLAIR sequences',0.165497757,'73 patients diagnosed with germinoma or glioma of the basal ganglia',0.002160398,'73 patients diagnosed with germinoma or glioma of the basal ganglia',0.004012404,'This retrospective study enrolled 73 patients diagnosed with germinoma or glioma of the basal ganglia',0.148597173,'This retrospective study enrolled 73 patients diagnosed with germinoma or glioma of the basal ganglia',0.148597173
96,35317471,An hybrid deep learning approach for depression prediction from user tweets using feature-rich CNN and bi-directional LSTM.,"Depression has become one of the most widespread mental health disorders across the globe. Depression is a state of mind which affects how we think, feel, and act. The number of suicides caused by depression has been on the rise for the last several years. This issue needs to be addressed. Considering the rapid growth of various social media platforms and their effect on society and the psychological context of a being, it's becoming a platform for depressed people to convey feelings and emotions, and to study their behavior by mining their social activity through social media posts. The key objective of our study is to explore the possibility of predicting a user's mental condition by classifying the depressive from non-depressive ones using Twitter data. Using textual content of the user's tweet, semantic context in the textual narratives is analyzed by utilizing deep learning models. The proposed model, however, is a hybrid of two deep learning architectures, Convolutional Neural Network (CNN) and bi-directional Long Short-Term Memory (biLSTM) that after optimization obtains an accuracy of 94.28% on benchmark depression dataset containing tweets. CNN-biLSTM model is compared with Recurrent Neural Network (RNN) and CNN model and also with the baseline approaches. Experimental results based on various performance metrics indicate that our model helps to improve predictive performance. To examine the problem more deeply, statistical techniques and visualization approaches were used to show the profound difference between the linguistic representation of depressive and non-depressive content.",'Depression',0.563557923,'Twitter',0.02433974,'to explore the possibility of predicting a user's mental condition by classifying the depressive from non-depressive ones using Twitter data',0.565196499,'Twitter',0.784367651,'Depression has become one of the most widespread mental health disorders across the globe',0.002153084,'Twitter',0.003100079,'Twitter',0.633818656,'Twitter',0.633818656
97,35315260,"Identifying psychological antecedents and predictors of vaccine hesitancy through machine learning: A cross sectional study among chronic disease patients of deprived urban neighbourhood, India.","COVID-19 vaccine hesitancy among chronic disease patients can severely impact individual health with the potential to impede mass vaccination essential for containing the pandemic. The present study was done to assess the COVID-19 vaccine antecedents and its predictors among chronic disease patients. This cross-sectional study was conducted among chronic disease patients availing care from a primary health facility in urban Jodhpur, Rajasthan. Factor and reliability analysis was done for the vaccine hesitancy scale to validate the 5 C scale. Predictors assessed for vaccine hesitancy were modelled with help of machine learning (ML). Out of 520 patients, the majority of participants were female (54.81%). Exploratory factor analysis revealed four psychological antecedents' ""calculation""; ""confidence""; ""constraint"" and ""collective responsibility"" determining 72.9% of the cumulative variance of vaccine hesitancy scale. The trained ML algorithm yielded an R2 of 0.33. Higher scores for COVID-19 health literacy and preventive behaviour, along with family support, monthly income, past COVID-19 screening, adherence to medications and age were associated with lower vaccine hesitancy. Behaviour changes communication strategies targeting COVID-19 health literacy and preventive behaviour especially among population sub-groups with poor family support, low income, higher age groups and low adherence to medicines may prove instrumental in this regard.",'chronic disease',0.346781328,'520',0.47360526,'to assess the COVID-19 vaccine antecedents and its predictors among chronic disease patients',0.291341498,'machine learning (ML)',0.369123369,'Rajasthan',0.064322015,"'primary health facility in urban Jodhpur, Rajasthan'",0.03055691,"'primary health facility in urban Jodhpur, Rajasthan'",0.053817667,"'primary health facility in urban Jodhpur, Rajasthan'",0.053817667
98,35320742,Cardi-Net: A deep neural network for classification of cardiac disease using phonocardiogram signal.,"The lack of medical facilities in isolated areas makes many patients remain aloof from quick and timely diagnosis of cardiovascular diseases, leading to high mortality rates. A deep learning based method for automatic diagnosis of multiple cardiac diseases from Phonocardiogram (PCG) signals is proposed in this paper.The proposed system is a combination of deep learning based convolutional neural network (CNN) and power spectrogram Cardi-Net, which can extract deep discriminating features of PCG signals from the power spectrogram to identify the diseases. The choice of Power Spectral Density (PSD) makes the model extract highly discriminatory features significant for the multi-classification of four common cardiac disorders.Data augmentation techniques are applied to make the model robust, and the model undergoes 10-fold cross-validation to yield an overall accuracy of 98.879% on the test dataset to diagnose multi heart diseases from PCG signals.The proposed model is completely automatic, where signal pre-processing and feature engineering are not required. The conversion time of power spectrogram from PCG signals is very low range from 0.10 s to 0.11 s. This reduces the complexity of the model, making it highly reliable and robust for real-time applications. The proposed architecture can be deployed on cloud and a low cost processor, desktop, android app leading to proper access to the dispensaries in remote areas.",'multi heart diseases',0.530647352,'0.10 s to 0.11 s',0.010022751,'diagnose multi heart diseases from PCG signals',0.257785454,'Phonocardiogram (PCG) signals',0.64721553,'10-fold cross-validation to yield an overall accuracy of 98.879% on the test dataset',0.000162701,'PCG signals',0.001205131,"'Phonocardiogram (PCG) signals is proposed in this paper.The proposed system is a combination of deep learning based convolutional neural network (CNN) and power spectrogram Cardi-Net, which can extract deep discriminating features of PCG signals from the power spectrogram to identify the diseases. The choice of Power Spectral Density (PSD)'",0.05134622,"'Phonocardiogram (PCG) signals is proposed in this paper.The proposed system is a combination of deep learning based convolutional neural network (CNN) and power spectrogram Cardi-Net, which can extract deep discriminating features of PCG signals from the power spectrogram to identify the diseases. The choice of Power Spectral Density (PSD)'",0.05134622
99,35317470,Development of portable and robust cataract detection and grading system by analyzing multiple texture features for Tele-Ophthalmology.,"This paper presents a low cost, robust, portable and automated cataract detection system which can detect the presence of cataract from the colored digital eye images and grade their severity. Ophthalmologists detect cataract through visual screening using ophthalmoscope and slit lamps. Conventionally a patient has to visit an ophthalmologist for eye screening and treatment follows the course. Developing countries lack the proper health infrastructure and face huge scarcity of trained medical professionals as well as technicians. The condition is not very satisfactory with the rural and remote areas of developed nations. To bridge this barrier between the patient and the availability of resources, current work focuses on the development of portable low-cost, robust cataract screening and grading system. Similar works use fundus and retinal images which use costly imaging modules and image based detection algorithms which use much complex neural network models. Current work derives its benefit from the advancements in digital image processing techniques. A set of preprocessing has been done on the colored eye image and later texture information in form of mean intensity, uniformity, standard deviation and randomness has been calculated and mapped with the diagnostic opinion of doctor for cataract screening of over 200 patients. For different grades of cataract severity edge pixel count was calculated as per doctor's opinion and later these data are used for calculating the thresholds using hybrid k-means algorithm, for giving a decision on the presence of cataract and grade its severity. Low value of uniformity and high value of other texture parameters confirm the presence of cataract as clouding in eye lens causes the uniformity function to take lower value due to presence of coarse texture. Higher the edge pixel count value, this confirms the presence of starting of cataract as solidified regions in lens are nonuniform. Lower value corresponds to fully solidified region or matured cataract. Proposed algorithm was initially developed on MATLAB, and tested on over 300 patients in an eye camp. The system has shown more than 98% accuracy in detection and grading of cataract. Later a cloud based system was developed with 3D printed image acquisition module to manifest an automated, portable and efficient cataract detection system for Tele-Ophthalmology. The proposed system uses a very simple and efficient technique by mapping the diagnostic opinion of the doctor as well, giving very promising results which suggest its potential use in teleophthalmology applications to reduce the cost of delivering eye care services and increasing its reach effectively. Developed system is simple in design and easy to operate and suitable for mass screening of cataracts. Due to non-invasive and non-mydriatic and mountable nature of device, in person screening is not required. Hence, social distancing norms are easy to follow and device is very useful in COVID-19 like situation.",'cataract from the colored digital eye images and grade their severity. Ophthalmologists detect cataract',0.150187656,'over 200',0.053320963,'grade their severity',0.512320951,'colored digital eye images',0.620235234,'Developing countries',0.01620043,'COVID-19',0.002700823,'COVID-19',0.126231939,'COVID-19',0.126231939
