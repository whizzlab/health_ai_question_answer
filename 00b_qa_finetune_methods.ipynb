{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4522f12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e67f3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44330449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.base -  Numba not found, replacing njit() with no-op implementation. Enable it with 'pip install numba'.\n",
      "INFO - haystack.modeling.model.optimization -  apex not found, won't use it. See https://nvidia.github.io/apex/\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import FARMReader\n",
    "from haystack.utils import fetch_archive_from_http"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3ae3b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find franklu/pubmed_bert_squadv2 locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Loaded franklu/pubmed_bert_squadv2\n",
      "INFO - haystack.modeling.logger -  ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "INFO - haystack.modeling.utils -  Using devices: CUDA\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.infer -  Got ya 15 parallel workers to do inference ...\n",
      "INFO - haystack.modeling.infer -   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "INFO - haystack.modeling.infer -  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /|\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /|\\\n",
      "INFO - haystack.modeling.infer -  /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\  /'\\  /'\\  /'\\  /'\\  /'\\  / \\  /'\\  /'\\\n",
      "INFO - haystack.modeling.utils -  Using devices: CUDA\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.data_handler.data_silo -  \n",
      "Loading data into the data silo ... \n",
      "              ______\n",
      "               |o  |   !\n",
      "   __          |:`_|---'-.\n",
      "  |__|______.-/ _ \\-----.|       \n",
      " (o)(o)------'\\ _ /     ( )      \n",
      " \n",
      "INFO - haystack.modeling.data_handler.data_silo -  LOADING TRAIN DATA\n",
      "INFO - haystack.modeling.data_handler.data_silo -  ==================\n",
      "INFO - haystack.modeling.data_handler.data_silo -  Loading train set from: data\\domain_training_methods.json \n",
      "INFO - haystack.modeling.data_handler.data_silo -  Got ya 5 parallel workers to convert 25 dictionaries to pytorch datasets (chunksize = 5)...\n",
      "INFO - haystack.modeling.data_handler.data_silo -   0    0    0    0    0 \n",
      "INFO - haystack.modeling.data_handler.data_silo -  /w\\  /w\\  /w\\  /w\\  /w\\\n",
      "INFO - haystack.modeling.data_handler.data_silo -  /'\\  / \\  /'\\  /'\\  / \\\n",
      "Preprocessing Dataset data\\domain_training_methods.json: 100%|█████████████████████| 25/25 [00:08<00:00,  2.81 Dicts/s]\n",
      "INFO - haystack.modeling.data_handler.data_silo -  \n",
      "INFO - haystack.modeling.data_handler.data_silo -  LOADING DEV DATA\n",
      "INFO - haystack.modeling.data_handler.data_silo -  =================\n",
      "INFO - haystack.modeling.data_handler.data_silo -  No dev set is being loaded\n",
      "INFO - haystack.modeling.data_handler.data_silo -  \n",
      "INFO - haystack.modeling.data_handler.data_silo -  LOADING TEST DATA\n",
      "INFO - haystack.modeling.data_handler.data_silo -  =================\n",
      "INFO - haystack.modeling.data_handler.data_silo -  No test set is being loaded\n",
      "INFO - haystack.modeling.data_handler.data_silo -  \n",
      "INFO - haystack.modeling.data_handler.data_silo -  DATASETS SUMMARY\n",
      "INFO - haystack.modeling.data_handler.data_silo -  ================\n",
      "INFO - haystack.modeling.data_handler.data_silo -  Examples in train: 1427\n",
      "INFO - haystack.modeling.data_handler.data_silo -  Examples in dev  : 0\n",
      "INFO - haystack.modeling.data_handler.data_silo -  Examples in test : 0\n",
      "INFO - haystack.modeling.data_handler.data_silo -  Total examples   : 1427\n",
      "INFO - haystack.modeling.data_handler.data_silo -  \n",
      "INFO - haystack.modeling.data_handler.data_silo -  Longest sequence length observed after clipping:     256\n",
      "INFO - haystack.modeling.data_handler.data_silo -  Average sequence length after clipping: 250.62648913805185\n",
      "INFO - haystack.modeling.data_handler.data_silo -  Proportion clipped:      0.9201121233356693\n",
      "INFO - haystack.modeling.data_handler.data_silo -  [Haystack Tip] 92.0% of your samples got cut down to 256 tokens. Consider increasing max_seq_len. This will lead to higher memory consumption but is likely to improve your model performance\n",
      "INFO - haystack.modeling.model.optimization -  Loading optimizer `AdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}'\n",
      "INFO - haystack.modeling.model.optimization -  Using scheduler 'get_linear_schedule_with_warmup'\n",
      "INFO - haystack.modeling.model.optimization -  Loading schedule `get_linear_schedule_with_warmup`: '{'num_training_steps': 143, 'num_warmup_steps': 28}'\n",
      "Train epoch 0/0 (Cur. train loss: 0.0900): 100%|█████████████████████████████████████| 143/143 [00:20<00:00,  6.97it/s]\n",
      "INFO - haystack.nodes.reader.farm -  Saving reader model to model\n"
     ]
    }
   ],
   "source": [
    "#reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)\n",
    "reader = FARMReader(model_name_or_path=\"franklu/pubmed_bert_squadv2\", use_gpu=True)\n",
    "data_dir = \"data/\"\n",
    "# data_dir = \"PATH/TO_YOUR/TRAIN_DATA\"\n",
    "reader.train(data_dir=data_dir, train_filename=\"domain_training_methods.json\", use_gpu=True, n_epochs=1, save_dir=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "859bce08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.reader.farm -  Saving reader model to pubmed_tuned_methods\n"
     ]
    }
   ],
   "source": [
    "reader.save(directory=\"pubmed_tuned_methods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67b757d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
