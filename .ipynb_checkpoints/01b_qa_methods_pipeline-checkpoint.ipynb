{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30bc93f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60a63b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adc163f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.base -  Numba not found, replacing njit() with no-op implementation. Enable it with 'pip install numba'.\n",
      "INFO - haystack.modeling.model.optimization -  apex not found, won't use it. See https://nvidia.github.io/apex/\n"
     ]
    }
   ],
   "source": [
    "from haystack.utils import clean_wiki_text, convert_files_to_dicts, fetch_archive_from_http, print_answers\n",
    "from haystack.nodes import FARMReader, TransformersReader\n",
    "from haystack.nodes import TextConverter, PDFToTextConverter, DocxToTextConverter, PreProcessor\n",
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "\n",
    "#haystack contains a search system for retrieval and QA across documents.\n",
    "#designed for large documents, but pipeline also works for single document QA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b6ab6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-Memory Document Store\n",
    "from haystack.document_stores import InMemoryDocumentStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae4dc9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve from store\n",
    "from haystack.nodes import TfidfRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8928dda",
   "metadata": {},
   "source": [
    "# import file containing all abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6982af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23767</th>\n",
       "      <td>35011970</td>\n",
       "      <td>10.3390/jcm11010229</td>\n",
       "      <td>An Application of Machine Learning That Uses the Magnetic Resonance Imaging ...</td>\n",
       "      <td>This retrospective single-center study included patients diagnosed with epit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34412</th>\n",
       "      <td>34972109</td>\n",
       "      <td>10.1371/journal.pone.0261698</td>\n",
       "      <td>DAVS-NET: Dense Aggregation Vessel Segmentation Network for retinal vasculat...</td>\n",
       "      <td>In this era, deep learning-based medical image analysis has become a reliabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29263</th>\n",
       "      <td>34971557</td>\n",
       "      <td>10.1371/journal.pone.0260600</td>\n",
       "      <td>Optical coherence tomography for identification of malignant pulmonary nodul...</td>\n",
       "      <td>To explore the feasibility of using random forest (RF) machine learning algo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26000</th>\n",
       "      <td>35005197</td>\n",
       "      <td>10.1002/dad2.12264</td>\n",
       "      <td>Deep learning improves utility of tau PET in the study of Alzheimer's disease.</td>\n",
       "      <td>Positron emission tomography (PET) imaging targeting neurofibrillary tau tan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39158</th>\n",
       "      <td>34969093</td>\n",
       "      <td>10.1093/cercor/bhab474</td>\n",
       "      <td>Predicting Superagers by Machine Learning Classification Based on the Functi...</td>\n",
       "      <td>Superagers are defined as older adults who have youthful memory performance ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pmid                           doi  \\\n",
       "23767  35011970           10.3390/jcm11010229   \n",
       "34412  34972109  10.1371/journal.pone.0261698   \n",
       "29263  34971557  10.1371/journal.pone.0260600   \n",
       "26000  35005197            10.1002/dad2.12264   \n",
       "39158  34969093        10.1093/cercor/bhab474   \n",
       "\n",
       "                                                                                 title  \\\n",
       "23767  An Application of Machine Learning That Uses the Magnetic Resonance Imaging ...   \n",
       "34412  DAVS-NET: Dense Aggregation Vessel Segmentation Network for retinal vasculat...   \n",
       "29263  Optical coherence tomography for identification of malignant pulmonary nodul...   \n",
       "26000   Deep learning improves utility of tau PET in the study of Alzheimer's disease.   \n",
       "39158  Predicting Superagers by Machine Learning Classification Based on the Functi...   \n",
       "\n",
       "                                                                              abstract  \n",
       "23767  This retrospective single-center study included patients diagnosed with epit...  \n",
       "34412  In this era, deep learning-based medical image analysis has become a reliabl...  \n",
       "29263  To explore the feasibility of using random forest (RF) machine learning algo...  \n",
       "26000  Positron emission tomography (PET) imaging targeting neurofibrillary tau tan...  \n",
       "39158  Superagers are defined as older adults who have youthful memory performance ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basedf = pd.read_csv('data/decade_abstracts.csv', index_col=0)\n",
    "basedf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e66bb980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joe Z\\AppData\\Local\\Temp\\ipykernel_18080\\2635964149.py:1: DtypeWarning: Columns (25,26,27,28,29,30,31,32,33,34,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  methods = pd.read_csv('data/05_methods_combined.csv', index_col=0)\n"
     ]
    }
   ],
   "source": [
    "methods = pd.read_csv('data/05_methods_combined.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d7fb9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>methods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35005676</td>\n",
       "      <td>methods we enrolled patients from the university of washington healthcare sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34998166</td>\n",
       "      <td>materials and methods in this paper, a novel tmsf-net is proposed to compens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34979435</td>\n",
       "      <td>materials and methods deep learning architectures are formed by a sequential...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35045383</td>\n",
       "      <td>dataset the cnn model used in this manuscript and was trained on the patch c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34979213</td>\n",
       "      <td>methods this retrospective study was conducted under a hippa-compliant irb p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid  \\\n",
       "0  35005676   \n",
       "1  34998166   \n",
       "2  34979435   \n",
       "3  35045383   \n",
       "4  34979213   \n",
       "\n",
       "                                                                           methods  \n",
       "0  methods we enrolled patients from the university of washington healthcare sy...  \n",
       "1  materials and methods in this paper, a novel tmsf-net is proposed to compens...  \n",
       "2  materials and methods deep learning architectures are formed by a sequential...  \n",
       "3  dataset the cnn model used in this manuscript and was trained on the patch c...  \n",
       "4  methods this retrospective study was conducted under a hippa-compliant irb p...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methodsdf = methods[['pmid', '0']].copy()\n",
    "methodsdf = methodsdf.rename(columns={'0':'methods'})\n",
    "methodsdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9e134b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf = basedf.merge(methodsdf, on='pmid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1393f13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf_m = fulldf[fulldf['methods'].notnull()].reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e155e29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27252"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fulldf_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18deeeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_list = fulldf_m['methods'].tolist()\n",
    "title_list = list(range(0,len(methods_list)))\n",
    "\n",
    "pmid_list = fulldf_m['pmid'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8b2e498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>methods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35011970</td>\n",
       "      <td>10.3390/jcm11010229</td>\n",
       "      <td>An Application of Machine Learning That Uses the Magnetic Resonance Imaging ...</td>\n",
       "      <td>This retrospective single-center study included patients diagnosed with epit...</td>\n",
       "      <td>2. methods this retrospective, single-centre study included patients who und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34972109</td>\n",
       "      <td>10.1371/journal.pone.0261698</td>\n",
       "      <td>DAVS-NET: Dense Aggregation Vessel Segmentation Network for retinal vasculat...</td>\n",
       "      <td>In this era, deep learning-based medical image analysis has become a reliabl...</td>\n",
       "      <td>3 proposed methodology in this work, we propose davs-net architecture for ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34971557</td>\n",
       "      <td>10.1371/journal.pone.0260600</td>\n",
       "      <td>Optical coherence tomography for identification of malignant pulmonary nodul...</td>\n",
       "      <td>To explore the feasibility of using random forest (RF) machine learning algo...</td>\n",
       "      <td>methods to explore the feasibility of using random forest (rf) machine learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35005197</td>\n",
       "      <td>10.1002/dad2.12264</td>\n",
       "      <td>Deep learning improves utility of tau PET in the study of Alzheimer's disease.</td>\n",
       "      <td>Positron emission tomography (PET) imaging targeting neurofibrillary tau tan...</td>\n",
       "      <td>methods research in context 1. systematic review: the authors reviewed the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34969093</td>\n",
       "      <td>10.1093/cercor/bhab474</td>\n",
       "      <td>Predicting Superagers by Machine Learning Classification Based on the Functi...</td>\n",
       "      <td>Superagers are defined as older adults who have youthful memory performance ...</td>\n",
       "      <td>['materials and methods community-dwelling volunteers aged 60\\xa0years or ol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid                           doi  \\\n",
       "0  35011970           10.3390/jcm11010229   \n",
       "1  34972109  10.1371/journal.pone.0261698   \n",
       "2  34971557  10.1371/journal.pone.0260600   \n",
       "3  35005197            10.1002/dad2.12264   \n",
       "4  34969093        10.1093/cercor/bhab474   \n",
       "\n",
       "                                                                             title  \\\n",
       "0  An Application of Machine Learning That Uses the Magnetic Resonance Imaging ...   \n",
       "1  DAVS-NET: Dense Aggregation Vessel Segmentation Network for retinal vasculat...   \n",
       "2  Optical coherence tomography for identification of malignant pulmonary nodul...   \n",
       "3   Deep learning improves utility of tau PET in the study of Alzheimer's disease.   \n",
       "4  Predicting Superagers by Machine Learning Classification Based on the Functi...   \n",
       "\n",
       "                                                                          abstract  \\\n",
       "0  This retrospective single-center study included patients diagnosed with epit...   \n",
       "1  In this era, deep learning-based medical image analysis has become a reliabl...   \n",
       "2  To explore the feasibility of using random forest (RF) machine learning algo...   \n",
       "3  Positron emission tomography (PET) imaging targeting neurofibrillary tau tan...   \n",
       "4  Superagers are defined as older adults who have youthful memory performance ...   \n",
       "\n",
       "                                                                           methods  \n",
       "0  2. methods this retrospective, single-centre study included patients who und...  \n",
       "1  3 proposed methodology in this work, we propose davs-net architecture for ro...  \n",
       "2  methods to explore the feasibility of using random forest (rf) machine learn...  \n",
       "3  methods research in context 1. systematic review: the authors reviewed the l...  \n",
       "4  ['materials and methods community-dwelling volunteers aged 60\\xa0years or ol...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldf_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "792e4172",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['materials and methods community-dwelling volunteers aged 60\\\\xa0years or older were recruited from the gangseo center for dementia or yangcheon dementia center, two public facilities for dementia prevention in seoul. from march to august in 2018, a total of 134 older adults agreed to participate in this study. a neurologist evaluated eligibility using the following inclusion criteria: aged 60\\\\xa0years or older, able to read and write, scored >\\\\u2009\\\\u20091.5 standard deviation (sd) of the mean of age and education-matched norm on the korean version of mini-mental state examination (k-mmse) ( ), and with typical cognitive function defined as scoring higher than 1 sd (16th percentile) of the demographically matched norm on the tests of memory, attention, language, and visuospatial and frontal executive functions in the seoul neuropsychological screening battery-ii (snsb-ii) ( ). we excluded individuals with any of the following characteristics: 1) suspected or diagnosed with mild cognitive impairment or dementia; 2) suspected or diagnosed with a major neurological or psychiatric illness, including major depressive disorders; 3) any contraindications to magnetic resonance imaging (mri); 4) visual or hearing impairments severe enough to interfere with questionnaire response; 5) history of medications that could affect cognitive and emotional functions in the last 3\\\\xa0months; or 6) any other major medical problems. of the 134 participants, 24 individuals did not meet the inclusion criteria while 20 refused the evaluation of the study including mri. therefore, a total of 90 older adults finally participated in this study. all participants underwent mri and cognitive function tests using the snsb-ii. mri scans were conducted within 3\\\\xa0months before and after the cognitive function tests. the definition of superagers was based on memory performance at or above average normative values of middle-aged adults (45-year-olds) on tests of delayed recall in both the seoul verbal learning test (svlt) and the rey osterrieth complex figure test (rcft), in conjunction with scores in other cognitive domains that were at least average for age ( written informed consent was obtained from all participants prior to study participation, and this study was approved by the institutional review board of ewha womans university mokdong hospital (irb approval number: 2017-12-047). all participants were administered a standardized neuropsychological battery using the snsb-ii: digit span test (dst) forward and backward for attention; korean version of the boston naming test for language; rcft for visuospatial function and visual memory; svlt for verbal memory; phonemic and semantic controlled oral word association test; korean-color word stroop test; digit symbol coding; and korean trail making test-elderlys version for executive functions. age- and education-specific  a 3.0-tesla philips achieva mr scanner (philips medical system, the netherlands) was used for acquisition of t1-weighted structural mri and resting-state functional mri (rsfmri) data. structural images were acquired using a three-dimensional t1-weighted magnetization-prepared rapid gradient echo imaging sequence with the following acquisition parameters: repetition time (tr)\\\\u2009=\\\\u20099.9\\\\xa0ms, echo time (te)\\\\u2009=\\\\u20094.6\\\\xa0ms, flip angle (fa)\\\\u2009=\\\\u20098, field of view (fov)\\\\u2009=\\\\u2009240\\\\u2009\\\\u2009240\\\\xa0mm , slice thickness\\\\u2009=\\\\u20091\\\\xa0mm, and number of excitation\\\\u2009=\\\\u20091; 160 contiguous sagittal slices. resting-state functional images were acquired using an echo planar imaging sequence with the following parameters: tr\\\\u2009=\\\\u20093000\\\\xa0ms, te\\\\u2009=\\\\u200935\\\\xa0ms, fa\\\\u2009=\\\\u200990, fov\\\\u2009=\\\\u2009220\\\\u2009\\\\u2009220\\\\xa0mm ; slice thickness\\\\u2009=\\\\u20094.0\\\\xa0mm for 35 slices. participants were instructed to think of nothing in particular, keep their eyes closed, and stay awake. an automated shimming procedure was used to reduce the influence of field inhomogeneities before performing rsfmri scans. ), rsfmri data were preprocessed following the order of spatial realignment for correction of head movement, normalization to the same coordinate frame as the template brain in the standard space, spatial smoothing with a gaussian kernel of 8\\\\xa0mm full width at half maximum, linear detrending for removing systematic signal increases or decreases, and band-pass filtering at 0.010.08\\\\xa0hz for removing physiological noise. ), representative signals were extracted via the singular value decomposition of voxel-wise signals. functional connectivity between each pair of nodes was estimated by computing the partial correlation between the two signals, after adjusting for the effect of confounding time courses. head movement parameters estimated through spatial realignment and non-neuronal fluctuations extracted from white matter and cerebrospinal fluid were considered as confounding time courses. functional connectivity measures were provided by converting partial correlation coefficients into approximately normally distributed values using fisher transformation. the brain functional connectome consisted of the 90 nodes and functional connection strength assigned to all pairs of nodes, which could be represented as a 90\\\\u2009\\\\u200990 symmetric matrix for each individual. for this study, we specifically used the brain functional connectome as the set of functional connections in the brain. we applied the brain functional connectome in the framework of brain connectome-based predictive modeling, in which functional connection strength served as features. machine learning furnished a predictive model for differentiating superagers from typical agers. the 90\\\\u2009\\\\u200990 symmetric matrix corresponding to the brain functional connectome contained 4005 unique features. for each of these features, a two-sample   test was applied to compare the values between superagers and typical agers. a variable was selected as a sufficiently important feature for contributing to the classification when the   value \\\\u20090.05. among 4005 features, a total of 244 features (6%) were selected for the construction of the three classifiers, which are provided in   tests. the selected features, together with the potential confounding variables of age, sex, and years of education, resulted in a matrix containing a row per instance and a column per feature. the dataset was finally composed of this matrix in addition to a vector of the individuals actual class labels. the dataset was randomly divided into 80% of data for training and the remaining 20% for testing by preserving the percentage of samples for each class. for the training dataset, a scaler was fit to transform the features, such that they had a zero mean and unit variance. a fitted scaler was used to transform the features of the test dataset as well. to build predictive models for the classification of elderly individuals into superagers and typical agers, three machine learning methods were used in this study, including the linear support vector machines, the random forests, and the logistic regression, as implemented in the scikit-learn python library ( ). two classes were classified by fitting the largest possible margin between them with the linear support vector machines, by fitting classification rules for an ensemble of decision trees with random forests, and by estimating the probability that an instance belongs to a particular class via logistic regression with l2 regularization. we applied three machine learning methods to the training dataset to fit parameters and build respective predictive models. namely, we applied a linear support vector machines classifier (sv), a random forest classifier (rf), and a logistic regression classifier (lr). in training the three classifiers, hyperparameters for regularizing the classifiers were tuned using 5-fold cross-validation (i.e. splitting the training dataset into 5folds) to avoid overfitting the training dataset. in addition, we aggregated the predictions of the ensemble of classifiers to create a classifier that was superior to the best classifier among the three. specifically, we used the soft voting method, in which the probability of belonging to each class averaged over the three classifiers was compared, and the class with the highest probability was predicted. to compare the classifiers, we employed accuracy (referring to the ratio of correctly classified individuals). although accuracy is widely used as a performance measure for classifiers, it may not always be the preferred measure with respect to the precision-recall trade-off, which refers to the fact that it is not possible to increase the ratios of instances correctly predicted as positive, both among instances predicted as positive and among instances that are actually positive. thus, we also used the receiver operating characteristic (roc) curve, which describes a trade-off similar to the precision-recall trade-off by plotting the true positive rate against the false-positive rate according to changes in a decision threshold at which predictions are made. specifically, we employed the area under the roc curve (auc) as a concise metric; whereas a random classifier has an auc of 0.5, a good classifier tends to be as far away from the random classifier as possible (i.e. trending toward a higher auc). these performance measures were computed for predictions made by the classifiers on the test dataset that were unseen during training. having found the best classifier in terms of performance measures, we visualized the degree to which each functional connection contributed to the classification. specifically, we visualized the weight of each feature in the case of the sv and lr, and the importance of each feature in the case of the rf. in addition, the weight or importance of features was mapped onto each node by summing the values over functional connections either endpoint of which corresponded to the node. although the classifiers were primarily aimed to predict the class labels of superagers and typical agers, the probability of belonging to the predicted class could also be estimated from the classifiers. thus, we additionally examined correlations between class probabilities and memory scores. the memory scores were converted to standardized   scores using the group mean scores and sds for each participant. spearman correlations between class probabilities from the best classifier and memory scores were assessed separately for the individuals in the training and test datasets. a correlation coefficient that satisfied a ']\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods_list[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b732ef73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(methods_list))\n",
    "print(len(fulldf_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578ba18d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test match\n",
    "#n = 9\n",
    "#\n",
    "#test = methods_list[n]\n",
    "#pmid = pmid_list[n]\n",
    "#test_dict = {'content': test, 'meta': {'name': pmid}}\n",
    "#\n",
    "#test_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91128e36",
   "metadata": {},
   "source": [
    "# set up question bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e922a3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q1=\"what disease is being studied?\"\n",
    "#q2=\"What is the objective of the study?\"\n",
    "###\n",
    "q3=\"how many patient data samples were included in this study?\"\n",
    "#q4=\"what modality of data is used in this study?\"\n",
    "###\n",
    "#q5=\"what country was the study conducted in?\"\n",
    "#q6=\"what hospital did the data come from?\"\n",
    "q7=\"What existing data source did the data come from?\"\n",
    "q8=\"What location did the data come from?\"\n",
    "###\n",
    "#q10=\"how does the model perform relative to a human?\"\n",
    "#q11=\"how does the model perform in prospective testing\"\n",
    "#q12=\"what were the results of the study?\"\n",
    "#q12=\"what was the area under the curve (AUC) value?\"\n",
    "qlist = [q3, q7, q8]\n",
    "#qlist = [q1, q2, q3, q4, q5, q6, q7, q8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bade33d",
   "metadata": {},
   "source": [
    "# initialising pre-processor module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5108f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = PreProcessor(\n",
    "    clean_empty_lines=True,\n",
    "    clean_whitespace=True,\n",
    "    clean_header_footer=False,\n",
    "    split_by=\"word\",\n",
    "    split_length=2000,\n",
    "    split_respect_sentence_boundary=True,\n",
    ")\n",
    "\n",
    "document_store = InMemoryDocumentStore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880131d6",
   "metadata": {},
   "source": [
    "# hugging face model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b1e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reader scans text returned by retriever and extracts k-best answers\n",
    "# Load a fine-tuned  model (e.g. RoBERTa QA = \"deepset/roberta-base-squad2\")\n",
    "# alternatives (Reader): TransformersReader (leveraging the pipeline of the Transformers package)\n",
    "# alternatives (Models): e.g. \"distilbert-base-uncased-distilled-squad\" (fast) or \"deepset/bert-large-uncased-whole-word-masking-squad2\" (good accuracy)\n",
    "# can adjust the model to return \"no answer possible\" with the no_ans_boost. Higher values mean the model prefers \"no answer possible\"\n",
    "# alternatively, QA models on model hub (https://huggingface.co/models)\n",
    "#sota: ahotrod/albert_xxlargev1_squad2_512\n",
    "#dmis-lab/biobert-large-cased-v1.1-squad\n",
    "#\n",
    "#reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True, use_confidence_scores=True)\n",
    "#sets pipeline to contain retriever and reader\n",
    "#pipe = ExtractiveQAPipeline(reader, retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b93070",
   "metadata": {},
   "source": [
    "# question answer pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90569010",
   "metadata": {},
   "outputs": [],
   "source": [
    "##create dataframe to hold results\n",
    "\n",
    "resultsdf = fulldf_m[['pmid', 'title', 'methods']].copy()\n",
    "\n",
    "for q in qlist:\n",
    "    resultsdf[q] = pd.Series(dtype='object')\n",
    "    \n",
    "#resultsdf['q1_disease'] = pd.Series(dtype='object')\n",
    "#resultsdf['q2_objective'] = pd.Series(dtype='object')\n",
    "#resultsdf['q3_size'] = pd.Series(dtype='object')\n",
    "#resultsdf['q4_modality'] = pd.Series(dtype='object')\n",
    "#resultsdf['q5_country'] = pd.Series(dtype='object')\n",
    "#resultsdf['q6_hospital'] = pd.Series(dtype='object')\n",
    "#resultsdf['q7_database'] = pd.Series(dtype='object')\n",
    "#resultsdf['q8_organisation'] = pd.Series(dtype='object')\n",
    "\n",
    "print(len(resultsdf))\n",
    "resultsdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08745d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#qa_df = resultsdf[0:50]\n",
    "qa_df = resultsdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0f2b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = TfidfRetriever(document_store=document_store)\n",
    "tuned_reader = FARMReader(model_name_or_path=\"pubmed_tuned_methods\", use_gpu=True, use_confidence_scores=True)\n",
    "tuned_pipe = ExtractiveQAPipeline(tuned_reader, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6893c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "for i, row in tqdm(qa_df.iterrows()):\n",
    "    try:\n",
    "        #set up dict for new methods\n",
    "        methods_dict = {'content': methods_list[i], 'meta': {'name': title_list[i]}}\n",
    "        docs_proc = preprocessor.process(methods_dict)\n",
    "            #####test#####print(f\"n_docs_input: 1\\nn_docs_output: {len(docs_proc)}\")\n",
    "    \n",
    "        #dump old doc store, and import next document into doc store\n",
    "        document_store.delete_documents()\n",
    "        document_store.write_documents(docs_proc)\n",
    "    \n",
    "        #set up pipeline\n",
    "        retriever = TfidfRetriever(document_store=document_store)\n",
    "        tuned_pipe = ExtractiveQAPipeline(tuned_reader, retriever)\n",
    "        \n",
    "        #run pipeline for current 'i'\n",
    "        plist = qlist.copy() #same length list to set-up iteration through question bank\n",
    "        l = len(qlist)\n",
    "    \n",
    "        temp_list = []\n",
    "        temp_list = [row['pmid'], row['title'], row['methods']]\n",
    "        \n",
    "        try:\n",
    "            for answer in range(0,l):\n",
    "                plist[answer] = tuned_pipe.run(\n",
    "                    query=qlist[answer], params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}}\n",
    "                )\n",
    "        \n",
    "            #append top answer for each row/question\n",
    "            #print(plist[answer]['answers'][0])\n",
    "                temp_list.append(plist[answer]['answers'][0])\n",
    "        \n",
    "            qa_df.loc[i] = temp_list\n",
    "    \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "#measure time\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6b7205",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df.to_csv('output/methods_interim.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b2fc60",
   "metadata": {},
   "source": [
    "# clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ebb0ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleandf = qa_df.copy().applymap(str)\n",
    "cleandf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ef6119",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create lists for answer/score pairs\n",
    "disease_score = []\n",
    "disease_answer = []\n",
    "question_score = []\n",
    "question_answer = []\n",
    "sample_score = []\n",
    "sample_answer = []\n",
    "modality_score = []\n",
    "modality_answer = []\n",
    "country_score = []\n",
    "country_answer = []\n",
    "hospital_score = []\n",
    "hospital_answer = []\n",
    "database_score = []\n",
    "database_answer = []\n",
    "organisation_score = []\n",
    "organisation_answer = []\n",
    "\n",
    "#categories = [disease_score, disease_answer, sample_score, sample_answer, modality_score, modality_answer,\n",
    "#              country_score, country_answer, hospital_score, hospital_answer, database_score, database_answer,\n",
    "#              organisation_score, organisation_answer]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4556a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = cleandf.iloc[34,5]\n",
    "\n",
    "## start/end strings for scores and answers\n",
    "score_start = 'score='\n",
    "score_end = ', context'\n",
    "print((s.split(score_start))[1].split(score_end)[0])\n",
    "\n",
    "answer_start = 'answer='\n",
    "answer_end = ', score'\n",
    "print((s.split(answer_start))[1].split(answer_end)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9071ccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in tqdm(cleandf.iterrows()):\n",
    "    try:\n",
    "        #disease_score.append((row['what disease is being studied?'].split(score_start))[1].split(score_end)[0])\n",
    "        #disease_answer.append((row['what disease is being studied?'].split(answer_start))[1].split(answer_end)[0])\n",
    "        sample_score.append((row['how many patient data samples were included in this study?'].split(score_start))[1].split(score_end)[0])\n",
    "        sample_answer.append((row['how many patient data samples were included in this study?'].split(answer_start))[1].split(answer_end)[0])\n",
    "        #question_score.append((row['What is the objective of the study?'].split(score_start))[1].split(score_end)[0])\n",
    "        #question_answer.append((row['What is the objective of the study?'].split(answer_start))[1].split(answer_end)[0])\n",
    "        #modality_score.append((row['what modality of data is used in this study?'].split(score_start))[1].split(score_end)[0])\n",
    "        #modality_answer.append((row['what modality of data is used in this study?'].split(answer_start))[1].split(answer_end)[0])\n",
    "        #country_score.append((row['what country was the study conducted in?'].split(score_start))[1].split(score_end)[0])\n",
    "        #country_answer.append((row['what country was the study conducted in?'].split(answer_start))[1].split(answer_end)[0])    \n",
    "        #hospital_score.append((row['what hospital did the data come from?'].split(score_start))[1].split(score_end)[0])\n",
    "        #hospital_answer.append((row['what hospital did the data come from?'].split(answer_start))[1].split(answer_end)[0])\n",
    "        database_score.append((row[\"What existing data source did the data come from?\"].split(score_start))[1].split(score_end)[0])\n",
    "        database_answer.append((row[\"What existing data source did the data come from?\"].split(answer_start))[1].split(answer_end)[0])\n",
    "        organisation_score.append((row[\"What location did the data come from?\"].split(score_start))[1].split(score_end)[0])\n",
    "        organisation_answer.append((row[\"What location did the data come from?\"].split(answer_start))[1].split(answer_end)[0])  \n",
    "    except:\n",
    "        #disease_score.append('nan')\n",
    "        #disease_answer.append('nan')\n",
    "        sample_score.append('nan')\n",
    "        sample_answer.append('nan')\n",
    "        #question_score.append('nan')\n",
    "        #question_answer.append('nan')\n",
    "        #modality_score.append('nan')\n",
    "        #modality_answer.append('nan')\n",
    "        #country_score.append('nan')\n",
    "        #country_answer.append('nan') \n",
    "        #hospital_score.append('nan')\n",
    "        #hospital_answer.append('nan')\n",
    "        database_score.append('nan')\n",
    "        database_answer.append('nan')\n",
    "        organisation_score.append('nan')\n",
    "        organisation_answer.append('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bed5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoredf = cleandf[['pmid', 'title', 'methods']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3825d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scoredf['disease_answer'] = disease_answer\n",
    "#scoredf['disease_answer'] = scoredf['disease_answer'].str[1:-1]\n",
    "#scoredf['disease_score'] = disease_score\n",
    "\n",
    "scoredf['sample_answer'] = sample_answer\n",
    "scoredf['sample_answer'] = scoredf['sample_answer'].str[1:-1]\n",
    "scoredf['sample_score'] = sample_score\n",
    "\n",
    "#scoredf['question_answer'] = question_answer\n",
    "#scoredf['question_answer'] = scoredf['question_answer'].str[1:-1]\n",
    "#scoredf['question_score'] = question_score\n",
    "\n",
    "#scoredf['modality_answer'] = modality_answer\n",
    "#scoredf['modality_answer'] = scoredf['modality_answer'].str[1:-1]\n",
    "#scoredf['modality_score'] = modality_score\n",
    "\n",
    "#scoredf['country_answer'] = country_answer\n",
    "#scoredf['country_answer'] = scoredf['country_answer'].str[1:-1]\n",
    "#scoredf['country_score'] = country_score\n",
    "\n",
    "#scoredf['hospital_answer'] = hospital_answer\n",
    "#scoredf['hospital_answer'] = scoredf['hospital_answer'].str[1:-1]\n",
    "#scoredf['hospital_score'] = hospital_score\n",
    "\n",
    "scoredf['database_answer'] = database_answer\n",
    "scoredf['database_answer'] = scoredf['database_answer'].str[1:-1]\n",
    "scoredf['database_score'] = database_score\n",
    "\n",
    "scoredf['organisation_answer'] = organisation_answer\n",
    "scoredf['organisation_answer'] = scoredf['organisation_answer'].str[1:-1]\n",
    "scoredf['organisation_score'] = organisation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4b9341",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scoredf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5523b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoredf.to_csv('output/methods_scored.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae49b4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20f3129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660132b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6f8aef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
