{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30bc93f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60a63b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adc163f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.base -  Numba not found, replacing njit() with no-op implementation. Enable it with 'pip install numba'.\n",
      "INFO - haystack.modeling.model.optimization -  apex not found, won't use it. See https://nvidia.github.io/apex/\n"
     ]
    }
   ],
   "source": [
    "from haystack.utils import clean_wiki_text, convert_files_to_dicts, fetch_archive_from_http, print_answers\n",
    "from haystack.nodes import FARMReader, TransformersReader\n",
    "from haystack.nodes import TextConverter, PDFToTextConverter, DocxToTextConverter, PreProcessor\n",
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "\n",
    "#haystack contains a search system for retrieval and QA across documents.\n",
    "#designed for large documents, but pipeline also works for single document QA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b6ab6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-Memory Document Store\n",
    "from haystack.document_stores import InMemoryDocumentStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e66bb980",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf = pd.read_csv('data/included_abstracts.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07b92fa",
   "metadata": {},
   "source": [
    "## extract abstracts for annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc017441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotatedf = pd.DataFrame({'document_identifier' : range(0,len(fulldf))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38d44c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotatedf['document_text'] = fulldf['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43d82eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampled = annotatedf.sample(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "449213ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampled.to_csv('data/sample_abstracts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fd9d79",
   "metadata": {},
   "source": [
    "## import docs and load into document store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "18deeeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_list = fulldf['abstract']\n",
    "title_list = list(range(0,len(abstract_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "578ba18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 55\n",
    "test = abstract_list[n]\n",
    "title = title_list[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f2822925",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {'content': test, 'meta': {'name': title}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e377f843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': \"Heart failure (HF) is a major cause of mortality. Accurately monitoring HF progress and adjusting therapies are critical for improving patient outcomes. An experienced cardiologist can make accurate HF stage diagnoses based on combination of symptoms, signs, and lab results from the electronic health records (EHR) of a patient, without directly measuring heart function. We examined whether machine learning models, more specifically the XGBoost model, can accurately predict patient stage based on EHR, and we further applied the SHapley Additive exPlanations (SHAP) framework to identify informative features and their interpretations. Our results indicate that based on structured data from EHR, our models could predict patients' ejection fraction (EF) scores with moderate accuracy. SHAP analyses identified informative features and revealed potential clinical subtypes of HF. Our findings provide insights on how to design computing systems to accurately monitor disease progression of HF patients through continuously mining patients' EHR data.\",\n",
       " 'meta': {'name': 55}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7101d80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_docs_input: 1\n",
      "n_docs_output: 1\n"
     ]
    }
   ],
   "source": [
    "preprocessor = PreProcessor(\n",
    "    clean_empty_lines=True,\n",
    "    clean_whitespace=True,\n",
    "    clean_header_footer=False,\n",
    "    split_by=\"word\",\n",
    "    split_length=2000,\n",
    "    split_respect_sentence_boundary=True,\n",
    ")\n",
    "\n",
    "docs_proc = preprocessor.process(test_dict)\n",
    "print(f\"n_docs_input: 1\\nn_docs_output: {len(docs_proc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ceda6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': \"Heart failure (HF) is a major cause of mortality. Accurately monitoring HF progress and adjusting therapies are critical for improving patient outcomes. An experienced cardiologist can make accurate HF stage diagnoses based on combination of symptoms, signs, and lab results from the electronic health records (EHR) of a patient, without directly measuring heart function. We examined whether machine learning models, more specifically the XGBoost model, can accurately predict patient stage based on EHR, and we further applied the SHapley Additive exPlanations (SHAP) framework to identify informative features and their interpretations. Our results indicate that based on structured data from EHR, our models could predict patients' ejection fraction (EF) scores with moderate accuracy. SHAP analyses identified informative features and revealed potential clinical subtypes of HF. Our findings provide insights on how to design computing systems to accurately monitor disease progression of HF patients through continuously mining patients' EHR data.\",\n",
       "  'meta': {'name': 55, '_split_id': 0}}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "95b5aab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "document_store = InMemoryDocumentStore() #to enable documents stored in local memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ac5b7570",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d16ed82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##now writes the dict to haystack document store\n",
    "\n",
    "document_store.write_documents(docs_proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7896a0cb",
   "metadata": {},
   "source": [
    "## load pipeline components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e216360e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.sparse -  Found 0 candidate paragraphs from 0 docs in DB\n",
      "INFO - haystack.nodes.retriever.sparse -  Found 0 candidate paragraphs from 0 docs in DB\n",
      "WARNING - haystack.nodes.retriever.sparse -  Fit method called with empty document store\n"
     ]
    }
   ],
   "source": [
    "# An in-memory TfidfRetriever based on Pandas dataframes\n",
    "# retrievers narrow down Reader scope to smaller text units\n",
    "# see haystack documentation -> other retrievers\n",
    "\n",
    "from haystack.nodes import TfidfRetriever\n",
    "\n",
    "retriever = TfidfRetriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "616e87df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find deepset/roberta-base-squad2 locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Loaded deepset/roberta-base-squad2\n",
      "INFO - haystack.modeling.logger -  ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "INFO - haystack.modeling.utils -  Using devices: CUDA\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.infer -  Got ya 15 parallel workers to do inference ...\n",
      "INFO - haystack.modeling.infer -   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "INFO - haystack.modeling.infer -  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /|\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /|\\\n",
      "INFO - haystack.modeling.infer -  /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\  /'\\  /'\\  /'\\  /'\\  /'\\  / \\  /'\\  /'\\\n"
     ]
    }
   ],
   "source": [
    "# Reader scans text returned by retriever and extracts k-best answers\n",
    "# Load a fine-tuned  model (e.g. RoBERTa QA = \"deepset/roberta-base-squad2\")\n",
    "# alternatives (Reader): TransformersReader (leveraging the pipeline of the Transformers package)\n",
    "# alternatives (Models): e.g. \"distilbert-base-uncased-distilled-squad\" (fast) or \"deepset/bert-large-uncased-whole-word-masking-squad2\" (good accuracy)\n",
    "# can adjust the model to return \"no answer possible\" with the no_ans_boost. Higher values mean the model prefers \"no answer possible\"\n",
    "# alternatively, QA models on model hub (https://huggingface.co/models)\n",
    "#sota: ahotrod/albert_xxlargev1_squad2_512\n",
    "#dmis-lab/biobert-large-cased-v1.1-squad\n",
    "#\n",
    "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True, use_confidence_scores=True)\n",
    "#sets pipeline to contain retriever and reader\n",
    "pipe = ExtractiveQAPipeline(reader, retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f2ded5",
   "metadata": {},
   "source": [
    "## pipeline with fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9e7db14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at pubmed_tuned\n",
      "INFO - haystack.modeling.model.language_model -  Loaded pubmed_tuned\n",
      "INFO - haystack.modeling.model.adaptive_model -  Found files for loading 1 prediction heads\n",
      "WARNING - haystack.modeling.model.prediction_head -  Some unused parameters are passed to the QuestionAnsweringHead. Might not be a problem. Params: {\"training\": true, \"num_labels\": 2, \"ph_output_type\": \"per_token_squad\", \"model_type\": \"span_classification\", \"label_tensor_name\": \"question_answering_label_ids\", \"label_list\": [\"start_token\", \"end_token\"], \"metric\": \"squad\", \"name\": \"QuestionAnsweringHead\"}\n",
      "INFO - haystack.modeling.model.prediction_head -  Loading prediction head from pubmed_tuned\\prediction_head_0.bin\n",
      "INFO - haystack.modeling.data_handler.processor -  Initialized processor without tasks. Supply `metric` and `label_list` to the constructor for using the default task or add a custom task later via processor.add_task()\n",
      "INFO - haystack.modeling.logger -  ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "INFO - haystack.modeling.utils -  Using devices: CUDA\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.infer -  Got ya 15 parallel workers to do inference ...\n",
      "INFO - haystack.modeling.infer -   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "INFO - haystack.modeling.infer -  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /|\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /|\\\n",
      "INFO - haystack.modeling.infer -  /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\  /'\\  /'\\  /'\\  /'\\  /'\\  / \\  /'\\  /'\\\n"
     ]
    }
   ],
   "source": [
    "tuned_reader = FARMReader(model_name_or_path=\"pubmed_tuned\", use_gpu=True, use_confidence_scores=True)\n",
    "tuned_pipe = ExtractiveQAPipeline(tuned_reader, retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba7fe4e",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ee19dba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1=\"what disease is being studied?\"\n",
    "q2=\"What is the objective of the study?\"\n",
    "###\n",
    "q3=\"how many patient data samples were included in this study?\"\n",
    "q4=\"what modality of data is used in this study?\"\n",
    "###\n",
    "q5=\"what country was the study conducted in?\"\n",
    "q6=\"what hospital did the data come from?\"\n",
    "q7=\"What existing database did the data come from?\"\n",
    "q8=\"What organisation did the data come from?\"\n",
    "###\n",
    "#q10=\"how does the model perform relative to a human?\"\n",
    "#q11=\"how does the model perform in prospective testing\"\n",
    "#q12=\"what were the results of the study?\"\n",
    "#q12=\"what was the area under the curve (AUC) value?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd3d153",
   "metadata": {},
   "source": [
    "## question answering (new model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0ec9024b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.nodes.retriever.sparse -  Indexed documents have been updated and fit() method needs to be run before retrieval. Running it now.\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\torch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 16.70 Batches/s]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\torch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 16.16 Batches/s]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\torch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 15.42 Batches/s]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\torch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.66 Batches/s]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\torch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.97 Batches/s]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\torch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 15.20 Batches/s]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\torch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 15.66 Batches/s]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\torch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 13.38 Batches/s]\n"
     ]
    }
   ],
   "source": [
    "# Number of candidates the reader and retriever return\n",
    "# Higher top_k for retriever = better accuracy (but slower)\n",
    "qlist = [q1, q2, q3, q4, q5, q6, q7, q8]\n",
    "plist = qlist.copy() #keep same length\n",
    "l = len(qlist)\n",
    "\n",
    "for i in range(0,l):\n",
    "    plist[i] = tuned_pipe.run(\n",
    "            query=qlist[i], params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}}\n",
    "        )\n",
    "\n",
    "#p1 = pipe.run(\n",
    "#    query=q1, params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}}\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5dda6831",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: what disease is being studied?\n",
      "Answers:\n",
      "[   {   'answer': 'Heart failure (HF)',\n",
      "        'context': 'Heart failure (HF) is a major cause of mortality. '\n",
      "                   'Accurately monitoring HF progress and adjusting therapies '\n",
      "                   'are critical for improving patient outcome',\n",
      "        'score': 0.6165068447589874}]\n",
      "\n",
      "Query: What is the objective of the study?\n",
      "Answers:\n",
      "[   {   'answer': 'Accurately monitoring HF progress and adjusting therapies '\n",
      "                  'are critical for improving patient outcomes. An experienced '\n",
      "                  'cardiologist can make accurate HF stage diagnoses based on '\n",
      "                  'combination of symptoms, signs, and lab results from the '\n",
      "                  'electronic health records (EHR) of a patient, without '\n",
      "                  'directly measuring heart function. We examined whether '\n",
      "                  'machine learning models, more specifically the XGBoost '\n",
      "                  'model, can accurately predict patient stage based on EHR, '\n",
      "                  'and we further applied the SHapley Additive exPlanations '\n",
      "                  '(SHAP) framework to identify informative features and their '\n",
      "                  'interpretations. Our results indicate that based on '\n",
      "                  'structured data from EHR, our models could predict '\n",
      "                  \"patients' ejection fraction (EF) scores with moderate \"\n",
      "                  'accuracy',\n",
      "        'context': 'Accurately monitoring HF progress and adjusting therapies '\n",
      "                   'are critical for improving patient outcomes. An '\n",
      "                   'experienced cardiologist can make accurate HF stage '\n",
      "                   'diagnoses based on combination of symptoms, signs, and lab '\n",
      "                   'results from the electronic health records (EHR) of a '\n",
      "                   'patient, without directly measuring heart function. We '\n",
      "                   'examined whether machine learning models, more '\n",
      "                   'specifically the XGBoost model, can accurately predict '\n",
      "                   'patient stage based on EHR, and we further applied the '\n",
      "                   'SHapley Additive exPlanations (SHAP) framework to identify '\n",
      "                   'informative features and their interpretations. Our '\n",
      "                   'results indicate that based on structured data from EHR, '\n",
      "                   \"our models could predict patients' ejection fraction (EF) \"\n",
      "                   'scores with moderate accuracy',\n",
      "        'score': 0.10465653240680695}]\n",
      "\n",
      "Query: how many patient data samples were included in this study?\n",
      "Answers:\n",
      "[   {   'answer': 'ejection fraction (EF) scores',\n",
      "        'context': 'structured data from EHR, our models could predict '\n",
      "                   \"patients' ejection fraction (EF) scores with moderate \"\n",
      "                   'accuracy. SHAP analyses identified informativ',\n",
      "        'score': 0.005774942226707935}]\n",
      "\n",
      "Query: what modality of data is used in this study?\n",
      "Answers:\n",
      "[   {   'answer': 'electronic health records',\n",
      "        'context': 'ed on combination of symptoms, signs, and lab results from '\n",
      "                   'the electronic health records (EHR) of a patient, without '\n",
      "                   'directly measuring heart function',\n",
      "        'score': 0.6768624186515808}]\n",
      "\n",
      "Query: what country was the study conducted in?\n",
      "Answers:\n",
      "[   {   'answer': 'SHapley Additive exPlanations (SHAP) framework to identify '\n",
      "                  'informative features and their interpretations. Our results '\n",
      "                  'indicate that based on structured data from EHR, our models '\n",
      "                  \"could predict patients' ejection fraction (EF) scores with \"\n",
      "                  'moderate accuracy. SHAP analyses',\n",
      "        'context': 'SHapley Additive exPlanations (SHAP) framework to identify '\n",
      "                   'informative features and their interpretations. Our '\n",
      "                   'results indicate that based on structured data from EHR, '\n",
      "                   \"our models could predict patients' ejection fraction (EF) \"\n",
      "                   'scores with moderate accuracy. SHAP analyses',\n",
      "        'score': 0.00030183901253622025}]\n",
      "\n",
      "Query: what hospital did the data come from?\n",
      "Answers:\n",
      "[   {   'answer': 'electronic health records',\n",
      "        'context': 'ed on combination of symptoms, signs, and lab results from '\n",
      "                   'the electronic health records (EHR) of a patient, without '\n",
      "                   'directly measuring heart function',\n",
      "        'score': 0.009098882786929607}]\n",
      "\n",
      "Query: What existing database did the data come from?\n",
      "Answers:\n",
      "[   {   'answer': 'electronic health records',\n",
      "        'context': 'ed on combination of symptoms, signs, and lab results from '\n",
      "                   'the electronic health records (EHR) of a patient, without '\n",
      "                   'directly measuring heart function',\n",
      "        'score': 0.5206711888313293}]\n",
      "\n",
      "Query: What organisation did the data come from?\n",
      "Answers:\n",
      "[   {   'answer': 'electronic health records',\n",
      "        'context': 'ed on combination of symptoms, signs, and lab results from '\n",
      "                   'the electronic health records (EHR) of a patient, without '\n",
      "                   'directly measuring heart function',\n",
      "        'score': 0.2522529363632202}]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,l):\n",
    "    print_answers(plist[i], details='medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5309704e",
   "metadata": {},
   "source": [
    "## question answering (original model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2629684d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\torch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.53 Batches/s]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\torch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.85 Batches/s]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\torch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 16.70 Batches/s]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\torch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11.27 Batches/s]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\torch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 15.92 Batches/s]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\torch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 16.72 Batches/s]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\torch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.38 Batches/s]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\torch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 16.44 Batches/s]\n"
     ]
    }
   ],
   "source": [
    "# Number of candidates the reader and retriever return\n",
    "# Higher top_k for retriever = better accuracy (but slower)\n",
    "qlist = [q1, q2, q3, q4, q5, q6, q7, q8]\n",
    "plist = qlist.copy() #keep same length\n",
    "l = len(qlist)\n",
    "\n",
    "for i in range(0,l):\n",
    "    plist[i] = pipe.run(\n",
    "            query=qlist[i], params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}}\n",
    "        )\n",
    "\n",
    "#p1 = pipe.run(\n",
    "#    query=q1, params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}}\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6f0a7e80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: what disease is being studied?\n",
      "Answers:\n",
      "[   {   'answer': 'Heart failure',\n",
      "        'context': 'Heart failure (HF) is a major cause of mortality. '\n",
      "                   'Accurately monitoring HF progress and adjusting therapies '\n",
      "                   'are critical for improving patient outcome',\n",
      "        'score': 0.3558764010667801}]\n",
      "\n",
      "Query: What is the objective of the study?\n",
      "Answers:\n",
      "[   {   'answer': 'Our findings provide insights on how to design computing '\n",
      "                  'systems to accurately monitor disease progression of HF '\n",
      "                  'patients',\n",
      "        'context': 'ubtypes of HF. Our findings provide insights on how to '\n",
      "                   'design computing systems to accurately monitor disease '\n",
      "                   'progression of HF patients through conti',\n",
      "        'score': 0.1781071275472641}]\n",
      "\n",
      "Query: how many patient data samples were included in this study?\n",
      "Answers:\n",
      "[   {   'answer': 'EHR data',\n",
      "        'context': 'e insights on how to design computing systems to '\n",
      "                   'accurately monitor disease progression of HF patients '\n",
      "                   \"through continuously mining patients' EHR data.\",\n",
      "        'score': 0.13103366643190384}]\n",
      "\n",
      "Query: what modality of data is used in this study?\n",
      "Answers:\n",
      "[   {   'answer': 'structured data from EHR, our models could predict '\n",
      "                  \"patients' ejection fraction (EF) scores with moderate \"\n",
      "                  'accuracy. SHAP analyses identified informative features and '\n",
      "                  'revealed potential clinical subtypes of HF. Our findings '\n",
      "                  'provide insights on how to design computing systems to '\n",
      "                  'accurately monitor disease progression of HF patients '\n",
      "                  \"through continuously mining patients' EHR data\",\n",
      "        'context': ' structured data from EHR, our models could predict '\n",
      "                   \"patients' ejection fraction (EF) scores with moderate \"\n",
      "                   'accuracy. SHAP analyses identified informative features '\n",
      "                   'and revealed potential clinical subtypes of HF. Our '\n",
      "                   'findings provide insights on how to design computing '\n",
      "                   'systems to accurately monitor disease progression of HF '\n",
      "                   \"patients through continuously mining patients' EHR data\",\n",
      "        'score': 0.2963193953037262}]\n",
      "\n",
      "Query: what country was the study conducted in?\n",
      "Answers:\n",
      "[   {   'answer': 'electronic health records (EHR) of a patient, without '\n",
      "                  'directly measuring heart function',\n",
      "        'context': 'signs, and lab results from the electronic health records '\n",
      "                   '(EHR) of a patient, without directly measuring heart '\n",
      "                   'function. We examined whether machine l',\n",
      "        'score': 0.00046555130393244326}]\n",
      "\n",
      "Query: what hospital did the data come from?\n",
      "Answers:\n",
      "[   {   'answer': 'EHR',\n",
      "        'context': ' interpretations. Our results indicate that based on '\n",
      "                   'structured data from EHR, our models could predict '\n",
      "                   \"patients' ejection fraction (EF) scores with m\",\n",
      "        'score': 0.0014329932746477425}]\n",
      "\n",
      "Query: What existing database did the data come from?\n",
      "Answers:\n",
      "[   {   'answer': 'EHR',\n",
      "        'context': ' interpretations. Our results indicate that based on '\n",
      "                   'structured data from EHR, our models could predict '\n",
      "                   \"patients' ejection fraction (EF) scores with m\",\n",
      "        'score': 0.10637079924345016}]\n",
      "\n",
      "Query: What organisation did the data come from?\n",
      "Answers:\n",
      "[   {   'answer': 'EHR',\n",
      "        'context': ' interpretations. Our results indicate that based on '\n",
      "                   'structured data from EHR, our models could predict '\n",
      "                   \"patients' ejection fraction (EF) scores with m\",\n",
      "        'score': 0.35925403237342834}]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,l):\n",
    "    print_answers(plist[i], details='medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae49b4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20f3129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660132b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6f8aef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
