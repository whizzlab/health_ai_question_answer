{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9542a253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd51feb3",
   "metadata": {},
   "source": [
    "# import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad775c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28703"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_abstracts = pd.read_csv('data/included_abstracts.csv', index_col = 0)\n",
    "\n",
    "all_abstracts['article_date'] = pd.to_datetime(all_abstracts['article_date'])\n",
    "decade_df = all_abstracts[(all_abstracts['article_date'] > '2012-01-01') & (all_abstracts['article_date'] <'2022-01-01')]\n",
    "len(decade_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ca1054e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9071"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods_df = pd.read_csv('output/methods_scored.csv', index_col = 0)\n",
    "len(methods_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22b80652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>title</th>\n",
       "      <th>methods</th>\n",
       "      <th>sample_answer</th>\n",
       "      <th>sample_score</th>\n",
       "      <th>database_answer</th>\n",
       "      <th>database_score</th>\n",
       "      <th>organisation_answer</th>\n",
       "      <th>organisation_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35330977</td>\n",
       "      <td>ECG Restitution Analysis and Machine Learning ...</td>\n",
       "      <td>Subject Recruitment This study did not requi...</td>\n",
       "      <td>Two</td>\n",
       "      <td>0.395289</td>\n",
       "      <td>Rossdales Equine Hospital and Diagnostic Centre</td>\n",
       "      <td>0.076196</td>\n",
       "      <td>University of Surrey</td>\n",
       "      <td>0.352178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30814403</td>\n",
       "      <td>Combined machine learning and functional magne...</td>\n",
       "      <td>2.1. Subjects The protocol was approved by t...</td>\n",
       "      <td>69</td>\n",
       "      <td>0.003431</td>\n",
       "      <td>ShaanxiTibet immigrant cohort</td>\n",
       "      <td>0.141915</td>\n",
       "      <td>Xijing Hospital of Air Force Medical University</td>\n",
       "      <td>0.135661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34933537</td>\n",
       "      <td>The use and applicability of machine learning ...</td>\n",
       "      <td>lected database for 153 men with BPE, treated...</td>\n",
       "      <td>153</td>\n",
       "      <td>0.058369</td>\n",
       "      <td>lected database</td>\n",
       "      <td>0.030526</td>\n",
       "      <td>lected database for 153 men with BPE, treated ...</td>\n",
       "      <td>0.002073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34897147</td>\n",
       "      <td>Automation of a Rule-based Workflow to Estimat...</td>\n",
       "      <td>Participants This retrospective, noninvasive...</td>\n",
       "      <td>908</td>\n",
       "      <td>0.643942</td>\n",
       "      <td>Juntendo University Hospital</td>\n",
       "      <td>0.019872</td>\n",
       "      <td>Juntendo University Hospital</td>\n",
       "      <td>0.608144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34176867</td>\n",
       "      <td>Deep Learning Algorithm to Detect Cardiac Sarc...</td>\n",
       "      <td>Study Sample Patients aged ≥18 years who und...</td>\n",
       "      <td>50</td>\n",
       "      <td>0.329474</td>\n",
       "      <td>EchoNet-Dynamic dataset</td>\n",
       "      <td>0.001419</td>\n",
       "      <td>University of Tokyo Hospital</td>\n",
       "      <td>0.691286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid                                              title  \\\n",
       "0  35330977  ECG Restitution Analysis and Machine Learning ...   \n",
       "1  30814403  Combined machine learning and functional magne...   \n",
       "2  34933537  The use and applicability of machine learning ...   \n",
       "3  34897147  Automation of a Rule-based Workflow to Estimat...   \n",
       "4  34176867  Deep Learning Algorithm to Detect Cardiac Sarc...   \n",
       "\n",
       "                                             methods sample_answer  \\\n",
       "0    Subject Recruitment This study did not requi...           Two   \n",
       "1    2.1. Subjects The protocol was approved by t...            69   \n",
       "2   lected database for 153 men with BPE, treated...           153   \n",
       "3    Participants This retrospective, noninvasive...           908   \n",
       "4    Study Sample Patients aged ≥18 years who und...            50   \n",
       "\n",
       "   sample_score                                  database_answer  \\\n",
       "0      0.395289  Rossdales Equine Hospital and Diagnostic Centre   \n",
       "1      0.003431                    ShaanxiTibet immigrant cohort   \n",
       "2      0.058369                                  lected database   \n",
       "3      0.643942                     Juntendo University Hospital   \n",
       "4      0.329474                          EchoNet-Dynamic dataset   \n",
       "\n",
       "   database_score                                organisation_answer  \\\n",
       "0        0.076196                               University of Surrey   \n",
       "1        0.141915    Xijing Hospital of Air Force Medical University   \n",
       "2        0.030526  lected database for 153 men with BPE, treated ...   \n",
       "3        0.019872                       Juntendo University Hospital   \n",
       "4        0.001419                       University of Tokyo Hospital   \n",
       "\n",
       "   organisation_score  \n",
       "0            0.352178  \n",
       "1            0.135661  \n",
       "2            0.002073  \n",
       "3            0.608144  \n",
       "4            0.691286  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3d2c1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28703"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts_df = pd.read_csv('output/abstracts_scored.csv', index_col = 0)\n",
    "len(abstracts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59563552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>disease_answer</th>\n",
       "      <th>disease_score</th>\n",
       "      <th>sample_answer</th>\n",
       "      <th>sample_score</th>\n",
       "      <th>modality_answer</th>\n",
       "      <th>modality_score</th>\n",
       "      <th>database_answer</th>\n",
       "      <th>database_score</th>\n",
       "      <th>organisation_answer</th>\n",
       "      <th>organisation_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35309968</td>\n",
       "      <td>mTeeth: Identifying Brushing Teeth Surfaces Us...</td>\n",
       "      <td>Ensuring that all the teeth surfaces are adequ...</td>\n",
       "      <td>oral diseases</td>\n",
       "      <td>0.304024</td>\n",
       "      <td>114</td>\n",
       "      <td>0.414761</td>\n",
       "      <td>inertial sensors</td>\n",
       "      <td>0.559315</td>\n",
       "      <td>wrist-worn inertial sensor dataset collected f...</td>\n",
       "      <td>0.169088</td>\n",
       "      <td>wrist-worn inertial sensor dataset collected f...</td>\n",
       "      <td>0.169088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35330785</td>\n",
       "      <td>Development of a Machine Learning Algorithm fo...</td>\n",
       "      <td>Reverse total shoulder arthroplasty (rTSA) off...</td>\n",
       "      <td>Reverse total shoulder arthroplasty</td>\n",
       "      <td>0.377661</td>\n",
       "      <td>2799</td>\n",
       "      <td>0.494304</td>\n",
       "      <td>Office of Statewide Health Planning and Develo...</td>\n",
       "      <td>0.363589</td>\n",
       "      <td>Office of Statewide Health Planning and Develo...</td>\n",
       "      <td>0.689447</td>\n",
       "      <td>Office of Statewide Health Planning and Develo...</td>\n",
       "      <td>0.689447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35330977</td>\n",
       "      <td>ECG Restitution Analysis and Machine Learning ...</td>\n",
       "      <td>Atrial fibrillation is the most frequent arrhy...</td>\n",
       "      <td>paroxysmal atrial fibrillation</td>\n",
       "      <td>0.391101</td>\n",
       "      <td>control and horses with PAF</td>\n",
       "      <td>0.110626</td>\n",
       "      <td>normal sinus-rhythm ECGs</td>\n",
       "      <td>0.316086</td>\n",
       "      <td>normal sinus-rhythm ECGs</td>\n",
       "      <td>0.071468</td>\n",
       "      <td>normal sinus-rhythm ECGs</td>\n",
       "      <td>0.071468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35330920</td>\n",
       "      <td>Segmenting Thoracic Cavities with Neoplastic L...</td>\n",
       "      <td>Automatic segmentation of thoracic cavity stru...</td>\n",
       "      <td>neoplastic disease</td>\n",
       "      <td>0.441814</td>\n",
       "      <td>402</td>\n",
       "      <td>0.776861</td>\n",
       "      <td>CT images</td>\n",
       "      <td>0.502925</td>\n",
       "      <td>402 cancer patients</td>\n",
       "      <td>0.757216</td>\n",
       "      <td>402 cancer patients</td>\n",
       "      <td>0.757216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30814403</td>\n",
       "      <td>Combined machine learning and functional magne...</td>\n",
       "      <td>Hypoxia exposure during high-altitude expediti...</td>\n",
       "      <td>psychomotor impairment</td>\n",
       "      <td>0.347314</td>\n",
       "      <td>69</td>\n",
       "      <td>0.720279</td>\n",
       "      <td>Rs-fMRI</td>\n",
       "      <td>0.341074</td>\n",
       "      <td>Shaanxi-Tibet immigrant cohort</td>\n",
       "      <td>0.850154</td>\n",
       "      <td>Shaanxi-Tibet immigrant cohort</td>\n",
       "      <td>0.850154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid                                              title  \\\n",
       "0  35309968  mTeeth: Identifying Brushing Teeth Surfaces Us...   \n",
       "1  35330785  Development of a Machine Learning Algorithm fo...   \n",
       "2  35330977  ECG Restitution Analysis and Machine Learning ...   \n",
       "3  35330920  Segmenting Thoracic Cavities with Neoplastic L...   \n",
       "4  30814403  Combined machine learning and functional magne...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Ensuring that all the teeth surfaces are adequ...   \n",
       "1  Reverse total shoulder arthroplasty (rTSA) off...   \n",
       "2  Atrial fibrillation is the most frequent arrhy...   \n",
       "3  Automatic segmentation of thoracic cavity stru...   \n",
       "4  Hypoxia exposure during high-altitude expediti...   \n",
       "\n",
       "                        disease_answer  disease_score  \\\n",
       "0                        oral diseases       0.304024   \n",
       "1  Reverse total shoulder arthroplasty       0.377661   \n",
       "2       paroxysmal atrial fibrillation       0.391101   \n",
       "3                   neoplastic disease       0.441814   \n",
       "4               psychomotor impairment       0.347314   \n",
       "\n",
       "                 sample_answer  sample_score  \\\n",
       "0                          114      0.414761   \n",
       "1                         2799      0.494304   \n",
       "2  control and horses with PAF      0.110626   \n",
       "3                          402      0.776861   \n",
       "4                           69      0.720279   \n",
       "\n",
       "                                     modality_answer  modality_score  \\\n",
       "0                                   inertial sensors        0.559315   \n",
       "1  Office of Statewide Health Planning and Develo...        0.363589   \n",
       "2                           normal sinus-rhythm ECGs        0.316086   \n",
       "3                                          CT images        0.502925   \n",
       "4                                            Rs-fMRI        0.341074   \n",
       "\n",
       "                                     database_answer  database_score  \\\n",
       "0  wrist-worn inertial sensor dataset collected f...        0.169088   \n",
       "1  Office of Statewide Health Planning and Develo...        0.689447   \n",
       "2                           normal sinus-rhythm ECGs        0.071468   \n",
       "3                                402 cancer patients        0.757216   \n",
       "4                     Shaanxi-Tibet immigrant cohort        0.850154   \n",
       "\n",
       "                                 organisation_answer  organisation_score  \n",
       "0  wrist-worn inertial sensor dataset collected f...            0.169088  \n",
       "1  Office of Statewide Health Planning and Develo...            0.689447  \n",
       "2                           normal sinus-rhythm ECGs            0.071468  \n",
       "3                                402 cancer patients            0.757216  \n",
       "4                     Shaanxi-Tibet immigrant cohort            0.850154  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1736db79",
   "metadata": {},
   "source": [
    "# proper noun extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9897b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eddd4e",
   "metadata": {},
   "source": [
    "### abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d3976dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_list = abstracts_df['abstract'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "aef1e6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c08c3e879f84ec19b8339c5ea7365b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28703 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "abs_nouns = []\n",
    "\n",
    "for text in tqdm(abstracts_list):\n",
    "    \n",
    "    blocklist = []\n",
    "    \n",
    "    for sentence in sent_detector.tokenize(text):\n",
    "        tokenizedSentence = word_tokenize(sentence)\n",
    "        taggedSentence = pos_tag(tokenizedSentence)\n",
    "        wordlist = []\n",
    "        \n",
    "        for word, pos in taggedSentence:\n",
    "            if pos == 'NNP':\n",
    "                #print(word)\n",
    "                wordlist.append(word)\n",
    "        \n",
    "        blocklist.extend(wordlist)\n",
    "    \n",
    "    abs_nouns.append(blocklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bee27065",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_df['abs_nouns'] = abs_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "822d8435",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_df.to_csv('output/abstracts_scored_nouns.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083a7851",
   "metadata": {},
   "source": [
    "### methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "32bd9362",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_list = methods_df['methods'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c83da4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4612fba408440193fa2a8c7bfb3cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "met_nouns = []\n",
    "\n",
    "for text in tqdm(methods_list):\n",
    "    \n",
    "    blocklist = []\n",
    "    \n",
    "    for sentence in sent_detector.tokenize(text):\n",
    "        tokenizedSentence = word_tokenize(sentence)\n",
    "        taggedSentence = pos_tag(tokenizedSentence)\n",
    "        wordlist = []\n",
    "        \n",
    "        for word, pos in taggedSentence:\n",
    "            if pos == 'NNP':\n",
    "                #print(word)\n",
    "                wordlist.append(word)\n",
    "        \n",
    "        blocklist.extend(wordlist)\n",
    "    \n",
    "    met_nouns.append(blocklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a11b1026",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_df['met_nouns'] = met_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4732cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_df.to_csv('output/methods_scored_nouns.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d7eb27",
   "metadata": {},
   "source": [
    "# geo_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5f8b1f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Joe Z\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to C:\\Users\\Joe\n",
      "[nltk_data]     Z\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to C:\\Users\\Joe\n",
      "[nltk_data]     Z\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geograpy\n",
    "from geograpy import extraction\n",
    "from geograpy import places\n",
    "import nltk\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "acaaa848",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_list = abstracts_df['abstract'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c7c36fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c756675912456a914f267555e2c81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28703 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "abs_geo_cities = []\n",
    "abs_geo_countries = []\n",
    "abs_geo_other = []\n",
    "\n",
    "for x in tqdm(abstracts_list):\n",
    "    try:\n",
    "        places = geograpy.get_geoPlace_context(text=x)\n",
    "    \n",
    "        abs_geo_cities.append(places.cities)\n",
    "        abs_geo_countries.append(places.countries)\n",
    "        abs_geo_other.append(places.other)\n",
    "    \n",
    "    except:\n",
    "        abs_geo_cities.append('nan')\n",
    "        abs_geo_countries.append('nan')\n",
    "        abs_geo_other.append('nan')\n",
    "        \n",
    "abstracts_df['abs_geo_cities'] = abs_geo_cities\n",
    "abstracts_df['abs_geo_countries'] = abs_geo_countries\n",
    "abstracts_df['abs_geo_other'] = abs_geo_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796b406b",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_df.to_csv('output/abstracts_scored_nouns_geo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2ff25c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_list = methods_df['methods'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9171faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d52763eff244cbf97a230faa258500c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "met_geo_cities = []\n",
    "met_geo_countries = []\n",
    "met_geo_other = []\n",
    "\n",
    "for x in tqdm(methods_list):\n",
    "    try:\n",
    "        places = geograpy.get_geoPlace_context(text=x)\n",
    "    \n",
    "        met_geo_cities.append(places.cities)\n",
    "        met_geo_countries.append(places.countries)\n",
    "        met_geo_other.append(places.other)\n",
    "    \n",
    "    except:\n",
    "        met_geo_cities.append('nan')\n",
    "        met_geo_countries.append('nan')\n",
    "        met_geo_other.append('nan')\n",
    "        \n",
    "methods_df['met_geo_cities'] = met_geo_cities\n",
    "methods_df['met_geo_countries'] = met_geo_countries\n",
    "methods_df['met_geo_other'] = met_geo_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523f6863",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_df.to_csv('output/methods_scored_nouns_geo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24f96fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c903e3f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1940c45a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8fb6f32",
   "metadata": {},
   "source": [
    "# detect proper nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ea396631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c665553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I enjoyed the visit to Pisa where I visited Stephen at the AMIDA institute\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "14f686fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pisa\n",
      "Stephen\n",
      "AMIDA\n"
     ]
    }
   ],
   "source": [
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    \n",
    "for sentence in sent_detector.tokenize(text):\n",
    "    tokenizedSentence = word_tokenize(sentence)\n",
    "    taggedSentence = pos_tag(tokenizedSentence)\n",
    "    start = True\n",
    "    currentCandidate = []\n",
    "\n",
    "    for word, pos in taggedSentence:\n",
    "        if start:\n",
    "            start = False\n",
    "            continue\n",
    "\n",
    "        if pos == 'NNP':\n",
    "            currentCandidate.append(word)\n",
    "            continue\n",
    "\n",
    "        if len(currentCandidate) > 0:\n",
    "            print(' '.join(currentCandidate))\n",
    "            currentCandidate = []\n",
    "\n",
    "    if len(currentCandidate) > 0:\n",
    "        print(' '.join(currentCandidate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5457cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
