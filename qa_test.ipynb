{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30bc93f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60a63b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adc163f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.base -  Numba not found, replacing njit() with no-op implementation. Enable it with 'pip install numba'.\n",
      "INFO - haystack.modeling.model.optimization -  apex not found, won't use it. See https://nvidia.github.io/apex/\n"
     ]
    }
   ],
   "source": [
    "from haystack.utils import clean_wiki_text, convert_files_to_dicts, fetch_archive_from_http, print_answers\n",
    "from haystack.nodes import FARMReader, TransformersReader\n",
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "\n",
    "#haystack contains a search system for retrieval and QA across documents.\n",
    "#designed for large documents, but pipeline also works for single document QA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b6ab6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n"
     ]
    }
   ],
   "source": [
    "# In-Memory Document Store\n",
    "from haystack.document_stores import InMemoryDocumentStore\n",
    "document_store = InMemoryDocumentStore() #to enable documents stored in local memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1d5a4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.utils.preprocessing -  Converting testdata\\s12967-020-02620-5 (1).txt\n"
     ]
    }
   ],
   "source": [
    "doc_dir = \"testdata\"\n",
    "\n",
    "dicts = convert_files_to_dicts(dir_path=doc_dir, split_paragraphs=True)\n",
    "\n",
    "## if there are multiple documents for database, this puts all relevant docs into dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fe09522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'Hou et al. J Transl Med\\t(2020) 18:462\\nhttps://doi.org/10.1186/s12967-020-02620-5\\n               \\nJournal of Translational Medicine\\n            ',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'Predicting 30-days mortality for MIMIC-III patients with sepsis-3: a machine learning approach using XGboost\\nNianzong Hou1†, Mingzhe Li2, Lu He3, Bing Xie1, Lin Wang4, Rumin Zhang4, Yong Yu4, Xiaodong Sun5, Zhengsheng Pan6 and Kai Wang4*†',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': '\\n*Correspondence: wangkaiicu@163.com\\n†Nianzong Hou and Kai Wang contributed equally to this work\\n4 Department of Critical Care Medicine, Zibo Central Hospital, Shandong First Medical University , Zibo 255036, Shandong, China\\nFull list of author information is available at the end of the article',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'Background\\nSepsis is a common and economically significant disease which has become an important public health issue glob- ally and led to over 5.3 million people dies annually with an approximately overall mortality of 30%, particularly in the intensive care unit (ICU) [1–3]. Sepsis is defined as a syndrome of physiologic, pathologic, and biochemi- cal abnormalities induced by infection which results in',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': '\\n© The Author(s) 2020. This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativeco mmons.org/licenses/by/4.0/. The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/ zero/1.0/) applies to the data made available in this article, unless otherwise stated in a credit line to the data.',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'life-threatening organ dysfunction caused by dysregu- lated host response [3]. Different from those previous diagnostic criteria for sepsis, sepsis-3 highlighted the strong association between infection and organ failure according to the Third International Consensus Defini- tions for Sepsis and Septic Shock in February 2016 [2], hence, the early identification and diagnosis for sepsis are essential, which could provide meaningful information for clinicians to assess patients’ condition and improve survival outcomes through prompt and appropriate treatment. Due to the complex of vague sepsis syndrome definitions, unknown sources of infection and higher mortality, it is necessary to establish a reliable and effec- tive prognostic model for sepsis. With the help of these prognostic models, strong evidences for clinical deci- sion-making and rational allocation of public health care resources can be provided.\\n  The establishment of prognosis model for sepsis patients has always been a hot topic in critical care medi- cine. Some sensitive serum markers, such as Ang-2, PCT, interleukin-6, pentraxin 3, etc. [1, 4, 5], have been widely used to facilitate sepsis prognosis, however, their prog- nostic values are limited, not only rarely available but often lack of sensitivity or specificity. On the other hand, traditional prediction models based on small sample data such as logistic regression analysis and scoring systems including acute physiology and chronic health evalu- ation-II (APHACHE-II), Simplified acute physiology score-II (SAPS-II) and etc. [6–8], are still providing com- prehensively clinical importance of identifying patients who are at risk of unfavourable prognostic outcomes, but these methods and scores require the statistical assump- tion of the independent and linear relationship between explanatory and outcome variables or preclude the analy- sis of a large number of valuable variables. In addition, insufficient prognostic strength, large fluctuation range, poor stability and operability, tedious process, and other shortcomings exist in these predictive serum markers, models and scores to a certain extent.\\n  Recently, novel machine learning techniques have dem- onstrated improved predictive performance compared to traditional prediction methods. Moreover, the evolution of statistical theory, computer technology and the estab- lishment of specialized database for critical care medical such as MIMIC-III could help machine learning get more attention and recognition by clinicians. eXtreme Gradi- ent Boosting (XGBoost) is a machine learning technique with the remarkable features of processing the missing data efficiently and flexibly and assembling weak pre- diction models to build a accurate one [9]. As an open source package, XGBoost has been widely recognized in a number of machine learning and data mining challenges, for example, 17 solutions used XGBoost among the 29',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'challenge winning solutions published at Kaggle’s blog in 2015 and the top-10 winning teams used XGBoost in KDD Cup 2015 [10].\\n  Therefore, the goal of the study was twofold: firstly, we attempted to compare the performance of machine learn- ing (XGboost) model with traditional prediction mod- els (conventional logistic regression model and SAPS-II score model) in the prediction of the 30-days mortality in MIMIC-IIIpatients with sepsis-3. Secondly, we planned to plot nomogram and clinical impact curve (CIC) to val- idate the XGboost model.\\nMethods\\nDatabase\\nWe used the Medical Information Mart for Intensive Care III database version 1.4 (MIMIC III v1.4) for the study. MIMIC-III, a publicly available single-center criti- cal care database which was approved by the Institutional Review Boards of Beth Israel Deaconess Medical Center (BIDMC, Boston, MA, USA) and the Massachusetts Institute of Technology (MIT, Cambridge, MA, USA), includes information on 46,520 patients who were admit- ted to various ICUs of BIDMC in Boston, Massachu- setts from 2001 to 2012 [11–13]. The database contains charted events such as demographics, vital signs, labo- ratory tests, fluid balance and vital status; documents International Classification of Diseases and Ninth Revi- sion (ICD-9) codes; records hourly physiologic data from bedside monitors validated by ICU nurses; and stores written evaluations of radiologic films by specialists cov- ering in the corresponding time period. The use of the data in the database, provided by clinicians, data scien- tists, and information technology personnel and uniden- tified health information of patients, has been deemed not human subjects research and there was no require- ment for individual patient consent because of the uni- dentified health information [12, 13]. The users, whereas, must pass a test to qualify to register for the database and be approved by MIMIC-III database administration staff. After passing a training course “Protecting Human Research Participants” on the website of National Insti- tutes of Health (NIH), an author (NZ Hou) was approved to extract data from this database for research purposes (certification number: 37258322).\\nStudy population\\nAdult patients who were diagnosed with sepsis-3 were included in our study. The inclusion criteria were: (I) patients who were older than 18 years old; (II) length of stay in the ICU was over 24 h to ensure sufficient data for analysis; (III) patients with the diagnosed of sepsis according to The Third International Consensus Defini- tions for Sepsis and Septic Shock (sepsis-3) [2]. Because',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'MIMIC-III database has shifted their date of birth to obscure their age, we excluded patients who were over 89 years, and if a patient had multiple admissions with sepsis, only the first admission was analyzed. As it is common with missing data in the MIMIC-III database, we also removed the variables with more than 20% obser- vations missing to facilitate and ensure the accuracy of the review. However, for those with less than 20% missing data or randomly missing data, we explored and visual- ized them with Templ’s method (R Package “VIM”) [14] and multiple imputation method (R Package “mice”) [15] for further analysis respectively.\\nData extraction\\nWe obtained the raw data about patients who were diag- nosed with “sepsis”, “severe sepsis” and “septic shock” on discharge using pgAdmin PostgreSQL tools (version 1.22.1) and Navicat Premium (version 12.0.28). After',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'that, R software (version 3.4.3, CRAN) was used for fur- ther process. The code, supporting the MIMIC-III doc- umentation and generating the descriptive statistic, is publicly available and contributions from the community of users are encouraged (https://github.com/MIT-LCP). The detailed process of data extraction is shown in Fig. 1. Following demographic data were extracted: age, gen- der, ethnicity, weight, height and body mass index (BMI), length of stay in hospital, length of stay in the ICU, hospi- tal expire flag (in-hospital death recorded in the hospital database) at the first ICU admission. Then, we collected vital signs of the patients from the first 24 h of ICU stay, including heart rate (HR), systolic blood pressure (SBP), diastolic blood pressure (DBP), mean arterial pressure (MAP), temperature (TEMP), respiratory rate (RR) and oxyhemoglobin saturation (SpO2). Afterwards, labora- tory values, such as blood routine examination, liver and kidney function, blood glucose, and arterial blood gas',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': '\\n(ABG) were abstracted. Furthermore, advanced cardiac life support (mechanical ventilation, renal replacement therapy, etc.) and accompanied diseases (diabetes, malig- nant tumour, etc.) were accessed. Because of the high sampling frequency, we use the maximum, minimum and the mean value when incorporating the characteristics of vital signs and related laboratory indicators. Ultimately, we obtained the list of anonymized patients with sepsis from the Table 1 (Additional file 1).\\nStatistical analysis\\nPatients were divided into two groups based on whether death or alive within 30 days and variables were dis- played and compared between groups. We revealed and excluded these confounders of the independent risk fac- tors, then, performed correlation analysis to determine the impact of them on 30-days mortality. Normally and non-normally distributed continuous variables were summarized as the mean ± SD and the median respec- tively. Continuous variables of normal distribution were tested by Kolmogorov–Smirnov test. Student’s t test, One-way ANOVA, Mann–Whitney U or Kruskal–Wallis H test were used to compare continuous data of non-nor- mally distribution, if appropriate. Categorical variables were expressed as numbers or percentage and assessed using Chi-square test or Fisher’s exact test according to different sample sizes as proper.\\nIn  the  model-development  phase,  we  constructed\\nthree predictive models: conventional logistic regression model, SAPS-II score model and XGBoost algorithm model. Firstly, the conventional logistic regression model was conducted using these significant variables identified by backward stepwise analysis with Chi-square test. Then we chose an entry probability of < 0.05 by the stepwise selection method. Secondly, in the construction of SAPS II model, we used these time-stamp variables to do pre- diction based on the methods provided by the original lit- erature of SAPS II [16]. Thirdly, we performed XGBoost model [17, 18] to analysis the contribution (gain) of each variable to 30-days mortality, at the same time, back- ward stepwise analysis was processed to select the vari- able with a threshold of p < 0.05 according to the Akaike information criterion (AIC) [19]. After identifying the variables through XGBoost, we used these clinical and laboratory variables included to construct the XGBoost algorithm model. In the model-comparison phase, we tested and compared the performances of the three predictive models by area under curves (AUCs) of the receiver operating characteristic curves (ROC) and deci- sion curve analysis (DCA), then, selected the model that achieved the highest overall diagnostic value for further verification. At last, nomogram and clinical impact curve (CIC) were plotted to evaluate the clinical usefulness and',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'applicability net benefits of the model with the best diag- nostic value. All the analyses above were conducted using R software, and p value < 0.05 was defined as statistically significant.\\nResults\\nBaseline characteristics\\nA total of 4559 sepsis-3 patients are included in our study, in which, 889 patients were death and 3670 sur- vival within 30 days, respectively. In these patients of death, the age, ethnicity, admission type, heartrate_ mean, sysbp_min, diasbp_mean, meanbp, meanbp_min, resprate_mean, tempc_min/max, spo2_mean, aniongap (AG)_min/max, creatinine_min, hemoglobin_min/max, lactate_min, potassium_min, sodium_max, bun (blood urea nitrogen)_min/max, wbc (white blood cell)_min/ max/mean, INR (international normalized ratio)_max/ mean, urine output, score system, comorbidity and com- mon sources of infection differ significantly compared these of survived, however, the sex, heart rate_min, chlo- ride_min, platelet_min, sodium_min and advanced life support show no significant difference between the two groups. Figure 1 is a flow chart describing the procedure for subjects selection; Table 1 is a summary conclud- ing the comparisons of the baseline characteristics, vital signs, laboratory parameters between the non-survivors and the survivors within 30 days, and the overall ethnic- ity characteristics/the common sources of infection are listed in Fig. 2.\\nFeatures selected in models\\nAs shown in Table 2, the most important features, which were identified by the results of backward stepwise anal- ysis and strongly associated with mortality in 30 days, were applied in conventional logistic regression model, all of which with p value < 0.05. Moreover, according to the analysis results of each features’ contribution by XGBoost model (Table 3 and Fig. 3), urine output, lac- tate, Bun, sysbp, INR, age, cancer, SpO2, sodium, AG, and creatinine were the top 11 most important features of the data set and these variables are also included to construct XGBoost predictive models in our study.\\nModel comparisons\\nIn the model-development and validation phase, the three models (traditional logistic regression model, SAPS-II score model and XGBoost algorithm model) showed good discriminatory power with AUCs of 0.819 (95% CI 0.800–0.838), 0.797 (95% CI 0.781–0.813), and\\n0.857 (95% CI 0.839–0.876), respectively (Fig. 4). The XGBoost algorithm model showed the largest test AUC but the traditional logistic regression model was the smallest. According to the DCA of the three prediction',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': '\\nTable 1 Baseline characteristics, vital signs, laboratory parameters and statistic results of mimic-III patients with sepsis',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'Death within 30 days\\tSurvival within 30 days\\tp',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': '\\nAdmission type\\nMED\\t580 (65.2%)\\t1912 (52.1%)\\nCMED\\t86 (9.7%)\\t477 (13.0%)\\nOthers\\t223 (25.1%)\\t1282 (34.9%)\\t1.36E?11\\nVital signs\\nHeartrate_min (times/min), mean (SD)\\t72.92 ± 19.16\\t73.08 ± 15.72\\t0.826205355\\nHeartrate_mean (times/min), mean (SD)\\t91.12 ± 18.27\\t87.81 ± 16.15\\t0.00000579\\nSysbp_min (mmhg), mean (SD)\\t80.46 ± 20.01\\t90.69 ± 16.18\\t6.49E?36\\nDiasbp_mean (mmhg), mean (SD)\\t58.65 ± 10.42\\t61.7 ± 10.08\\t6.62E?13\\nMeanbp_min (mmhg), mean (SD)\\t48.41 ± 15.65\\t56.24 ± 13.89\\t6.74E?34\\nResprate_mean (times/min),mean (SD)\\t21.73 ± 4.68\\t19.54 ± 4.06\\t3.66E?30\\nTempc_min (?), mean (SD)\\t35.77 ± 1.17\\t36.15 ± 0.86\\t1.78E?16\\nTempc_max (?), mean (SD)\\n37.34 ± 1.17\\n37.65 ± 0.85\\n3.37E?11\\nSpo2_mean (%), mean (SD)\\nLaboratory parameters\\n96.03 ± 4.02\\n97.1 ± 1.96\\n3.06E?12\\nAniongap_max (mmhg), mean (SD)\\n19.12 ± 6.26\\n16.17 ± 4.65\\n1.45E?31\\nAniongap_min (mmhg), mean (SD)\\n14.58 ± 4.66\\n12.45 ± 3.08\\n1.48E?30\\nCreatinine_min (ng/dL), mean (SD)\\n1.65 ± 1.23\\n1.35 ± 1.39\\n3.89E?09\\nChloride_min (mmol/L), mean (SD)\\n101.67 ± 7.65\\n101.93 ± 6.69\\n0.39868745\\nHemoglobin_min (g/dL), mean (SD)\\n9.84 ± 2.21\\n10.08 ± 2.08\\n0.009534544\\nHemoglobin_max, (g/dL), mean (SD)\\n11.77 ± 2.26\\n12 ± 2.09\\n0.012634047\\nLactate_min (mmol/L), mean (SD)\\n2.36 ± 2.07\\n1.55 ± 0.81\\n4.26E?24\\nPlatelet_min (109/L), mean (SD)\\n189.73 ± 125.29\\n195.98 ± 108.29\\n0.207608419\\nPotassium_min (mmol/L), mean (SD)\\n3.84 ± 0.7\\n3.71 ± 0.54\\n0.00000328\\nSodium_min (mmol/L), mean (SD)\\n136.27 ± 6.62\\n136.08 ± 5.35\\n0.454879474\\nSodium_max (mmol/L), mean (SD)\\n141.28 ± 6.8\\n140.51 ± 5.03\\n0.003570629\\nBun_min (mmol/L), mean (SD)\\n36.09 ± 25.43\\n24.22 ± 19.69\\n8.45E?31\\nBun_max (mmol/L), mean (SD)\\n42.88 ± 28.49\\n30.23 ± 24.39\\n1.12E?27\\nWbc_min (109/L), mean (SD)\\nWbc_max (109/L), mean (SD)\\n12.54 ± 12.22\\n17.54 ± 19.99\\n10.41 ± 6.55\\n14.8 ± 9.87\\n4.81E?06\\n0.000293182\\nInr_max, mean (SD)\\n2.12 ± 1.79\\n1.61 ± 1.34\\n2.89E?14\\nUrine output\\n1225.29 ± 1307.53\\n1993.04 ± 1551.57\\n2.82E?48',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'Table 1 (continued)',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': '\\nScore system', 'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'Death within 30 days\\tSurvival within 30 days\\tp',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': '\\nSOFA\\n8.02 ± 4.33\\n5.22 ± 2.85\\n2.74E?55\\nqSOFA\\n2.15 ± 0.64\\n1.9 ± 0.69\\n4.60E?21\\nSAPS II\\nAdvanced life support\\n54.67 ± 16.37\\n37.51 ± 13.22\\n2.2E?16\\nMechanical ventilation\\n531 (59.69%)\\n1668 (45.55%)',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'Renal replacement therapy\\n53 (5.95%)\\n135 (3.61%)\\n0.2503\\nAccompanied diseases (comorbidity)',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'Diabetes\\n246 (27.64%)\\n2631 (71.70%)',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'Malignant tumour\\n116 (13.05%)\\n160 (4.37%)',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'Others\\nCommon sources of infection\\n527 (59.31%)\\n879 (23.93%)\\n2.20E?16\\nBlood culture\\n418 (47%)\\n1343 (36.6%)',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'MRSA screen\\n267 (30%)\\n1384 (37.72%)',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'Urine\\n151 (17%)\\n642 (17.5%)',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'Swab\\n18 (2%)\\n70 (1.9%)',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'Others\\nOutcome\\n35 (4%)\\n231 (6.3%)\\n7.82E?08\\nWithin 30-days mortality\\n19.50%\\n80.50%\\nMED medical-general service for internal medicine, CMED cardiac medical-for non-surgical cardiac related admissions, sysbp systolic blood pressure, diasbp diastolic blood pressure, meanbp mean blood pressure, resprate respiratary rate, tempc temperature, bun blood urea nitrogen, wbc white blood cell, INR international normalized ratio, sofa sequential organ failure assessment, qSOFA quick SOFA, SAPS II simplified acute physiology score II, Spo2 oxyhemoglobin saturation, Max maximum, Min minimum',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'model, the net benefit for XGboost model was larger over the range of traditional logistic model and SAPS-II score model, which means XGboost model is the optimal and the SAPS-II score model inferior (Fig. 5).\\nOptimal model analysis\\nFor visualization of the XGboost predictive model, the risk nomogram that  integrated  11  selected  variables for the incidence of mortality within 30 days is shown in Fig. 6. Clinical impact curve (CIC) analysis was per- formed in Fig. 7 to evaluate clinical applicability of risk prediction nomogram. CIC visually showed that the nomogram had a superior overall net benefit within the wide and practical ranges of threshold probabilities and impacted patient outcomes, which indicates that the XGboost model possesses significant predictive value.\\nDiscussion\\nSepsis, which is associated with profound mortality and substantial economic burden, is no longer defined sim- ply as serious infection. In a systematic review and meta- analysis, Reinhart et al. [20] concluded that the mortality rate estimate of ICU- and hospital-treated sepsis patients were 41.9% and 26.7% respectively, or one out of four sepsis patients did not survive their hospital stay. Torio et al. [21] estimated sepsis accounted for 6.2% of the',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': '\\naggregate costs for all hospitalizations, or 23.7 billion USD in 2011. Furthermore, Moss et al. [22] conducted a study spanning two decades (from 1979 to 2000), which reported the annual increase of sepsis cases was around 8.7%. The improvement of sepsis prevention, recognition, and treatment has been a global health priority since the declaration repeatedly by the World Health Organization (WHO) in 2017 [23]. Progressive exacerbation of sepsis can lead to organ failure and death, but early aggressive therapy also forestalls further progression and rescues a decompensating patient. Unfortunately, in ICU it is very difficult for clinicians to predict which patients will respond favorably and could be out of the crisis or will deteriorate despite all interventions and resuscitative efforts. At present, these findings indicate the urgent need to increase efforts to  promote  reliable  predic- tion models to identify patients with sepsis who are at increased risk of developing organ dysfunction and to prognosticate their mortality.\\n  In this present study, the AUCs and DCAs we devel- oped have demonstrated the benefit of using a XGboost model- as opposed to the classic logistic regression analysis and traditional SAPS II scoring system for early prediction of probability of septic mortality. Moreover, CIC and nomogram were plotted to evaluate the clini- cal usefulness and applicability net benefits of the model\\n  ',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'Fig. 2 Characteristics of MIMIC-III patients with sepsis by ethnicities (a) and characteristics of MIMIC-III patients with sepsis by common sources of infection (b)',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'Table 2 Features selected in the conventional logistic regression',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'OR_with_CI\\np value\\n(Intercept)\\n52,913.003 (87.92–\\n< 0.001',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': '33,934,517.782)',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'Sofa\\n1.142 (1.106–1.179)\\n< 0.001\\nAniongap_min\\n1.078 (1.043–1.115)\\n< 0.001\\nCreatinine_min\\n0.676 (0.592–0.767)\\n< 0.001\\nChloride_min\\n0.98 (0.962–0.999)\\n0.03393\\nHematocrit_min\\n1.113 (1.053–1.178)\\n< 0.001\\nHemoglobin_min\\n0.748 (0.623–0.895)\\n0.00169\\nHemoglobin_max\\n0.926 (0.863–0.992)\\n0.02993\\nLactate_min\\n1.308 (1.194–1.435)\\n< 0.001\\nPotassium_min\\n1.179 (1.001–1.389)\\n0.04922\\nSodium_max\\n1.046 (1.019–1.074)\\n< 0.001\\nBun_min\\n1.033 (1.018–1.048)\\n< 0.001\\nBun_max\\n0.986 (0.973–0.997)\\n0.01542\\nWbc_min\\n1.062 (1.036–1.09)\\n< 0.001\\nWbc_max\\n0.969 (0.952–0.987)\\n< 0.001\\nHeartrate_min Heartrate_mean\\n0.987 (0.977–0.997)\\n1.022 (1.011–1.033)\\n0.0111\\n< 0.001\\nSysbp_min\\n0.991 (0.984–0.998)\\n0.00839\\nMeanbp_min\\n0.992 (0.985–1)\\n0.0468\\nResprate_mean\\n1.062 (1.038–1.086)\\n< 0.001\\nTempc_min\\n0.897 (0.81–0.993)\\n0.03242\\nTempc_max\\n0.781 (0.698–0.873)\\n< 0.001\\nSpo2_mean\\n0.947 (0.909–0.986)\\n0.00839\\nAge\\n1.029 (1.022–1.035)\\n< 0.001\\nDiabetes\\n0.779 (0.639–0.948)\\n0.01328\\nVent\\n1.824 (1.48–2.251)\\n< 0.001\\nOR odds ratio, CI confidence interval, SOFA sequential organ failure assessment, bun blood urea nitrogen, wbc white blood cell, sysbp systolic blood pressure, meanbp mean blood pressure, resprate respiratary rate, Spo2 oxyhemoglobin saturation, vent ventilation, Max maximum, Min minimum',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': '\\nTable 3 Features selected in the XGboost model',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'OR_with_CI\\tP', 'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': '(Intercept)\\n493.907 (9.063–27,931.087)\\n0.00247\\nUrineoutput\\n1 (1–1)\\n< 0.001\\nLactate_min\\n1.401 (1.288–1.527)\\n< 0.001\\nBun_mean\\n1.018 (1.013–1.023)\\n< 0.001\\nSysbp_min\\n0.979 (0.974–0.984)\\n< 0.001\\nMetastatic_cancer\\n2.997 (2.217–4.038)\\n< 0.001\\nInr_max\\n1.058 (1.002–1.115)\\n0.03709\\nAge\\n1.019 (1.013–1.025)\\n< 0.001\\nSodium_max\\n1.016 (1.001–1.031)\\n0.03835\\nAniongap_max\\n1.048 (1.026–1.069)\\n< 0.001\\nCreatinine_min\\n0.766 (0.686–0.852)\\n< 0.001\\nSpo2_mean\\n0.897 (0.865–0.93)\\n< 0.001\\nOR odds ratio, CI confidence interval, bun blood urea nitrogen, sysbp systolic blood pressure, INR international normalized ratio, Spo2 oxyhemoglobin saturation, Max maximum, Min minimum',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'with the best diagnostic value. Logistic regression analy- sis as one of the classic regression analyses is widely used to test the association between sepsis and mortality. For instance, through the logistic regression analysis, Vivien et al. [24]  observed  an  association  between  mortality at day 28 and the tidal volume indexed on ideal body weight (VTIBW) in pre-hospital mechanically ventilated patients with septic shock; Wu et al. [25] revealed that dynamic changes of serum S100B levels from day 3 to 1 were more associated with mortality than those on day 1 in patients with sepsis; Oud et al. [26] indicated that sepsis was associated with most of the short-term deaths among ICU patients with SLE despite its relatively low mortality; Song et al. [5] revealed that combined bio- markers approach showed good performance in predict- ing 28-day all-cause mortality among patients diagnosed with either sepsis or septic shock according to the sep- sis-3 definition, however, the differences might not be statistically proven. Furthemore, some studies [27, 28] found conventional logistic regression had a relatively low indicator of performance as measured by AUCs for ROC curves or showed higher prediction error and worsen performance compared to some novel techniques.\\n  Several conventional prognostic scoring systems have been developed to provide relevant evaluation results considering the hospital mortality of ICU patients. The advantages of such scoring systems are easy to calcu- late and interpret. SAPS II, as one of  the  commonly used model, has better discrimination, calibration and power to predict deaths on ICU than the sequential organ failure assessment score (SOFA), which has been recommended for the identification and mortality prog- nostication of patients in ICU by sepsis-3 [7]. Moreover, the ability of SAPS II to discriminate between survivors and non-survivors is as excellent as APACHE II score and other scores and even to help to play in end-of-life decision-making in ICUs [8]. However, the specificity and sensitivity of scoring systems such as SAPS II are low, and the predictive performance is worse than that of multivariate predictive models. Last but not least, the evaluation systems and the accurate outcomes depended heavily on the practitioner’s experience [6].\\n  In recent years, various machine learning algorithms, a subset of artificial intelligence and a data analysis tech- nique that develops algorithms to predict outcomes by “learning” from data, have been investigated for early detection of sepsis-3 and outperformed than conven- tional or classic statistic methods, which could auto- matically analyze complex data and produce significant results. Following is four notable examples of such algo- rithms. Buchman et al. [29] concluded that machine learning-based CDS tools can accurately predict the onset of sepsis in an ICU patient 4–12 h prior to clinical\\n  ',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'recognition. Seymour et al. [30] performed different machine learning methods and suggested 4 clinical phe- notypes may help in understanding the heterogeneity of treatment effects for patients with sepsis. Kashyap et al.\\n[31] used JMP statistical software to conduct a super- vised machine learning for identification of sepsis and septic shock and found it’s a reliable and efficient alterna- tive to manual chart review. Winslow et al. [32] applied machine learning to features calculated from patient with sepsis to estimate whether or not a patient enters this pre-shock state. However, all those articles mentioned above haven’t verified the superiority of machine learning models or done relevant further analysis or offered inter- pretation compared to other types of prediction model. More importantly, the primary outcomes of these studies are the emergence of detection of sepsis rather than poor clinical outcomes (i.e. mortality) of sepsis. XGBoost, a decision-tree-based algorithm, has been found to be the best algorithm for machine learning and prediction com- petition hosted by Kaggle.com [10, 33]. Due to its best precision value and performance, XGBoost-based algo- rithm machine learning is increasingly emphasized as a competitive alternative to regression analysis and used in predicting clinical adverse outcomes.\\n  In terms of the prognosis of sepsis, an artificial intel- ligence algorithm based on XGBoost has been published by Yuan et al. [9] in 2020. Nevertheless, both of our arti- cles about XGboost models have its own merits. Firstly,',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'there are several limits in Yuan’s study mentioned by him- self. For instance, the features selected were according to clinical experience but not algorithm; the representative- ness of features may not clear in sepsis and some impor- tant dynamic features were not included; left or right censoring may be resulted from incomplete recording of electronic medical records (EMR) when patients transfer or discharge; besides, there were no validations for the XGboost model and no traditional regression analysis was used as a control. Secondly, there are some superi- orities in our model compared to Yuan’s machine learn- ing: the features selected were according to backward stepwise analysis which increased representativeness and accuracy; some important features are not missing such as lactate, AG, etc.; data was from MIMIC-III which is an updated database and provides detailed information; classic logistic regression analysis with AUCs and DCAs were used to contrast with XGboost except for tradi- tional scoring system; crucially, nomogram and CIC were plotted to evaluate the clinical usefulness and applica- bility net benefits of the model. Thirdly, of course, some common limitations exist in both of our articles: meas- urement bias within calculation is possible due to the method is based on experts’ opinion; sepsis could happen at any time during ICU admission (even possibly hours before labelled), although with the help of algorithm, it’s still difficult for intensivists to integrate the data of point- of-care vital signs, latest lab reports and etc. all the time',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'and to determine the patient condition with sepsis or not according to any database.\\n  An interesting finding in our study is that the fea- tures included in the XGBoost-based model and logistic regression model showed consistent, which  indicated the excellent performances of XGBoost model were sig- nificant, although the two models may fit and perform differently in different datasets. However, these recogni- tions of the features and sepsis-induced mortality cannot be entirely explained. Hence, further studies and efforts are needed to investigate the mechanisms underlying the role of these variables included in patients with sepsis-3. Following is a brief summary of remarkable or contro- versial features included in the XGBoost model. Among these features, the weight of urine output is the great- est which represents it is the most important predictor for 30-day mortality MIMIC-III patients. This result is compatible with some clinical studies. Vieira et al. [34] reported higher urine output is associated with success- ful enteral nutrition therapy in septic shock patients. Laranja et al. [35] concluded that septic patients with no acute kidney injury (AKI) had a more preserved urine output compared to that in all groups with AKI or AKI/ chronic kidney disease (CKD). Lin et al. [36] indicated decreased urine output could be manifested as a com- pensatory mechanism to maintain intravascular volume, and also imply intrinsic renal injury for patients in sepsis. Teixeira et al. [37] confirmed that the use of diuretics was inversely associated with mortality and itself may exert a protective effect. Sodium_max is an interesting feature in our XGBoost-based model. Hypernatremia can be an independent predictor of poor outcome in septic patients in the ICU, which is similar to some views [38]. However, another study [39] showed the risk of death increased by 71.6% when serum sodium was < 129 mmol/L for patients with sepsis. Lactate and AG are typical meta- bolic indicators. Patients with a normal lactate level alone should not be excluded life-threatening sepsis, and with high AG levels regardless of lactate levels, have high rates of mortality and should also be considered for early, aggressive therapy [40]. However, Liu and Velissaris et al. [41, 42] clearly pointed out that plasma lactate were asso- ciated with poor outcomes in patients with sepsis and predicted mortality. INR is another crucial predictive fac- tor in the machine learning model. Several studies [43, 44] found septic patients with elevated INR and platelet count appeared to have a greater risk of death compared with those without coagulopathy. There is no doubt that age and metastatic cancer as basic demographic infor- mation could be included in the model which plays unfavorable effects for the mortality. Whereas, survival in critically ill cancer patients with sepsis improved sig- nificantly over time but reasons or mechanisms for this',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'condition haven’t been identified [45]. In consideration of the source of infection, we found blood infection ranks the highest (38.49%), followed by MRSA screen (35.49%) and urine (17.36%), which indicates that we can per- form empirical antibiotics treatment, but de-escalation or determination of whether or not to stop antibiotics or successful implementation of antimicrobial stewardship may help to improve a patient’s clinical prognosis while preventing adverse outcomes [46].\\n  The strength of this study was mainly that it was the first time to predict the 30 day mortality of MIMIC-III patients with sepsis-3 using the XGBoost model, and compared to traditional regression analysis and clinical scoring system, and meanwhile verified by nomogram and CIC. We must acknowledge some other limitations of our study: firstly, because the data come from only one database and the majority of patients were white, poten- tial bias may occur; secondly, further exploration for the database was not performed, which may lead to the aban- donment of some key variables; thirdly, the proposed model was not designed to be validated by developing set from the database or our clinical data. Even so, we believe that the proposed model may contribute to further our understanding of the prognosis of patients suffering from sepsis in ICU.\\nConclusions\\nIn conclusion, this study shows that the machine learn- ing based on XGboost algorithm does outperform con- ventional logistic regressions and scoring system. This XGboost model may prove clinically useful and assist cli- nicians in tailoring precise management and therapy for the patients with sepsis-3 which is essential for maximiz- ing the patient’s chance of survival.\\nSupplementary information\\nSupplementary information accompanies this paper at https://doi. org/10.1186/s12967-020-02620-5.',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': '\\nAbbreviations\\nICU: Intensive care unit; Ang-2: Angiopoietin-2; PCT: Procalcitonin; APHACHE-II: Acute physiology and chronic health evaluation-II; SAPS-II: Simplified acute physiology score-II; XGBoost: EXtreme Gradient Boosting; KDD: Knowledge Discovery and Data Mining; MIMIC-III: Medical Information Mart for Intensive Care III; BIDMC: Beth Israel Deaconess Medical Center; MIT: Massachusetts Institute of Technology; ICD-9: International Classification of Diseases and Ninth Revision; NIH: National Institutes of Health; SQL: Structure query language; BMI: Body mass index; HR: Heart rate; SBP, sysbp: Systolic blood pres- sure; DBP, diasbp: Diastolic blood pressure; MAP: Mean arterial pressure; TEMP: Temperature; RR, Resprate: Respiratory rate; SpO2: Oxyhemoglobin saturation; ABG: Arterial blood gas; Meanbp: Mean blood pressure; Tempc: Temperature; Bun: Blood urea nitrogen; Wbc: White blood cell; INR: International normal- ized ratio; Vent: Ventilation; Max: Maximum; Min: Minimum; AIC: Akaike information criterion; AUCs: Area under curves; ROC: The receiver operating characteristic curves; OR: Odds ratio; CI: Confidence interval; DCA: Decision',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'curve analysis; CIC: Clinical impact curve; WHO: World Health Organization; SOFA: The sequential organ failure assessment; qSOFA: Quick SOFA; VTIBW: The tidal volume indexed on ideal body weight; MED: Medical-general service for internal medicine; CMED: Cardiac medical-for non-surgical cardiac related admissions; EMR: Electronic medical records; AKI: Acute kidney injury; CKD: Chronic kidney disease.',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'Acknowledgements\\nNot applicable.',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'Authors’ contributions\\nNH, ML, LH, and KW designed the work. BX, LW, RZ and YY record and summa- rized the patient of MIMIC features. XS, ZP and KW analyzed datasets. NH, ML and KW wrote this paper. All authors read and approved the final manuscript.',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'Funding\\nNot applicable.',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'Availability of data and materials\\nThe datasets used and/or analyzed during the current study are available from the corresponding author on reasonable request.',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'Ethics approval and consent to participate\\nNot applicable.',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'Consent for publication\\nNot applicable.',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'Competing interests\\nThe authors declare that they have no competing interests.',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'Author details\\n1 Department of Hand and Foot Surgery, Zibo Central Hospital, Shandong First Medical University, Zibo 255036, Shandong, China. 2 Independent researcher, bs20m2l@leeds.ac.uk, Leeds LS29JT, UK. 3 Institute of Medicine and Nursing,\\nHubei University of Medicine, Shiyan 442000, Hubei, China. 4 Department of Critical Care Medicine, Zibo Central Hospital, Shandong First Medical University , Zibo 255036, Shandong, China. 5 Fengnan District Maternal and Child Health Care Hospital of Tangshan City, Tangshan 063300, Hebei,\\nChina. 6 Department of Urology Surgery, Zibo Central Hospital, Shandong First Medical University , Zibo 255036, China.',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}},\n",
       " {'content': 'Received: 28 August 2020 Accepted: 18 November 2020\\n',\n",
       "  'meta': {'name': 's12967-020-02620-5 (1).txt'}}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "855a67bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.base -  Duplicate Documents: Document with id '911f0a35aac5f8a66a32093438b38afa' already exists in index 'document'\n"
     ]
    }
   ],
   "source": [
    "##now writes the dict to haystack document store\n",
    "\n",
    "document_store.write_documents(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e07434a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.sparse -  Found 51 candidate paragraphs from 51 docs in DB\n"
     ]
    }
   ],
   "source": [
    "# An in-memory TfidfRetriever based on Pandas dataframes\n",
    "# retrievers narrow down Reader scope to smaller text units\n",
    "# see haystack documentation -> other retrievers\n",
    "\n",
    "from haystack.nodes import TfidfRetriever\n",
    "\n",
    "retriever = TfidfRetriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9e29e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find deepset/roberta-base-squad2 locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Loaded deepset/roberta-base-squad2\n",
      "INFO - haystack.modeling.logger -  ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n",
      "INFO - haystack.modeling.infer -  Got ya 15 parallel workers to do inference ...\n",
      "INFO - haystack.modeling.infer -   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "INFO - haystack.modeling.infer -  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /|\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /|\\\n",
      "INFO - haystack.modeling.infer -  /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\  /'\\  /'\\  /'\\  /'\\  /'\\  / \\  /'\\  /'\\\n"
     ]
    }
   ],
   "source": [
    "# Reader scans text returned by retriever and extracts k-best answers\n",
    "# Load a fine-tuned  model (e.g. RoBERTa QA = \"deepset/roberta-base-squad2\")\n",
    "# alternatives (Reader): TransformersReader (leveraging the pipeline of the Transformers package)\n",
    "# alternatives (Models): e.g. \"distilbert-base-uncased-distilled-squad\" (fast) or \"deepset/bert-large-uncased-whole-word-masking-squad2\" (good accuracy)\n",
    "# can adjust the model to return \"no answer possible\" with the no_ans_boost. Higher values mean the model prefers \"no answer possible\"\n",
    "# alternatively, QA models on model hub (https://huggingface.co/models)\n",
    "#sota: ahotrod/albert_xxlargev1_squad2_512\n",
    "#dmis-lab/biobert-large-cased-v1.1-squad\n",
    "#\n",
    "\n",
    "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fd7a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative example:\n",
    "# reader = TransformersReader(model_name_or_path=\"distilbert-base-uncased-distilled-squad\", tokenizer=\"distilbert-base-uncased\", use_gpu=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4aac1ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sets pipeline to contain retriever and reader\n",
    "\n",
    "pipe = ExtractiveQAPipeline(reader, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee19dba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1=\"what was the study objective?\"\n",
    "q2=\"what disease is being studied?\"\n",
    "q3=\"how many patient data samples were included in this study?\"\n",
    "#q4=\"how many data samples were used to train the model?\"\n",
    "#q5=\"what modalities of data is used in this study?\"\n",
    "q6=\"what are the variable types used in this study?\"\n",
    "q7=\"what country was the study conducted in?\"\n",
    "q8=\"what city did the data come from?\"\n",
    "q9=\"did data come from an existing database?\"\n",
    "q10=\"did data come from an organisation?\"\n",
    "q11=\"was the model tested on a independent dataset?\"\n",
    "q12=\"what was the outcome measured by the area under the curve (AUC)?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2629684d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\pytorch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.15 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.41 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.14s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.31 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.13 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.24 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.22 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.29 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.03s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.89 Batches/s]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\pytorch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.78 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.06s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.87 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.02 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.30 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.92 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.98 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.60 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.25 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.07s/ Batches]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\pytorch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.23 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.80 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.52 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.00 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.20 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.00s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.52 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.62 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.25 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.75 Batches/s]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\pytorch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.18 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.23 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.06s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.57 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.56 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.04s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.61 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.32 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.28 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.06 Batches/s]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\pytorch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.27 Batches/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.03s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.58 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.31 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.02s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.30 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.75 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.18 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.18 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.27 Batches/s]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\pytorch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.12 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.60 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.35 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.64 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.66 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.31 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.28 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.05s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.33 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.71 Batches/s]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\pytorch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.54 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.87 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.70 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.92 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.38 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.84 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.35 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.27 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.28 Batches/s]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\pytorch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.88 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.73 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.73 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.95 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.34 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.46 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.56 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.30 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.26 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.27 Batches/s]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\pytorch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.28 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.12 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.04s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.57 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.62 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.01s/ Batches]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.33 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.92 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.31 Batches/s]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\pytorch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.28 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.03s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.31 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.55 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.24 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.31 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.94 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.19 Batches/s]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]"
     ]
    }
   ],
   "source": [
    "# Number of candidates the reader and retriever return\n",
    "# Higher top_k for retriever = better accuracy (but slower)\n",
    "qlist = [q1, q2, q3, q6, q7, q8, q9, q10, q11, q12]\n",
    "plist = qlist.copy() #keep same length\n",
    "l = len(qlist)\n",
    "\n",
    "for i in range(0,l):\n",
    "    plist[i] = pipe.run(\n",
    "            query=qlist[i], params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}}\n",
    "        )\n",
    "\n",
    "#p1 = pipe.run(\n",
    "#    query=q1, params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}}\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0a7e80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,l):\n",
    "    print_answers(plist[i], details='minimum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db036149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec9024b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dda6831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c56d559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
