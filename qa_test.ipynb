{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30bc93f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60a63b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adc163f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.base -  Numba not found, replacing njit() with no-op implementation. Enable it with 'pip install numba'.\n",
      "INFO - haystack.modeling.model.optimization -  apex not found, won't use it. See https://nvidia.github.io/apex/\n"
     ]
    }
   ],
   "source": [
    "from haystack.utils import clean_wiki_text, convert_files_to_dicts, fetch_archive_from_http, print_answers\n",
    "from haystack.nodes import FARMReader, TransformersReader\n",
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "\n",
    "#haystack contains a search system for retrieval and QA across documents.\n",
    "#designed for large documents, but pipeline also works for single document QA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b6ab6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n"
     ]
    }
   ],
   "source": [
    "# In-Memory Document Store\n",
    "from haystack.document_stores import InMemoryDocumentStore\n",
    "document_store = InMemoryDocumentStore() #to enable documents stored in local memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1d5a4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.utils.preprocessing -  Converting testdata\\15774048.txt\n"
     ]
    }
   ],
   "source": [
    "doc_dir = \"testdata\"\n",
    "\n",
    "dicts = convert_files_to_dicts(dir_path=doc_dir, split_paragraphs=True)\n",
    "\n",
    "## if there are multiple documents for database, this puts all relevant docs into dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a66aa6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': \"Open Access Available online http://ccforum.com/content/9/2/R150 R150 April 2005  Vol 9 No 2 Research Comparison between logistic regression and neural networks to  predict death in patients with suspected sepsis in the emergency  room FabiÃ¡n Jaimes1, Jorge Farbiarz2, Diego Alvarez3 and Carlos MartÃ\\xadnez4 1Associate Professor, Department of Internal Medicine and Escuela de Investigaciones MÃ©dicas Aplicadas (EIMA â€“ GRAEPI), School of Medicine,  Universidad de Antioquia, MedellÃ\\xadn, Colombia 2Chairman, Department of Physiology, Universidad de Antioquia, MedellÃ\\xadn, Colombia 3Assistant Professor, Department of Physiology, Universidad de Antioquia, MedellÃ\\xadn, Colombia 4Assistant Physician, Department of Internal Medicine, Division of Pulmonary and Critical Care Medicine, FundaciÃ³n Santa Fe de BogotÃ¡, BogotÃ¡,  Colombia Corresponding author: FabiÃ¡n Jaimes, fjaimes@catios.udea.edu.co Abstract Introduction Neural networks are new methodological tools based on nonlinear models. They appear to be better at prediction and classification in biological systems than do traditional strategies such as logistic regression. This paper provides a practical example that contrasts both approaches within the setting of suspected sepsis in the emergency room. Methods The study population comprised patients with suspected bacterial infection as their main diagnosis for admission to the emergency room at two University based hospitals. Mortality within the first 28 days from admission was predicted using logistic regression with the following variables: age, immunosuppressive systemic disease, general systemic disease, Shock Index, temperature, respiratory rate, Glasgow Coma Scale score, leucocyte counts, platelet counts and creatinine. Also, with the same input and output variables, a probabilistic neural network was trained with an adaptive genetic algorithm. The network had three neurone layers: 10 neurones in the input layer, 368 in the hidden layer and two in the output layer. Calibration was measured using the Hosmer Lemeshow goodness of fit test and discrimination was determined using receiver operating characteristic curves. Results A total of 533 patients were recruited and overall 28 day mortality was 19%. The factors chosen by logistic regression (with their score in parentheses) were as follows: immunosuppressive systemic disease or general systemic disease (2), respiratory rate 24â€“33 breaths/min (1), respiratory rate â‰¥ 34 breaths/min (3), Glasgow Come Scale score â‰¤12 (3), Shock Index â‰¥ 1.5 (2) and temperature <38Â°C (2). The network included all variables and there were no significant differences in predictive ability between the approaches. The areas under the receiver operating characteristic curves were 0.7517 and 0.8782 for the logistic model and the neural network, respectively (P = 0.037). Conclusion A predictive model would be an extremely useful tool in the setting of suspected sepsis in the emergency room. It could serve both as a guideline in medical decision making and as a simple way to select or stratify patients in clinical research. Our proposed model and the specific development method â€“ either logistic regression or neural networks â€“ must be evaluated and validated in an independent population. Received: 5 October 2004 Revisions requested: 1 December 2004 Revisions received: 17 December 2004 Accepted: 13 January 2005 Published: 17 February 2005 Critical Care 2005, 9:R150 R156 (DOI 10.1186/cc3054) This article is online at: http://ccforum.com/content/9/2/R150 Â© 2005 Jaimes et al.; licensee BioMed Central Ltd.  This is an Open Access article distributed under the terms of the  Creative Commons Attribution License (http://creativecommons.org/ licenses/by/2.0), which permits unrestricted use, distribution, and  reproduction in any medium, provided the original work is properly  cited. ANN = artificial neural network; APACHE = Acute Physiology and Chronic Health Evaluation; ER = emergency room; GCS = Glasgow Coma Scale;  GSD = general systemic disease; ICU = intensive care unit; ISD = immunosuppressive systemic disease; ROC = receiver operating characteristic;  SIRS = systemic inflammatory response syndrome. Critical Care    April 2005  Vol 9 No 2    Jaimes et al. R151 Introduction Sepsis is the second leading cause of death among patients in noncoronary intensive care units (ICUs) and is the 10th leading cause of death overall in the USA [1]. Despite new and complex therapies, the incidence of sepsis has increased annually at a constant rate over the past 20 years, and there have been no substantial changes in the associated mortality [2]. A tool that could stratify the severity of sepsis from the initial stages in the clinical course would enhance our understanding of this disorder and its management. A simple system designed to estimate the probability of death would represent the basis for improved diagnosis, prognostication and treat  ment. Specifically, such a model, in the setting of the emer  gency room (ER), could guide decisions regarding ICU admission or whether a particular type of therapy should be instituted. The strategy may be developed from the definitions proposed by the American College of Chest Physicians/Soci  ety of Critical Care Medicine in 1992 [3]. These definitions include a generalized process with clinical findings that may represent an initial phase during the sepsis phenomenon â€“ the systemic inflammatory response syndrome (SIRS). Although the natural history seems to reflect a continuum through differ  ent stages of an inflammatory response, from SIRS to septic shock [4], an unequivocal linear sequence of events is far from clinically apparent. Thus, classical analytical models, such as logistic regression, are limited in terms of their ability to eluci  date the interplay that underlies the sepsis phenomenon. Advances in statistical methods have supplied the tools nec  essary to model complex nonlinear relationships among many variables relevant to biological systems. Artificial neural net  works (ANNs) are computer programs that simulate some of the higher level functions of the human brain. As in the brain, there are neurones and synapses, with various synaptic con  nection strengths â€“ called 'weights' â€“ for each connected pair of neurones. However, unlike the brain but similar to many computer programs, there is a specific set of input and output neurones for each problem and each net. These input and out  put neurones correspond to the inputs to and outputs from a traditional computer program. The other, termed 'hidden' neu  rones, along with the synapses and weights, correspond to the instructions in a traditional program. Use of ANNs as clinical prediction models has been explored in many areas of medi  cine, including nephrology [5], microbiology [6], radiology [7] and neurology [8]. Thus far, however, we are unaware of their use in sepsis. In this study we present a practical example that contrasts the abilities of logistic regression and neural net  works to predict death in patients admitted to the ER with sus  pected sepsis as their main cause of hospitalization. Materials and methods Study design In this longitudinal cohort study, patients were recruited between August 1998 and March 1999. Starting from admis  sion to the ER, the patients were followed for 28 days or until death. Setting The patients were admitted to the ERs of two reference hospi  tals: the Hospital Universitario San Vicente de PaÃºl and the Hospital General de MedellÃ\\xadn. Hospital Universitario San Vice  nte de PaÃºl is a 550 bed, fourth level university hospital, and is a referral centre for a region including approximately 3 million habitants. Hospital General de MedellÃ\\xadn is a 300 bed, third level teaching hospital, and is a referral centre for the metro  politan area. Both are located in MedellÃ\\xadn, Colombia. Participants We included patients aged 15 years or older with any sus  pected or confirmed bacterial infection as their admission diagnosis and at least one of the following SIRS criteria: tem  perature >38Â°C or <36Â°C; and leucocyte count >12000/ mm3, <4000/mm3, or >10% immature forms (bands). We excluded eligible participants if they, their relatives, or their doctors refused to provide consent to participate in the study, or if they died or were discharged before 24 hours. Ethics committees of both hospitals had previously approved the pro  tocol, and patients or their legal representatives signed an informed consent form. Measurements The primary outcome variable was mortality within the first 28 days after admission to the ER. For those patients who were discharged before day 28, an evaluation of their vital status was conducted in the outpatient control centre or by phone if a personal interview was not possible. Independent variables recorded at admission were as follows: age, immunosuppres  sive systemic disease (ISD; i.e. any of cancer, chemotherapy, steroid use or AIDS), general systemic disease (GSD; i.e. any of cardiac failure, diabetes, renal failure, chronic obstructive lung disease, or cirrhosis), Shock Index (heart rate/systolic arterial pressure), body temperature, respiratory rate, Glasgow Coma Scale (GCS) score, leucocyte count, platelet count and creatinine blood level. Research assistants in the ER collected clinical variables at admission in a standardized manner. Lab  oratory variables were analyzed using standard quality control procedures at the participating institutions. Missing data for continuous variables were estimated with simple imputations using the median nonmissing value. In total, estimation proce  dures were performed in 2.6% (14 simple records) of baseline values. Data analysis and management The procedure for the logistic model has been described in detail elsewhere [9]. Briefly, we conducted univariate logistic Available online http://ccforum.com/content/9/2/R150 R152 regression analysis for each candidate variable, with P < 0.25 being the criterion for acceptance in the model. Collinearity was checked with a matrix of correlations, using the Spearman rank correlation coefficient between independent variables. We chose a conservative strategy, with r â‰¥ 0.4 in at least one correlation as the criterion for multicollinearity. Logistic model assumptions (i.e. no interaction terms and a linear relationship between the logit and the continuous covariates) were veri  fied. Then, a logistic regression analysis, employing a forward stepwise inclusion method, was developed using a P value of 0.05 at entry. This automatic procedure was contrasted with a backward elimination method and with a full model that included all of the candidate variables, in order to confirm the validity and stability of our results. For continuous variables, the cutoff points for changes in the probability of death were explored with locally weighted regression analysis and the lowess procedure [10]. According to the cutoff points detected, dummy variables were constructed and a new logis  tic regression model was fitted with those variables. In order to obtain the simplest score with the same scale within and between ranges of physiological variables and co morbid con  ditions, the regression coefficients were all divided by the low  est one, and then rounded off to the nearest whole number, as the weight reflecting 'risk' for death for each variable. In defin  ing the severity levels by the size of the coefficients, compara  ble severity levels within variables or conditions were grouped together. The global score for every patient in the cohort was calculated and a new logistic regression equation with the score as independent variable was fitted. The model calibration â€“ observed mortality versus that pre  dicted with the score â€“ was evaluated using the Hosmer  Lemeshow goodness of fit test. The test result, under a Ï‡2 dis  tribution, provides a P value in which higher values (P > 0.05) indicate nonsignificant differences between observed and predicted mortality. The discriminatory ability â€“ the capacity of the model to separate survivors from nonsurvivors, with 1.0 and 0.5 meaning perfect and random discrimination, respec  tively â€“ was determined using receiver operating characteristic (ROC) curve analysis. Internal validation was done with 2000 bootstrap replications of the model. All statistical analyses were performed with Stata Statistical Software, Release 7.0 (Stata Corporation, College Station, TX, USA). Using the same input and output variables, a probabilistic neu  ral network was trained using an adaptive genetic algorithm (NeuroShellÂ©; Ward Systems Group Inc., Frederick, MD, USA). The network has three neurone layers, with 10 neurones in the input layer, 368 in the hidden layer and two in the output layer, the latter indicating death versus survival. Of the cohort 75% was used to train the network and 25% was used in test  ing. The training criterion was that 20 generations had elapsed without changes in the minimum error. The general perform  ance of the neural network was evaluated using the ROC curve and the Hosmer Lemeshow goodness of fit test. The difference between the two ROC curves â€“ logistic regression and neural network â€“ was tested using the Wilcoxon statistic based on pairwise comparisons [11]. Results A total of 542 potentially eligible participants were admitted during the study period. Nine were excluded because of death (n = 5) or discharge (n = 4) during the first 24 hours. The final study population therefore included 533 patients, 55% (n = 293) of whom were male. Their age (mean Â± standard devia  tion) was 48 Â± 21 years, and their median hospital stay was 8 days (interquartile range 4â€“15 days). Overall 28 day mortality was 19% (n = 101), and 14% (n = 75) of the cohort was admitted to ICU. The most common diagnoses suspected at admission were community acquired pneumonia (recorded in 36% of patients), followed by soft tissue infection (17%), intra abdom  inal infection (12%), urinary tract infection (11%) and others (11%); sepsis of undetermined source was recorded in 13% patients. The major pre existing conditions related to admis  sion were trauma or surgery more than 24 hours before admis  sion (21%), chronic obstructive pulmonary disease (12%), diabetes (13%) and miscellaneous others (9%). Of the patients, 45% were free of associated diseases. A total of 283 (53%) out of 533 cases of clinically suspected bacterial infection were microbiologically confirmed, 113 of which (40%) grew on blood samples. The rate of positive blood cultures among the total requested was 27%, and the most frequently isolated micro organisms were Escherichia coli (19%), Staphylococcus aureus (16%), Streptococcus pneumoniae (13%), Staphylococcus coagulase negative (13%), Klebsiella pneumoniae (9%), Enterobacter spp. (6%), Enterococcus spp. (4%), Streptococcus pyogenes (3%), non  fermenting Gram negative bacilli (3%) and others (14%). After conducting univariate analysis for the logistic regression, leucocyte count was considered ineligible for inclusion in the model (P = 0.893). The evaluation of collinearity was carried out for all variables using the Spearman correlation coefficient. A significant correlation (r = 0.44) was found between age and GSD (P = 0.0000). Similar correlations, but to a lesser degree, were found between age and Shock Index (r = 0.1453; P = 0.0008) and between age and temperature (r = 0.1940; P = 0.0000). Therefore, age was excluded from the predictor variables. A multiple logistic regression model was applied to the overall 28 day mortality, taking into account GSD, ISD, Shock Index, respiratory rate, temperature, GCS score, creatinine and platelet count as predictive variables. This model allowed us to discard the latter two variables because they were statistically nonsignificant. For the varia  bles respiratory rate, temperature, Shock Index and GCS score, the cutoff points for changes in the probability of death Critical Care    April 2005  Vol 9 No 2    Jaimes et al. R153 were sought by locally weighted regression. The results are shown in Table 1. With the previous values, 12 dummy variables were con  structed considering the first level (1) as the reference value. These new variables, in conjunction with the two nominal vari  ables previously involved (GSD and ISD), were fitted in a new logistic regression model for prediction of mortality. After divid  ing and rounding off coefficients to the nearest whole number, some levels and variables were bound together, namely co  morbid conditions, GCS score, Shock Index and body temper  ature. The final meaningful variables are summarized in Table 2 according to their levels and relative weights. In this way the final scale of severity was a range between 0 and 12. With these data, the score for each patient in the cohort was calculated, and a model that provides an estimate of severity, defined as the probability of 28 day mortality, was obtained. The Hosmer Lemeshow goodness of fit test yielded a value of 7.54 (P = 0.5807). By ROC curve analysis for dis  criminative capacity, the area under the curve was 0.7517. The bootstrapped coefficients for 2000 replications exhibited standard errors of under 10% of those observed in the model, and the values for the Hosmer Lemeshow goodness of fit test and the area under the ROC curve in this set were 8.96 (P = 0.4321) and 0.7119, respectively. The neural network included all of the independent variables. Their weight, by the smoothing factor, ranged from 2.65 for temperature to 0.34 for ISD. The Hosmer Lemeshow good  ness of fit test yielded a value of 8.03 (P = 0.475), and the area under the ROC curve was 0.8782. The difference between ROC curves was statistically significant according to the Wilcoxon statistic based on pairwise comparisons (P = 0.037). Figure 1 shows the comparison of observed and pre  dicted deaths with both methods.\",\n",
       "  'meta': {'name': '15774048.txt'}}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "855a67bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##now writes the dict to haystack document store\n",
    "\n",
    "document_store.write_documents(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e07434a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.sparse -  Found 1 candidate paragraphs from 1 docs in DB\n"
     ]
    }
   ],
   "source": [
    "# An in-memory TfidfRetriever based on Pandas dataframes\n",
    "# retrievers narrow down Reader scope to smaller text units\n",
    "# see haystack documentation -> other retrievers\n",
    "\n",
    "from haystack.nodes import TfidfRetriever\n",
    "\n",
    "retriever = TfidfRetriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9e29e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find deepset/roberta-base-squad2 locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Loaded deepset/roberta-base-squad2\n",
      "INFO - haystack.modeling.logger -  ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n",
      "INFO - haystack.modeling.infer -  Got ya 15 parallel workers to do inference ...\n",
      "INFO - haystack.modeling.infer -   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "INFO - haystack.modeling.infer -  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /|\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /|\\\n",
      "INFO - haystack.modeling.infer -  /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\  /'\\  /'\\  /'\\  /'\\  /'\\  / \\  /'\\  /'\\\n"
     ]
    }
   ],
   "source": [
    "# Reader scans text returned by retriever and extracts k-best answers\n",
    "# Load a fine-tuned  model (e.g. RoBERTa QA = \"deepset/roberta-base-squad2\")\n",
    "# alternatives (Reader): TransformersReader (leveraging the pipeline of the Transformers package)\n",
    "# alternatives (Models): e.g. \"distilbert-base-uncased-distilled-squad\" (fast) or \"deepset/bert-large-uncased-whole-word-masking-squad2\" (good accuracy)\n",
    "# can adjust the model to return \"no answer possible\" with the no_ans_boost. Higher values mean the model prefers \"no answer possible\"\n",
    "# alternatively, QA models on model hub (https://huggingface.co/models)\n",
    "#sota: ahotrod/albert_xxlargev1_squad2_512\n",
    "#dmis-lab/biobert-large-cased-v1.1-squad\n",
    "#\n",
    "\n",
    "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fd7a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative example:\n",
    "# reader = TransformersReader(model_name_or_path=\"distilbert-base-uncased-distilled-squad\", tokenizer=\"distilbert-base-uncased\", use_gpu=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4aac1ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sets pipeline to contain retriever and reader\n",
    "\n",
    "pipe = ExtractiveQAPipeline(reader, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee19dba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1=\"what was the study objective?\"\n",
    "q2=\"what is the study trying to predict?\"\n",
    "q3=\"what disease is being studied?\"\n",
    "###\n",
    "q4=\"how many patient data samples were included in this study?\"\n",
    "#q4=\"how many data samples were used to train the model?\"\n",
    "#q5=\"what modalities of data is used in this study?\"\n",
    "q5=\"what are the variable types used in this study?\"\n",
    "###\n",
    "q6=\"what country was the study conducted in?\"\n",
    "q7=\"did data come from a care provider?\"\n",
    "q8=\"did data come from an existing database?\"\n",
    "q9=\"did data come from an organisation?\"\n",
    "###\n",
    "q10=\"was the model tested on a independent dataset?\"\n",
    "q11=\"was the model tested prospectively?\"\n",
    "q12=\"what were the results of the study?\"\n",
    "#q12=\"what was the area under the curve (AUC) value?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2629684d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\pytorch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.57s/ Batches]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\pytorch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.51s/ Batches]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\pytorch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.48s/ Batches]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\pytorch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.48s/ Batches]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\pytorch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.53s/ Batches]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\pytorch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.56s/ Batches]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\pytorch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.54s/ Batches]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\pytorch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.37s/ Batches]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\pytorch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.36s/ Batches]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\pytorch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.44s/ Batches]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\pytorch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.50s/ Batches]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]C:\\Users\\Joe Z\\anaconda3\\envs\\pytorch\\lib\\site-packages\\haystack\\modeling\\model\\prediction_head.py:485: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  start_indices = flat_sorted_indices // max_seq_len\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.63s/ Batches]\n"
     ]
    }
   ],
   "source": [
    "# Number of candidates the reader and retriever return\n",
    "# Higher top_k for retriever = better accuracy (but slower)\n",
    "qlist = [q1, q2, q3, q4, q5, q6, q7, q8, q9, q10, q11, q12]\n",
    "plist = qlist.copy() #keep same length\n",
    "l = len(qlist)\n",
    "\n",
    "for i in range(0,l):\n",
    "    plist[i] = pipe.run(\n",
    "            query=qlist[i], params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}}\n",
    "        )\n",
    "\n",
    "#p1 = pipe.run(\n",
    "#    query=q1, params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}}\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f0a7e80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: what was the study objective?\n",
      "Answers:\n",
      "[   {   'answer': '20 generations had elapsed without changes in the minimum '\n",
      "                  'error',\n",
      "        'context': ' test  ing. The training criterion was that 20 generations '\n",
      "                   'had elapsed without changes in the minimum error. The '\n",
      "                   'general perform  ance of the neural n'},\n",
      "    {   'answer': 'predict death in patients with suspected sepsis in the '\n",
      "                  'emergency  room',\n",
      "        'context': 'stic regression and neural networks to  predict death in '\n",
      "                   'patients with suspected sepsis in the emergency  room '\n",
      "                   'FabiÃ¡n Jaimes1, Jorge Farbiarz2, Diego'},\n",
      "    {   'answer': 'suspected bacterial infection',\n",
      "        'context': 'y room. Methods The study population comprised patients '\n",
      "                   'with suspected bacterial infection as their main diagnosis '\n",
      "                   'for admission to the emergency room'}]\n",
      "\n",
      "Query: what is the study trying to predict?\n",
      "Answers:\n",
      "[   {   'answer': 'Mortality',\n",
      "        'context': 'for admission to the emergency room at two University '\n",
      "                   'based hospitals. Mortality within the first 28 days from '\n",
      "                   'admission was predicted using logistic '},\n",
      "    {   'answer': 'death versus survival',\n",
      "        'context': ' hidden layer and two in the output layer, the latter '\n",
      "                   'indicating death versus survival. Of the cohort 75% was '\n",
      "                   'used to train the network and 25% was us'},\n",
      "    {   'answer': 'death',\n",
      "        'context': 'h Comparison between logistic regression and neural '\n",
      "                   'networks to  predict death in patients with suspected '\n",
      "                   'sepsis in the emergency  room FabiÃ¡n Jaimes'}]\n",
      "\n",
      "Query: what disease is being studied?\n",
      "Answers:\n",
      "[   {   'answer': 'sepsis',\n",
      "        'context': 'ession and neural networks to  predict death in patients '\n",
      "                   'with suspected sepsis in the emergency  room FabiÃ¡n '\n",
      "                   'Jaimes1, Jorge Farbiarz2, Diego Alvarez3'},\n",
      "    {   'answer': 'sepsis',\n",
      "        'context': ' example that contrasts both approaches within the setting '\n",
      "                   'of suspected sepsis in the emergency room. Methods The '\n",
      "                   'study population comprised patients '},\n",
      "    {   'answer': 'sepsis',\n",
      "        'context': 'ive model would be an extremely useful tool in the setting '\n",
      "                   'of suspected sepsis in the emergency room. It could serve '\n",
      "                   'both as a guideline in medical de'}]\n",
      "\n",
      "Query: how many patient data samples were included in this study?\n",
      "Answers:\n",
      "[   {   'answer': '533',\n",
      "        'context': 'rmined using receiver operating characteristic curves. '\n",
      "                   'Results A total of 533 patients were recruited and overall '\n",
      "                   '28 day mortality was 19%. The factor'},\n",
      "    {   'answer': '533',\n",
      "        'context': ' during the first 24 hours. The final study population '\n",
      "                   'therefore included 533 patients, 55% (n = 293) of whom '\n",
      "                   'were male. Their age (mean Â± standard d'},\n",
      "    {   'answer': '542',\n",
      "        'context': 'Wilcoxon statistic based on pairwise comparisons [11]. '\n",
      "                   'Results A total of 542 potentially eligible participants '\n",
      "                   'were admitted during the study period.'}]\n",
      "\n",
      "Query: what are the variable types used in this study?\n",
      "Answers:\n",
      "[   {   'answer': 'co  morbid conditions, GCS score, Shock Index and body '\n",
      "                  'temper  ature',\n",
      "        'context': 'nd variables were bound together, namely co  morbid '\n",
      "                   'conditions, GCS score, Shock Index and body temper  ature. '\n",
      "                   'The final meaningful variables are summ'},\n",
      "    {   'answer': 'age, immunosuppressive systemic disease',\n",
      "        'context': 'using logistic regression with the following variables: '\n",
      "                   'age, immunosuppressive systemic disease, general systemic '\n",
      "                   'disease, Shock Index, temperature, r'},\n",
      "    {   'answer': 'input and output',\n",
      "        'context': ' 7.0 (Stata Corporation, College Station, TX, USA). Using '\n",
      "                   'the same input and output variables, a probabilistic neu  '\n",
      "                   'ral network was trained using an a'}]\n",
      "\n",
      "Query: what country was the study conducted in?\n",
      "Answers:\n",
      "[   {   'answer': 'Colombia',\n",
      "        'context': 'ral centre for the metro  politan area. Both are located '\n",
      "                   'in MedellÃ\\xadn, Colombia. Participants We included '\n",
      "                   'patients aged 15 years or older with any sus'},\n",
      "    {   'answer': 'Colombia',\n",
      "        'context': 'â€“ GRAEPI), School of Medicine,  Universidad de '\n",
      "                   'Antioquia, MedellÃ\\xadn, Colombia 2Chairman, Department of '\n",
      "                   'Physiology, Universidad de Antioquia, MedellÃ'},\n",
      "    {   'answer': 'USA',\n",
      "        'context': 'tatistical Software, Release 7.0 (Stata Corporation, '\n",
      "                   'College Station, TX, USA). Using the same input and output '\n",
      "                   'variables, a probabilistic neu  ral ne'}]\n",
      "\n",
      "Query: did data come from a care provider?\n",
      "Answers:\n",
      "[   {   'answer': 'the score for each patient in the cohort was calculated',\n",
      "        'context': ' was a range between 0 and 12. With these data, the score '\n",
      "                   'for each patient in the cohort was calculated, and a model '\n",
      "                   'that provides an estimate of seve'},\n",
      "    {   'answer': 'Research assistants in the ER collected clinical variables '\n",
      "                  'at admission in a standardized manner',\n",
      "        'context': 'nd creatinine blood level. Research assistants in the ER '\n",
      "                   'collected clinical variables at admission in a '\n",
      "                   'standardized manner. Lab  oratory variables we'},\n",
      "    {   'answer': 'undetermined source was recorded in 13% patients',\n",
      "        'context': ' tract infection (11%) and others (11%); sepsis of '\n",
      "                   'undetermined source was recorded in 13% patients. The '\n",
      "                   'major pre existing conditions related to admi'}]\n",
      "\n",
      "Query: did data come from an existing database?\n",
      "Answers:\n",
      "[   {   'answer': 'undetermined source was recorded in 13% patients',\n",
      "        'context': ' tract infection (11%) and others (11%); sepsis of '\n",
      "                   'undetermined source was recorded in 13% patients. The '\n",
      "                   'major pre existing conditions related to admi'},\n",
      "    {   'answer': 'Ethics committees of both hospitals had previously approved '\n",
      "                  'the pro  tocol, and patients or their legal representatives '\n",
      "                  'signed an informed consent form',\n",
      "        'context': ' Ethics committees of both hospitals had previously '\n",
      "                   'approved the pro  tocol, and patients or their legal '\n",
      "                   'representatives signed an informed consent form'},\n",
      "    {   'answer': 'original work is properly  cited',\n",
      "        'context': 'istribution, and  reproduction in any medium, provided the '\n",
      "                   'original work is properly  cited. ANN = artificial neural '\n",
      "                   'network; APACHE = Acute Physiolog'}]\n",
      "\n",
      "Query: did data come from an organisation?\n",
      "Answers:\n",
      "[   {   'answer': 'Stata Corporation',\n",
      "        'context': 'lyses were performed with Stata Statistical Software, '\n",
      "                   'Release 7.0 (Stata Corporation, College Station, TX, USA). '\n",
      "                   'Using the same input and output varia'},\n",
      "    {   'answer': 'Research assistants in the ER collected clinical variables '\n",
      "                  'at admission in a standardized manner',\n",
      "        'context': 'nd creatinine blood level. Research assistants in the ER '\n",
      "                   'collected clinical variables at admission in a '\n",
      "                   'standardized manner. Lab  oratory variables we'},\n",
      "    {   'answer': 'Ethics committees of both hospitals had previously approved '\n",
      "                  'the pro  tocol, and patients or their legal representatives '\n",
      "                  'signed an informed consent form',\n",
      "        'context': ' Ethics committees of both hospitals had previously '\n",
      "                   'approved the pro  tocol, and patients or their legal '\n",
      "                   'representatives signed an informed consent form'}]\n",
      "\n",
      "Query: was the model tested on a independent dataset?\n",
      "Answers:\n",
      "[   {   'answer': 'must be evaluated and validated in an independent '\n",
      "                  'population',\n",
      "        'context': 'r logistic regression or neural networks â€“ must be '\n",
      "                   'evaluated and validated in an independent population. '\n",
      "                   'Received: 5 October 2004 Revisions requeste'},\n",
      "    {   'answer': 'must be evaluated and validated',\n",
      "        'context': 'ethod â€“ either logistic regression or neural networks '\n",
      "                   'â€“ must be evaluated and validated in an independent '\n",
      "                   'population. Received: 5 October 2004 Rev'},\n",
      "    {   'answer': '2000 bootstrap replications of the model',\n",
      "        'context': 'ROC) curve analysis. Internal validation was done with '\n",
      "                   '2000 bootstrap replications of the model. All statistical '\n",
      "                   'analyses were performed with Stata St'}]\n",
      "\n",
      "Query: was the model tested prospectively?\n",
      "Answers:\n",
      "[   {   'answer': 'must be evaluated and validated in an independent '\n",
      "                  'population',\n",
      "        'context': 'r logistic regression or neural networks â€“ must be '\n",
      "                   'evaluated and validated in an independent population. '\n",
      "                   'Received: 5 October 2004 Revisions requeste'},\n",
      "    {   'answer': 'The general perform  ance of the neural network was '\n",
      "                  'evaluated using the ROC curve and the Hosmer Lemeshow '\n",
      "                  'goodness of fit test',\n",
      "        'context': 'imum error. The general perform  ance of the neural '\n",
      "                   'network was evaluated using the ROC curve and the Hosmer '\n",
      "                   'Lemeshow goodness of fit test. The differ'},\n",
      "    {   'answer': 'Calibration was measured using the Hosmer Lemeshow goodness '\n",
      "                  'of fit test',\n",
      "        'context': 'dden layer and two in the output layer. Calibration was '\n",
      "                   'measured using the Hosmer Lemeshow goodness of fit test '\n",
      "                   'and discrimination was determined usin'}]\n",
      "\n",
      "Query: what were the results of the study?\n",
      "Answers:\n",
      "[   {   'answer': 'overall 28 day mortality was 19%.',\n",
      "        'context': 'curves. Results A total of 533 patients were recruited and '\n",
      "                   'overall 28 day mortality was 19%. The factors chosen by '\n",
      "                   'logistic regression (with their sco'},\n",
      "    {   'answer': 'the patients were followed for 28 days or until death',\n",
      "        'context': 'March 1999. Starting from admis  sion to the ER, the '\n",
      "                   'patients were followed for 28 days or until death. Setting '\n",
      "                   'The patients were admitted to the ERs '},\n",
      "    {   'answer': 'A total of 533 patients were recruited and overall 28 day '\n",
      "                  'mortality was 19%.',\n",
      "        'context': 'ating characteristic curves. Results A total of 533 '\n",
      "                   'patients were recruited and overall 28 day mortality was '\n",
      "                   '19%. The factors chosen by logistic regre'}]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,l):\n",
    "    print_answers(plist[i], details='minimum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db036149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec9024b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dda6831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c56d559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
